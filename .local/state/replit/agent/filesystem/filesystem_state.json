{"file_contents":{"auth.py":{"content":"from datetime import datetime, timedelta\nfrom typing import Optional\nfrom jose import JWTError, jwt\nfrom passlib.context import CryptContext\nfrom fastapi import Depends, HTTPException, status\nfrom fastapi.security import HTTPBearer, HTTPAuthorizationCredentials\nfrom sqlalchemy.orm import Session\nfrom database import get_db\nfrom models import User\nfrom config import settings\n\npwd_context = CryptContext(schemes=[\"bcrypt\"], deprecated=\"auto\")\nsecurity = HTTPBearer()\n\ndef verify_password(plain_password: str, hashed_password: str) -> bool:\n    \"\"\"Verify a password against its hash\"\"\"\n    return pwd_context.verify(plain_password, hashed_password)\n\ndef get_password_hash(password: str) -> str:\n    \"\"\"Hash a password\"\"\"\n    return pwd_context.hash(password)\n\ndef create_access_token(data: dict, expires_delta: Optional[timedelta] = None):\n    \"\"\"Create a JWT access token\"\"\"\n    to_encode = data.copy()\n    if expires_delta:\n        expire = datetime.utcnow() + expires_delta\n    else:\n        expire = datetime.utcnow() + timedelta(minutes=15)\n    to_encode.update({\"exp\": expire})\n    encoded_jwt = jwt.encode(to_encode, settings.SECRET_KEY, algorithm=settings.ALGORITHM)\n    return encoded_jwt\n\ndef verify_token(token: str) -> Optional[str]:\n    \"\"\"Verify JWT token and return username\"\"\"\n    try:\n        payload = jwt.decode(token, settings.SECRET_KEY, algorithms=[settings.ALGORITHM])\n        username: str = payload.get(\"sub\")\n        if username is None:\n            return None\n        return username\n    except JWTError:\n        return None\n\ndef get_user_by_username(db: Session, username: str) -> Optional[User]:\n    \"\"\"Get user by username\"\"\"\n    return db.query(User).filter(User.username == username).first()\n\ndef get_user_by_email(db: Session, email: str) -> Optional[User]:\n    \"\"\"Get user by email\"\"\"\n    return db.query(User).filter(User.email == email).first()\n\ndef authenticate_user(db: Session, username: str, password: str) -> Optional[User]:\n    \"\"\"Authenticate user credentials\"\"\"\n    user = get_user_by_username(db, username)\n    if not user:\n        return None\n    if not verify_password(password, user.hashed_password):\n        return None\n    return user\n\nasync def get_current_user(\n    credentials: HTTPAuthorizationCredentials = Depends(security),\n    db: Session = Depends(get_db)\n) -> User:\n    \"\"\"Get current authenticated user\"\"\"\n    credentials_exception = HTTPException(\n        status_code=status.HTTP_401_UNAUTHORIZED,\n        detail=\"Could not validate credentials\",\n        headers={\"WWW-Authenticate\": \"Bearer\"},\n    )\n    \n    token = credentials.credentials\n    username = verify_token(token)\n    if username is None:\n        raise credentials_exception\n    \n    user = get_user_by_username(db, username)\n    if user is None:\n        raise credentials_exception\n    \n    return user\n\nasync def get_current_active_user(current_user: User = Depends(get_current_user)) -> User:\n    \"\"\"Get current active user\"\"\"\n    if not current_user.is_active:\n        raise HTTPException(status_code=400, detail=\"Inactive user\")\n    return current_user\n","size_bytes":3084},"config.py":{"content":"import os\nfrom typing import Optional\n\nclass Settings:\n    # Database\n    DATABASE_URL: str = os.getenv(\n        \"DATABASE_URL\", \n        \"postgresql://user:password@localhost:5432/studyscheduler\"\n    )\n    \n    # Supabase\n    SUPABASE_URL: Optional[str] = os.getenv(\"SUPABASE_URL\")\n    SUPABASE_KEY: Optional[str] = os.getenv(\"SUPABASE_KEY\")\n    \n    # JWT\n    SECRET_KEY: str = os.getenv(\"SECRET_KEY\", \"your-secret-key-here\")\n    ALGORITHM: str = \"HS256\"\n    ACCESS_TOKEN_EXPIRE_MINUTES: int = 30\n    \n    # File upload\n    MAX_FILE_SIZE: int = 50 * 1024 * 1024  # 50MB\n    UPLOAD_DIR: str = \"uploads\"\n    \n    # Quiz generation\n    QUIZ_QUESTIONS_PER_SECTION: int = 5\n    MIN_QUIZ_DIFFICULTY: float = 0.3\n    MAX_QUIZ_DIFFICULTY: float = 0.8\n\nsettings = Settings()\n\n# Ensure upload directory exists\nos.makedirs(settings.UPLOAD_DIR, exist_ok=True)\n","size_bytes":850},"database.py":{"content":"from sqlalchemy import create_engine\nfrom sqlalchemy.ext.declarative import declarative_base\nfrom sqlalchemy.orm import sessionmaker\nfrom config import settings\n\n# Create engine with connection pooling\nengine = create_engine(\n    settings.DATABASE_URL,\n    pool_pre_ping=True,\n    pool_recycle=300,\n    pool_size=10,\n    max_overflow=20\n)\n\nSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)\nBase = declarative_base()\n\ndef get_db():\n    \"\"\"Dependency to get database session\"\"\"\n    db = SessionLocal()\n    try:\n        yield db\n    finally:\n        db.close()\n","size_bytes":584},"main.py":{"content":"from fastapi import FastAPI, HTTPException\nfrom fastapi.middleware.cors import CORSMiddleware\nfrom fastapi.staticfiles import StaticFiles\nimport uvicorn\nimport os\n\nfrom database import engine, Base\nfrom routers import auth, materials, schedules, quizzes, performance, sessions\nfrom services.ml_service import MLService\n\n# Create database tables\nBase.metadata.create_all(bind=engine)\n\napp = FastAPI(\n    title=\"Personalized Study Scheduler API\",\n    description=\"AI-powered personalized learning and study scheduling platform with ML-driven adaptive algorithms\",\n    version=\"2.0.0\"\n)\n\n# Add CORS middleware\napp.add_middleware(\n    CORSMiddleware,\n    allow_origins=[\"*\"],  # Configure this properly for production\n    allow_credentials=True,\n    allow_methods=[\"*\"],\n    allow_headers=[\"*\"],\n)\n\n# Include routers\napp.include_router(auth.router, prefix=\"/auth\", tags=[\"authentication\"])\napp.include_router(materials.router, prefix=\"/materials\", tags=[\"materials\"])\napp.include_router(schedules.router, prefix=\"/schedules\", tags=[\"schedules\"])\napp.include_router(quizzes.router, prefix=\"/quizzes\", tags=[\"quizzes\"])\napp.include_router(performance.router, prefix=\"/performance\", tags=[\"performance\"])\napp.include_router(sessions.router, prefix=\"/sessions\", tags=[\"sessions\"])\n\n@app.get(\"/\")\nasync def root():\n    return {\n        \"message\": \"Personalized Study Scheduler API\", \n        \"version\": \"2.0.0\",\n        \"features\": [\n            \"Half-Life Regression scheduling\",\n            \"ML-driven quiz generation\", \n            \"Advanced learning analytics\",\n            \"Cognitive load optimization\",\n            \"Adaptive difficulty progression\"\n        ]\n    }\n\n@app.get(\"/health\")\nasync def health_check():\n    return {\"status\": \"healthy\", \"message\": \"API is running\"}\n\nif __name__ == \"__main__\":\n    port = int(os.getenv(\"PORT\", 5000))\n    uvicorn.run(\n        \"main:app\",\n        host=\"0.0.0.0\",\n        port=port,\n        reload=True\n    )\n","size_bytes":1945},"models.py":{"content":"from sqlalchemy import Column, Integer, String, DateTime, Float, Boolean, Text, ForeignKey, JSON\nfrom sqlalchemy.orm import relationship\nfrom sqlalchemy.sql import func\nfrom database import Base\n\nclass User(Base):\n    __tablename__ = \"users\"\n    \n    id = Column(Integer, primary_key=True, index=True)\n    email = Column(String, unique=True, index=True, nullable=False)\n    username = Column(String, unique=True, index=True, nullable=False)\n    hashed_password = Column(String, nullable=False)\n    full_name = Column(String)\n    is_active = Column(Boolean, default=True)\n    \n    # Learning preferences\n    learning_goals = Column(JSON, default=dict)\n    preferred_study_times = Column(JSON, default=dict)\n    difficulty_preference = Column(Float, default=0.5)\n    \n    # Personal learning metrics\n    average_reading_speed = Column(Float, default=200.0)  # words per minute\n    retention_rate = Column(Float, default=0.7)\n    cognitive_load_limit = Column(Float, default=1.0)\n    \n    created_at = Column(DateTime(timezone=True), server_default=func.now())\n    updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n    \n    # Relationships\n    materials = relationship(\"Material\", back_populates=\"user\")\n    schedules = relationship(\"Schedule\", back_populates=\"user\")\n    performance_records = relationship(\"Performance\", back_populates=\"user\")\n    study_sessions = relationship(\"StudySession\", back_populates=\"user\")\n\nclass Material(Base):\n    __tablename__ = \"materials\"\n    \n    id = Column(Integer, primary_key=True, index=True)\n    user_id = Column(Integer, ForeignKey(\"users.id\"), nullable=False)\n    title = Column(String, nullable=False)\n    filename = Column(String, nullable=False)\n    file_path = Column(String, nullable=False)\n    file_size = Column(Integer)\n    \n    # Content analysis\n    extracted_text = Column(Text)\n    word_count = Column(Integer)\n    estimated_reading_time = Column(Float)  # in minutes\n    difficulty_score = Column(Float)\n    \n    # Metadata\n    subject = Column(String)\n    content_type = Column(String, default=\"pdf\")\n    \n    created_at = Column(DateTime(timezone=True), server_default=func.now())\n    updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n    \n    # Relationships\n    user = relationship(\"User\", back_populates=\"materials\")\n    schedules = relationship(\"Schedule\", back_populates=\"material\")\n    quizzes = relationship(\"Quiz\", back_populates=\"material\")\n\nclass Schedule(Base):\n    __tablename__ = \"schedules\"\n    \n    id = Column(Integer, primary_key=True, index=True)\n    user_id = Column(Integer, ForeignKey(\"users.id\"), nullable=False)\n    material_id = Column(Integer, ForeignKey(\"materials.id\"), nullable=False)\n    \n    # Schedule details\n    scheduled_date = Column(DateTime(timezone=True), nullable=False)\n    duration_minutes = Column(Integer, nullable=False)\n    session_type = Column(String, default=\"study\")  # study, review, quiz\n    \n    # Adaptive scheduling data\n    priority_score = Column(Float, default=1.0)\n    cognitive_load_score = Column(Float, default=0.5)\n    repetition_interval = Column(Integer, default=1)  # days\n    \n    # Session status\n    status = Column(String, default=\"scheduled\")  # scheduled, completed, skipped, rescheduled\n    completed_at = Column(DateTime(timezone=True))\n    \n    # Content section (for partial material study)\n    start_position = Column(Integer, default=0)\n    end_position = Column(Integer)\n    \n    created_at = Column(DateTime(timezone=True), server_default=func.now())\n    updated_at = Column(DateTime(timezone=True), onupdate=func.now())\n    \n    # Relationships\n    user = relationship(\"User\", back_populates=\"schedules\")\n    material = relationship(\"Material\", back_populates=\"schedules\")\n    study_sessions = relationship(\"StudySession\", back_populates=\"schedule\")\n\nclass Quiz(Base):\n    __tablename__ = \"quizzes\"\n    \n    id = Column(Integer, primary_key=True, index=True)\n    material_id = Column(Integer, ForeignKey(\"materials.id\"), nullable=False)\n    \n    # Quiz metadata\n    title = Column(String, nullable=False)\n    questions = Column(JSON, nullable=False)  # List of question objects\n    total_questions = Column(Integer, nullable=False)\n    difficulty_level = Column(Float, default=0.5)\n    \n    # Content reference\n    content_section = Column(String)  # Which part of material this quiz covers\n    \n    created_at = Column(DateTime(timezone=True), server_default=func.now())\n    \n    # Relationships\n    material = relationship(\"Material\", back_populates=\"quizzes\")\n    performance_records = relationship(\"Performance\", back_populates=\"quiz\")\n\nclass Performance(Base):\n    __tablename__ = \"performance\"\n    \n    id = Column(Integer, primary_key=True, index=True)\n    user_id = Column(Integer, ForeignKey(\"users.id\"), nullable=False)\n    quiz_id = Column(Integer, ForeignKey(\"quizzes.id\"))\n    session_id = Column(Integer, ForeignKey(\"study_sessions.id\"))\n    \n    # Performance metrics\n    score = Column(Float)  # 0.0 to 1.0\n    time_taken = Column(Float)  # minutes\n    questions_correct = Column(Integer)\n    questions_total = Column(Integer)\n    \n    # Learning analytics\n    comprehension_speed = Column(Float)  # questions per minute\n    retention_score = Column(Float)  # based on follow-up quizzes\n    \n    # Response analysis\n    question_responses = Column(JSON, default=dict)  # detailed responses\n    difficulty_handled = Column(Float)\n    \n    created_at = Column(DateTime(timezone=True), server_default=func.now())\n    \n    # Relationships\n    user = relationship(\"User\", back_populates=\"performance_records\")\n    quiz = relationship(\"Quiz\", back_populates=\"performance_records\")\n    study_session = relationship(\"StudySession\", back_populates=\"performance_records\")\n\nclass StudySession(Base):\n    __tablename__ = \"study_sessions\"\n    \n    id = Column(Integer, primary_key=True, index=True)\n    user_id = Column(Integer, ForeignKey(\"users.id\"), nullable=False)\n    schedule_id = Column(Integer, ForeignKey(\"schedules.id\"))\n    \n    # Session details\n    start_time = Column(DateTime(timezone=True), nullable=False)\n    end_time = Column(DateTime(timezone=True))\n    duration_minutes = Column(Float)\n    \n    # Reading metrics\n    pages_read = Column(Integer, default=0)\n    words_read = Column(Integer, default=0)\n    reading_speed = Column(Float)  # words per minute\n    \n    # Engagement metrics\n    focus_score = Column(Float, default=0.5)  # 0.0 to 1.0\n    interaction_count = Column(Integer, default=0)\n    pause_count = Column(Integer, default=0)\n    total_pause_time = Column(Float, default=0.0)  # minutes\n    \n    # Session outcome\n    completion_percentage = Column(Float, default=0.0)\n    self_rated_understanding = Column(Float)  # 0.0 to 1.0\n    session_notes = Column(Text)\n    \n    created_at = Column(DateTime(timezone=True), server_default=func.now())\n    \n    # Relationships\n    user = relationship(\"User\", back_populates=\"study_sessions\")\n    schedule = relationship(\"Schedule\", back_populates=\"study_sessions\")\n    performance_records = relationship(\"Performance\", back_populates=\"study_session\")\n","size_bytes":7096},"pyproject.toml":{"content":"[project]\nname = \"repl-nix-workspace\"\nversion = \"0.1.0\"\ndescription = \"Add your description here\"\nrequires-python = \">=3.11\"\ndependencies = [\n    \"alembic>=1.16.4\",\n    \"bcrypt>=4.3.0\",\n    \"django-routers>=0.2\",\n    \"fastapi>=0.116.1\",\n    \"jose>=1.0.0\",\n    \"numpy>=2.3.2\",\n    \"passlib>=1.7.4\",\n    \"psycopg2-binary>=2.9.10\",\n    \"pydantic>=2.11.7\",\n    \"pypdf2>=3.0.1\",\n    \"python-dateutil>=2.9.0.post0\",\n    \"python-jose>=3.5.0\",\n    \"python-multipart>=0.0.20\",\n    \"scikit-learn>=1.7.1\",\n    \"sqlalchemy>=2.0.43\",\n    \"uvicorn>=0.35.0\",\n]\n","size_bytes":546},"replit.md":{"content":"# Overview\n\nThis is a **Personalized Study Scheduler API** built with FastAPI that helps users manage their study materials, generate quizzes, and create adaptive learning schedules. The system processes PDF documents, analyzes content difficulty, tracks performance metrics, and provides personalized study recommendations based on individual learning patterns.\n\n# User Preferences\n\nPreferred communication style: Simple, everyday language.\n\n# System Architecture\n\n## Backend Framework\n- **FastAPI** serves as the main web framework, providing automatic API documentation and request/response validation\n- **SQLAlchemy** handles database operations with connection pooling for performance optimization\n- **Alembic** manages database migrations and schema changes\n- Modular router architecture separates concerns (auth, materials, quizzes, schedules, performance, sessions)\n\n## Authentication & Security\n- **JWT (JSON Web Tokens)** for stateless authentication using the JOSE library\n- **bcrypt password hashing** via Passlib for secure credential storage\n- **Bearer token authentication** with automatic token validation middleware\n- User session management with configurable token expiration\n\n## Database Architecture\n- **PostgreSQL** as the primary database (configurable via environment variables)\n- **Connection pooling** with pre-ping health checks and automatic reconnection\n- Relational data model with foreign key relationships between users, materials, schedules, and performance metrics\n- JSON fields for storing flexible user preferences and learning analytics\n\n## File Processing System\n- **PDF text extraction** using PyPDF2 for content analysis\n- **File upload handling** with size limits and unique filename generation\n- **Content analysis pipeline** that calculates reading time, difficulty scores, and word counts\n- Structured text processing for quiz generation and content sectioning\n\n## AI-Powered Features\n- **Quiz generation service** that creates multiple-choice, true/false, and fill-in-the-blank questions from text content\n- **Performance tracking system** that monitors learning progress and adapts to user patterns\n- **Adaptive scheduling algorithm** that adjusts study plans based on user performance and preferences\n- **Difficulty analysis** that matches content complexity to user skill levels\n\n## Service Layer Architecture\n- **PDFProcessor**: Handles document parsing and text extraction\n- **QuizGenerator**: Creates assessments from text content using pattern matching\n- **PerformanceTracker**: Analyzes learning metrics and progress patterns  \n- **StudyScheduler**: Generates and adapts personalized study timelines\n\n# External Dependencies\n\n## Database\n- **PostgreSQL** for primary data storage with connection pooling\n- **SQLAlchemy** ORM for database abstraction and query building\n- **Alembic** for database schema migrations\n\n## Authentication & Security\n- **python-jose** for JWT token creation and validation\n- **passlib[bcrypt]** for secure password hashing\n- **cryptography** libraries for token security\n\n## File Processing\n- **PyPDF2** for PDF text extraction and metadata analysis\n- **FastAPI file upload** handling for document processing\n\n## Optional Integrations\n- **Supabase** integration (configured via environment variables) for cloud database hosting\n- **CORS middleware** for cross-origin request handling in web applications\n\n## Development & Deployment\n- **uvicorn** ASGI server for running the FastAPI application\n- **pydantic** for data validation and serialization\n- Environment-based configuration system for deployment flexibility","size_bytes":3594},"schemas.py":{"content":"from pydantic import BaseModel, EmailStr, validator\nfrom typing import Optional, List, Dict, Any\nfrom datetime import datetime\n\n# User schemas\nclass UserBase(BaseModel):\n    email: EmailStr\n    username: str\n    full_name: Optional[str] = None\n\nclass UserCreate(UserBase):\n    password: str\n\nclass UserUpdate(BaseModel):\n    full_name: Optional[str] = None\n    learning_goals: Optional[Dict[str, Any]] = None\n    preferred_study_times: Optional[Dict[str, Any]] = None\n    difficulty_preference: Optional[float] = None\n\nclass User(UserBase):\n    id: int\n    is_active: bool\n    learning_goals: Dict[str, Any]\n    preferred_study_times: Dict[str, Any]\n    difficulty_preference: float\n    average_reading_speed: float\n    retention_rate: float\n    cognitive_load_limit: float\n    created_at: datetime\n    \n    class Config:\n        from_attributes = True\n\n# Material schemas\nclass MaterialBase(BaseModel):\n    title: str\n    subject: Optional[str] = None\n\nclass MaterialCreate(MaterialBase):\n    pass\n\nclass Material(MaterialBase):\n    id: int\n    user_id: int\n    filename: str\n    file_size: Optional[int]\n    word_count: Optional[int]\n    estimated_reading_time: Optional[float]\n    difficulty_score: Optional[float]\n    content_type: str\n    created_at: datetime\n    \n    class Config:\n        from_attributes = True\n\n# Schedule schemas\nclass ScheduleBase(BaseModel):\n    scheduled_date: datetime\n    duration_minutes: int\n    session_type: str = \"study\"\n\nclass ScheduleCreate(ScheduleBase):\n    material_id: int\n\nclass ScheduleUpdate(BaseModel):\n    scheduled_date: Optional[datetime] = None\n    duration_minutes: Optional[int] = None\n    status: Optional[str] = None\n\nclass Schedule(ScheduleBase):\n    id: int\n    user_id: int\n    material_id: int\n    priority_score: float\n    cognitive_load_score: float\n    repetition_interval: int\n    status: str\n    start_position: int\n    end_position: Optional[int]\n    created_at: datetime\n    \n    class Config:\n        from_attributes = True\n\n# Quiz schemas\nclass QuizQuestion(BaseModel):\n    question: str\n    options: List[str]\n    correct_answer: int\n    explanation: Optional[str] = None\n\nclass QuizBase(BaseModel):\n    title: str\n    difficulty_level: float = 0.5\n\nclass QuizCreate(QuizBase):\n    material_id: int\n    questions: List[QuizQuestion]\n\nclass Quiz(QuizBase):\n    id: int\n    material_id: int\n    questions: List[Dict[str, Any]]\n    total_questions: int\n    content_section: Optional[str]\n    created_at: datetime\n    \n    class Config:\n        from_attributes = True\n\n# Performance schemas\nclass PerformanceBase(BaseModel):\n    score: float\n    time_taken: float\n    questions_correct: int\n    questions_total: int\n\nclass PerformanceCreate(PerformanceBase):\n    quiz_id: Optional[int] = None\n    session_id: Optional[int] = None\n    question_responses: Optional[Dict[str, Any]] = None\n\nclass Performance(PerformanceBase):\n    id: int\n    user_id: int\n    comprehension_speed: Optional[float]\n    retention_score: Optional[float]\n    difficulty_handled: Optional[float]\n    created_at: datetime\n    \n    class Config:\n        from_attributes = True\n\n# Study Session schemas\nclass StudySessionBase(BaseModel):\n    start_time: datetime\n    \nclass StudySessionCreate(StudySessionBase):\n    schedule_id: Optional[int] = None\n\nclass StudySessionUpdate(BaseModel):\n    end_time: Optional[datetime] = None\n    pages_read: Optional[int] = None\n    words_read: Optional[int] = None\n    focus_score: Optional[float] = None\n    completion_percentage: Optional[float] = None\n    self_rated_understanding: Optional[float] = None\n    session_notes: Optional[str] = None\n\nclass StudySession(StudySessionBase):\n    id: int\n    user_id: int\n    schedule_id: Optional[int]\n    end_time: Optional[datetime]\n    duration_minutes: Optional[float]\n    pages_read: int\n    words_read: int\n    reading_speed: Optional[float]\n    focus_score: float\n    completion_percentage: float\n    created_at: datetime\n    \n    class Config:\n        from_attributes = True\n\n# Authentication schemas\nclass Token(BaseModel):\n    access_token: str\n    token_type: str\n\nclass TokenData(BaseModel):\n    username: Optional[str] = None\n","size_bytes":4156},"alembic/env.py":{"content":"import os\nimport sys\nfrom logging.config import fileConfig\nfrom sqlalchemy import engine_from_config\nfrom sqlalchemy import pool\nfrom alembic import context\n\n# Add the project root directory to the Python path\nsys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))\n\n# Import your models and database configuration\nfrom database import Base\nfrom models import *  # Import all models so they're registered with Base\nfrom config import settings\n\n# this is the Alembic Config object, which provides\n# access to the values within the .ini file in use.\nconfig = context.config\n\n# Set the database URL from environment or settings\nconfig.set_main_option(\"DATABASE_URL\", settings.DATABASE_URL)\n\n# Interpret the config file for Python logging.\n# This line sets up loggers basically.\nif config.config_file_name is not None:\n    fileConfig(config.config_file_name)\n\n# add your model's MetaData object here\n# for 'autogenerate' support\ntarget_metadata = Base.metadata\n\n# other values from the config, defined by the needs of env.py,\n# can be acquired:\n# my_important_option = config.get_main_option(\"my_important_option\")\n# ... etc.\n\n\ndef run_migrations_offline() -> None:\n    \"\"\"Run migrations in 'offline' mode.\n\n    This configures the context with just a URL\n    and not an Engine, though an Engine is acceptable\n    here as well.  By skipping the Engine creation\n    we don't even need a DBAPI to be available.\n\n    Calls to context.execute() here emit the given string to the\n    script output.\n\n    \"\"\"\n    url = config.get_main_option(\"sqlalchemy.url\")\n    context.configure(\n        url=url,\n        target_metadata=target_metadata,\n        literal_binds=True,\n        dialect_opts={\"paramstyle\": \"named\"},\n        compare_type=True,\n        compare_server_default=True,\n    )\n\n    with context.begin_transaction():\n        context.run_migrations()\n\n\ndef run_migrations_online() -> None:\n    \"\"\"Run migrations in 'online' mode.\n\n    In this scenario we need to create an Engine\n    and associate a connection with the context.\n\n    \"\"\"\n    # Get database URL from environment\n    database_url = os.getenv(\"DATABASE_URL\") or settings.DATABASE_URL\n    \n    # Handle SQLite URL for local development\n    if database_url.startswith(\"sqlite\"):\n        engine = engine_from_config(\n            {\"sqlalchemy.url\": database_url},\n            prefix=\"sqlalchemy.\",\n            poolclass=pool.NullPool,\n        )\n    else:\n        # PostgreSQL configuration\n        connectable = engine_from_config(\n            {\"sqlalchemy.url\": database_url},\n            prefix=\"sqlalchemy.\",\n            poolclass=pool.NullPool,\n        )\n        engine = connectable\n\n    with engine.connect() as connection:\n        context.configure(\n            connection=connection,\n            target_metadata=target_metadata,\n            compare_type=True,\n            compare_server_default=True,\n        )\n\n        with context.begin_transaction():\n            context.run_migrations()\n\n\nif context.is_offline_mode():\n    run_migrations_offline()\nelse:\n    run_migrations_online()\n","size_bytes":3074},"routers/__init__.py":{"content":"# Routers package for the Personalized Study Scheduler API","size_bytes":58},"routers/auth.py":{"content":"from datetime import timedelta\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom fastapi.security import OAuth2PasswordRequestForm\nfrom sqlalchemy.orm import Session\nfrom database import get_db\nfrom models import User\nfrom schemas import User as UserSchema, UserCreate, Token\nfrom auth import (\n    get_password_hash,\n    authenticate_user,\n    create_access_token,\n    get_user_by_email,\n    get_user_by_username,\n    get_current_active_user\n)\nfrom config import settings\n\nrouter = APIRouter()\n\n@router.post(\"/register\", response_model=UserSchema)\nasync def register(user_data: UserCreate, db: Session = Depends(get_db)):\n    \"\"\"Register a new user\"\"\"\n    \n    # Check if user already exists\n    if get_user_by_email(db, user_data.email):\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Email already registered\"\n        )\n    \n    if get_user_by_username(db, user_data.username):\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Username already taken\"\n        )\n    \n    # Create new user\n    hashed_password = get_password_hash(user_data.password)\n    db_user = User(\n        email=user_data.email,\n        username=user_data.username,\n        full_name=user_data.full_name,\n        hashed_password=hashed_password\n    )\n    \n    db.add(db_user)\n    db.commit()\n    db.refresh(db_user)\n    \n    return db_user\n\n@router.post(\"/login\", response_model=Token)\nasync def login(\n    form_data: OAuth2PasswordRequestForm = Depends(),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Authenticate user and return access token\"\"\"\n    \n    user = authenticate_user(db, form_data.username, form_data.password)\n    if not user:\n        raise HTTPException(\n            status_code=status.HTTP_401_UNAUTHORIZED,\n            detail=\"Incorrect username or password\",\n            headers={\"WWW-Authenticate\": \"Bearer\"},\n        )\n    \n    if not user.is_active:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Inactive user\"\n        )\n    \n    access_token_expires = timedelta(minutes=settings.ACCESS_TOKEN_EXPIRE_MINUTES)\n    access_token = create_access_token(\n        data={\"sub\": user.username}, expires_delta=access_token_expires\n    )\n    \n    return {\"access_token\": access_token, \"token_type\": \"bearer\"}\n\n@router.get(\"/me\", response_model=UserSchema)\nasync def get_current_user_info(\n    current_user: User = Depends(get_current_active_user)\n):\n    \"\"\"Get current user information\"\"\"\n    return current_user\n\n@router.put(\"/me\", response_model=UserSchema)\nasync def update_current_user(\n    user_update: dict,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Update current user profile\"\"\"\n    \n    # Update allowed fields\n    allowed_fields = [\n        'full_name', 'learning_goals', 'preferred_study_times', \n        'difficulty_preference'\n    ]\n    \n    for field, value in user_update.items():\n        if field in allowed_fields and hasattr(current_user, field):\n            setattr(current_user, field, value)\n    \n    db.commit()\n    db.refresh(current_user)\n    \n    return current_user\n","size_bytes":3217},"routers/materials.py":{"content":"import os\nimport shutil\nfrom typing import List\nfrom fastapi import APIRouter, Depends, HTTPException, status, UploadFile, File, Form\nfrom sqlalchemy.orm import Session\nfrom database import get_db\nfrom models import User, Material\nfrom schemas import Material as MaterialSchema, MaterialCreate\nfrom auth import get_current_active_user\nfrom services.pdf_processor import PDFProcessor\nfrom config import settings\n\nrouter = APIRouter()\n\n@router.post(\"/upload\", response_model=MaterialSchema)\nasync def upload_material(\n    file: UploadFile = File(...),\n    title: str = Form(...),\n    subject: str = Form(None),\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Upload and process a PDF material\"\"\"\n    \n    # Validate file type\n    if not file.filename.lower().endswith('.pdf'):\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Only PDF files are supported\"\n        )\n    \n    # Check file size\n    file_size = 0\n    file_content = await file.read()\n    file_size = len(file_content)\n    \n    if file_size > settings.MAX_FILE_SIZE:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=f\"File size exceeds {settings.MAX_FILE_SIZE / (1024*1024):.1f}MB limit\"\n        )\n    \n    # Create unique filename\n    import uuid\n    file_extension = os.path.splitext(file.filename)[1]\n    unique_filename = f\"{uuid.uuid4()}{file_extension}\"\n    file_path = os.path.join(settings.UPLOAD_DIR, unique_filename)\n    \n    try:\n        # Save file\n        with open(file_path, \"wb\") as buffer:\n            buffer.write(file_content)\n        \n        # Process PDF\n        pdf_result = PDFProcessor.extract_text_from_bytes(file_content, file.filename)\n        \n        if not pdf_result['success']:\n            # Clean up file on processing failure\n            if os.path.exists(file_path):\n                os.remove(file_path)\n            raise HTTPException(\n                status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n                detail=f\"PDF processing failed: {pdf_result.get('error', 'Unknown error')}\"\n            )\n        \n        # Create material record\n        material = Material(\n            user_id=current_user.id,\n            title=title,\n            filename=file.filename,\n            file_path=file_path,\n            file_size=file_size,\n            extracted_text=pdf_result['full_text'],\n            word_count=pdf_result['statistics']['word_count'],\n            estimated_reading_time=pdf_result['statistics']['estimated_reading_time'],\n            difficulty_score=pdf_result['statistics']['difficulty_score'],\n            subject=subject,\n            content_type=\"pdf\"\n        )\n        \n        db.add(material)\n        db.commit()\n        db.refresh(material)\n        \n        return material\n        \n    except Exception as e:\n        # Clean up file on any error\n        if os.path.exists(file_path):\n            os.remove(file_path)\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Failed to process upload: {str(e)}\"\n        )\n\n@router.get(\"/\", response_model=List[MaterialSchema])\nasync def get_materials(\n    subject: str = None,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get all materials for the current user\"\"\"\n    \n    query = db.query(Material).filter(Material.user_id == current_user.id)\n    \n    if subject:\n        query = query.filter(Material.subject == subject)\n    \n    materials = query.order_by(Material.created_at.desc()).all()\n    return materials\n\n@router.get(\"/{material_id}\", response_model=MaterialSchema)\nasync def get_material(\n    material_id: int,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get a specific material\"\"\"\n    \n    material = db.query(Material).filter(\n        Material.id == material_id,\n        Material.user_id == current_user.id\n    ).first()\n    \n    if not material:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Material not found\"\n        )\n    \n    return material\n\n@router.get(\"/{material_id}/content\")\nasync def get_material_content(\n    material_id: int,\n    section: int = None,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get material content, optionally by section\"\"\"\n    \n    material = db.query(Material).filter(\n        Material.id == material_id,\n        Material.user_id == current_user.id\n    ).first()\n    \n    if not material:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Material not found\"\n        )\n    \n    if section is not None:\n        # Extract specific section\n        sections = PDFProcessor.extract_sections(material.extracted_text)\n        if section < 1 or section > len(sections):\n            raise HTTPException(\n                status_code=status.HTTP_400_BAD_REQUEST,\n                detail=\"Invalid section number\"\n            )\n        \n        return {\n            'section_number': section,\n            'content': sections[section - 1]['text'],\n            'word_count': sections[section - 1]['word_count'],\n            'estimated_reading_time': sections[section - 1]['estimated_reading_time'],\n            'total_sections': len(sections)\n        }\n    \n    # Return full content\n    sections = PDFProcessor.extract_sections(material.extracted_text)\n    \n    return {\n        'title': material.title,\n        'full_content': material.extracted_text,\n        'word_count': material.word_count,\n        'estimated_reading_time': material.estimated_reading_time,\n        'difficulty_score': material.difficulty_score,\n        'total_sections': len(sections),\n        'sections': sections\n    }\n\n@router.delete(\"/{material_id}\")\nasync def delete_material(\n    material_id: int,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Delete a material and its associated file\"\"\"\n    \n    material = db.query(Material).filter(\n        Material.id == material_id,\n        Material.user_id == current_user.id\n    ).first()\n    \n    if not material:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Material not found\"\n        )\n    \n    # Delete the physical file\n    if os.path.exists(material.file_path):\n        try:\n            os.remove(material.file_path)\n        except OSError as e:\n            print(f\"Error deleting file {material.file_path}: {e}\")\n    \n    # Delete database record\n    db.delete(material)\n    db.commit()\n    \n    return {\"message\": \"Material deleted successfully\"}\n\n@router.get(\"/{material_id}/stats\")\nasync def get_material_stats(\n    material_id: int,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get detailed statistics for a material\"\"\"\n    \n    material = db.query(Material).filter(\n        Material.id == material_id,\n        Material.user_id == current_user.id\n    ).first()\n    \n    if not material:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Material not found\"\n        )\n    \n    # Get sections for analysis\n    sections = PDFProcessor.extract_sections(material.extracted_text)\n    \n    # Calculate additional statistics\n    text = material.extracted_text\n    paragraphs = len([p for p in text.split('\\n\\n') if p.strip()])\n    sentences = len([s for s in text.split('.') if s.strip()])\n    avg_words_per_sentence = material.word_count / sentences if sentences > 0 else 0\n    \n    return {\n        'basic_stats': {\n            'word_count': material.word_count,\n            'estimated_reading_time': material.estimated_reading_time,\n            'difficulty_score': material.difficulty_score,\n            'file_size': material.file_size\n        },\n        'content_structure': {\n            'total_sections': len(sections),\n            'paragraphs': paragraphs,\n            'sentences': sentences,\n            'avg_words_per_sentence': round(avg_words_per_sentence, 1)\n        },\n        'sections': [\n            {\n                'section_number': s['section_number'],\n                'word_count': s['word_count'],\n                'estimated_reading_time': s['estimated_reading_time']\n            }\n            for s in sections\n        ]\n    }\n","size_bytes":8503},"routers/performance.py":{"content":"from datetime import datetime, timedelta\nfrom typing import List, Dict, Any, Optional\nfrom fastapi import APIRouter, Depends, HTTPException, status, Query\nfrom sqlalchemy.orm import Session\nfrom database import get_db\nfrom models import User, Performance, StudySession, Material, Quiz\nfrom schemas import Performance as PerformanceSchema, PerformanceCreate\nfrom auth import get_current_active_user\nfrom services.performance_tracker import PerformanceTracker\n\nrouter = APIRouter()\n\n@router.get(\"/analytics\")\nasync def get_performance_analytics(\n    material_id: Optional[int] = Query(None, description=\"Filter by specific material\"),\n    days_back: int = Query(30, description=\"Number of days to analyze\", ge=1, le=365),\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get comprehensive performance analytics for the current user\"\"\"\n    \n    tracker = PerformanceTracker(db)\n    analytics = tracker.get_performance_analytics(\n        user_id=current_user.id,\n        material_id=material_id,\n        days_back=days_back\n    )\n    \n    if not analytics['success']:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=analytics.get('error', 'Failed to retrieve analytics')\n        )\n    \n    return analytics\n\n@router.get(\"/learning-curve/{material_id}\")\nasync def get_learning_curve(\n    material_id: int,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get learning curve data for a specific material\"\"\"\n    \n    # Verify material belongs to user\n    material = db.query(Material).filter(\n        Material.id == material_id,\n        Material.user_id == current_user.id\n    ).first()\n    \n    if not material:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Material not found\"\n        )\n    \n    tracker = PerformanceTracker(db)\n    curve_data = tracker.get_learning_curve_data(\n        user_id=current_user.id,\n        material_id=material_id\n    )\n    \n    if not curve_data['success']:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=curve_data.get('error', 'Failed to retrieve learning curve data')\n        )\n    \n    return curve_data\n\n@router.get(\"/quiz-history\", response_model=List[PerformanceSchema])\nasync def get_quiz_history(\n    material_id: Optional[int] = Query(None, description=\"Filter by material\"),\n    limit: int = Query(50, description=\"Number of records to return\", ge=1, le=200),\n    offset: int = Query(0, description=\"Number of records to skip\", ge=0),\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get quiz performance history for the current user\"\"\"\n    \n    query = db.query(Performance).filter(\n        Performance.user_id == current_user.id,\n        Performance.quiz_id.isnot(None)\n    )\n    \n    if material_id:\n        query = query.join(Quiz).filter(Quiz.material_id == material_id)\n    \n    performances = query.order_by(Performance.created_at.desc()).offset(offset).limit(limit).all()\n    return performances\n\n@router.get(\"/session-history\")\nasync def get_session_history(\n    material_id: Optional[int] = Query(None, description=\"Filter by material\"),\n    days_back: int = Query(30, description=\"Days to look back\", ge=1, le=365),\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get study session history with performance metrics\"\"\"\n    \n    cutoff_date = datetime.utcnow() - timedelta(days=days_back)\n    \n    query = db.query(StudySession).filter(\n        StudySession.user_id == current_user.id,\n        StudySession.start_time >= cutoff_date\n    )\n    \n    if material_id:\n        # Join through Schedule to filter by material\n        from models import Schedule\n        query = query.join(Schedule, StudySession.schedule_id == Schedule.id).filter(\n            Schedule.material_id == material_id\n        )\n    \n    sessions = query.order_by(StudySession.start_time.desc()).all()\n    \n    # Format session data with performance metrics\n    session_data = []\n    for session in sessions:\n        session_info = {\n            'id': session.id,\n            'start_time': session.start_time,\n            'end_time': session.end_time,\n            'duration_minutes': session.duration_minutes,\n            'pages_read': session.pages_read,\n            'words_read': session.words_read,\n            'reading_speed': session.reading_speed,\n            'focus_score': session.focus_score,\n            'completion_percentage': session.completion_percentage,\n            'self_rated_understanding': session.self_rated_understanding,\n            'schedule_id': session.schedule_id\n        }\n        \n        # Add material info if available through schedule\n        if session.schedule and session.schedule.material:\n            session_info['material'] = {\n                'id': session.schedule.material.id,\n                'title': session.schedule.material.title,\n                'subject': session.schedule.material.subject\n            }\n        \n        session_data.append(session_info)\n    \n    return {\n        'sessions': session_data,\n        'total_sessions': len(sessions),\n        'period_days': days_back\n    }\n\n@router.get(\"/summary\")\nasync def get_performance_summary(\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get overall performance summary for the current user\"\"\"\n    \n    # Get recent performance data (last 30 days)\n    cutoff_date = datetime.utcnow() - timedelta(days=30)\n    \n    # Quiz performances\n    quiz_performances = db.query(Performance).filter(\n        Performance.user_id == current_user.id,\n        Performance.quiz_id.isnot(None),\n        Performance.created_at >= cutoff_date\n    ).all()\n    \n    # Study sessions\n    study_sessions = db.query(StudySession).filter(\n        StudySession.user_id == current_user.id,\n        StudySession.start_time >= cutoff_date\n    ).all()\n    \n    # Calculate summary metrics\n    total_quizzes = len(quiz_performances)\n    avg_quiz_score = sum(p.score for p in quiz_performances) / total_quizzes if total_quizzes > 0 else 0\n    \n    total_sessions = len(study_sessions)\n    total_study_time = sum(s.duration_minutes for s in study_sessions if s.duration_minutes) or 0\n    avg_focus_score = sum(s.focus_score for s in study_sessions) / total_sessions if total_sessions > 0 else 0\n    \n    # Reading speed calculation\n    reading_speeds = [s.reading_speed for s in study_sessions if s.reading_speed and s.reading_speed > 0]\n    avg_reading_speed = sum(reading_speeds) / len(reading_speeds) if reading_speeds else current_user.average_reading_speed\n    \n    # Words read total\n    total_words_read = sum(s.words_read for s in study_sessions if s.words_read) or 0\n    \n    # Performance trends (comparing last 15 days to previous 15 days)\n    mid_date = datetime.utcnow() - timedelta(days=15)\n    \n    recent_performances = [p for p in quiz_performances if p.created_at >= mid_date]\n    older_performances = [p for p in quiz_performances if p.created_at < mid_date]\n    \n    trend = \"stable\"\n    if recent_performances and older_performances:\n        recent_avg = sum(p.score for p in recent_performances) / len(recent_performances)\n        older_avg = sum(p.score for p in older_performances) / len(older_performances)\n        \n        if recent_avg > older_avg + 0.05:\n            trend = \"improving\"\n        elif recent_avg < older_avg - 0.05:\n            trend = \"declining\"\n    \n    return {\n        'period': '30 days',\n        'quiz_metrics': {\n            'total_quizzes': total_quizzes,\n            'average_score': round(avg_quiz_score, 3),\n            'score_percentage': round(avg_quiz_score * 100, 1)\n        },\n        'study_metrics': {\n            'total_sessions': total_sessions,\n            'total_study_time_minutes': total_study_time,\n            'total_study_time_hours': round(total_study_time / 60, 1),\n            'average_focus_score': round(avg_focus_score, 3),\n            'total_words_read': total_words_read,\n            'average_reading_speed': round(avg_reading_speed, 1)\n        },\n        'performance_trend': trend,\n        'user_profile': {\n            'retention_rate': current_user.retention_rate,\n            'cognitive_load_limit': current_user.cognitive_load_limit,\n            'preferred_difficulty': current_user.difficulty_preference\n        }\n    }\n\n@router.get(\"/materials-progress\")\nasync def get_materials_progress(\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get progress overview for all user materials\"\"\"\n    \n    materials = db.query(Material).filter(Material.user_id == current_user.id).all()\n    \n    materials_progress = []\n    for material in materials:\n        # Get quiz performances for this material\n        quiz_performances = db.query(Performance).join(Quiz).filter(\n            Performance.user_id == current_user.id,\n            Quiz.material_id == material.id\n        ).order_by(Performance.created_at.desc()).limit(10).all()\n        \n        # Get study sessions for this material\n        from models import Schedule\n        study_sessions = db.query(StudySession).join(Schedule).filter(\n            StudySession.user_id == current_user.id,\n            Schedule.material_id == material.id\n        ).order_by(StudySession.start_time.desc()).limit(10).all()\n        \n        # Calculate progress metrics\n        avg_score = 0\n        total_study_time = 0\n        completion_rate = 0\n        \n        if quiz_performances:\n            avg_score = sum(p.score for p in quiz_performances) / len(quiz_performances)\n        \n        if study_sessions:\n            total_study_time = sum(s.duration_minutes for s in study_sessions if s.duration_minutes) or 0\n            completion_rates = [s.completion_percentage for s in study_sessions if s.completion_percentage is not None]\n            completion_rate = sum(completion_rates) / len(completion_rates) if completion_rates else 0\n        \n        # Determine mastery level\n        mastery_level = \"not_started\"\n        if avg_score >= 0.9:\n            mastery_level = \"mastered\"\n        elif avg_score >= 0.7:\n            mastery_level = \"proficient\"\n        elif avg_score >= 0.5:\n            mastery_level = \"learning\"\n        elif avg_score > 0:\n            mastery_level = \"struggling\"\n        \n        materials_progress.append({\n            'material': {\n                'id': material.id,\n                'title': material.title,\n                'subject': material.subject,\n                'difficulty_score': material.difficulty_score,\n                'estimated_reading_time': material.estimated_reading_time\n            },\n            'progress': {\n                'average_quiz_score': round(avg_score, 3),\n                'total_study_time_minutes': total_study_time,\n                'completion_rate': round(completion_rate, 1),\n                'mastery_level': mastery_level,\n                'total_quizzes_taken': len(quiz_performances),\n                'total_study_sessions': len(study_sessions)\n            }\n        })\n    \n    return {\n        'materials_progress': materials_progress,\n        'total_materials': len(materials)\n    }\n\n@router.get(\"/streaks\")\nasync def get_study_streaks(\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get study streak information\"\"\"\n    \n    # Get all study sessions ordered by date\n    sessions = db.query(StudySession).filter(\n        StudySession.user_id == current_user.id\n    ).order_by(StudySession.start_time.desc()).all()\n    \n    if not sessions:\n        return {\n            'current_streak': 0,\n            'longest_streak': 0,\n            'last_study_date': None,\n            'streak_status': 'no_data'\n        }\n    \n    # Calculate streaks\n    study_dates = []\n    for session in sessions:\n        date_str = session.start_time.strftime('%Y-%m-%d')\n        if date_str not in study_dates:\n            study_dates.append(date_str)\n    \n    # Sort dates (newest first)\n    study_dates.sort(reverse=True)\n    \n    # Calculate current streak\n    current_streak = 0\n    today = datetime.utcnow().strftime('%Y-%m-%d')\n    yesterday = (datetime.utcnow() - timedelta(days=1)).strftime('%Y-%m-%d')\n    \n    # Check if studied today or yesterday (allow for timezone differences)\n    if study_dates and (study_dates[0] == today or study_dates[0] == yesterday):\n        current_date = datetime.strptime(study_dates[0], '%Y-%m-%d')\n        current_streak = 1\n        \n        for i in range(1, len(study_dates)):\n            prev_date = datetime.strptime(study_dates[i], '%Y-%m-%d')\n            if (current_date - prev_date).days == 1:\n                current_streak += 1\n                current_date = prev_date\n            else:\n                break\n    \n    # Calculate longest streak\n    longest_streak = 0\n    temp_streak = 1\n    \n    if len(study_dates) > 1:\n        for i in range(1, len(study_dates)):\n            current_date = datetime.strptime(study_dates[i-1], '%Y-%m-%d')\n            prev_date = datetime.strptime(study_dates[i], '%Y-%m-%d')\n            \n            if (current_date - prev_date).days == 1:\n                temp_streak += 1\n            else:\n                longest_streak = max(longest_streak, temp_streak)\n                temp_streak = 1\n        \n        longest_streak = max(longest_streak, temp_streak)\n    else:\n        longest_streak = 1 if study_dates else 0\n    \n    # Determine streak status\n    streak_status = \"active\"\n    if current_streak == 0:\n        streak_status = \"broken\"\n    elif study_dates[0] == today:\n        streak_status = \"completed_today\"\n    elif study_dates[0] == yesterday:\n        streak_status = \"pending_today\"\n    \n    return {\n        'current_streak': current_streak,\n        'longest_streak': longest_streak,\n        'last_study_date': study_dates[0] if study_dates else None,\n        'streak_status': streak_status,\n        'total_study_days': len(study_dates)\n    }\n\n@router.post(\"/record-quiz\", response_model=PerformanceSchema)\nasync def record_quiz_performance(\n    performance_data: PerformanceCreate,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Record a quiz performance (alternative endpoint to quiz submission)\"\"\"\n    \n    if not performance_data.quiz_id:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Quiz ID is required for quiz performance recording\"\n        )\n    \n    # Verify quiz exists and belongs to user's material\n    quiz = db.query(Quiz).join(Material).filter(\n        Quiz.id == performance_data.quiz_id,\n        Material.user_id == current_user.id\n    ).first()\n    \n    if not quiz:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Quiz not found\"\n        )\n    \n    tracker = PerformanceTracker(db)\n    result = tracker.record_quiz_performance(\n        user_id=current_user.id,\n        quiz_id=performance_data.quiz_id,\n        score=performance_data.score,\n        time_taken=performance_data.time_taken,\n        questions_correct=performance_data.questions_correct,\n        questions_total=performance_data.questions_total,\n        question_responses=performance_data.question_responses\n    )\n    \n    if not result['success']:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=result.get('error', 'Failed to record performance')\n        )\n    \n    # Get the created performance record\n    performance = db.query(Performance).filter(Performance.id == result['performance_id']).first()\n    return performance\n\n@router.delete(\"/{performance_id}\")\nasync def delete_performance_record(\n    performance_id: int,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Delete a performance record\"\"\"\n    \n    performance = db.query(Performance).filter(\n        Performance.id == performance_id,\n        Performance.user_id == current_user.id\n    ).first()\n    \n    if not performance:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Performance record not found\"\n        )\n    \n    db.delete(performance)\n    db.commit()\n    \n    return {\"message\": \"Performance record deleted successfully\"}\n","size_bytes":16542},"routers/quizzes.py":{"content":"from typing import List, Dict, Any\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom sqlalchemy.orm import Session\nfrom database import get_db\nfrom models import User, Material, Quiz\nfrom schemas import Quiz as QuizSchema, QuizCreate\nfrom auth import get_current_active_user\nfrom services.quiz_generator import QuizGenerator\n\nrouter = APIRouter()\n\n@router.post(\"/generate\", response_model=QuizSchema)\nasync def generate_quiz(\n    material_id: int,\n    num_questions: int = 5,\n    difficulty_level: float = 0.5,\n    content_section: str = None,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Generate a quiz from material content\"\"\"\n    \n    # Verify material belongs to user\n    material = db.query(Material).filter(\n        Material.id == material_id,\n        Material.user_id == current_user.id\n    ).first()\n    \n    if not material:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Material not found\"\n        )\n    \n    # Validate parameters\n    if num_questions < 1 or num_questions > 20:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Number of questions must be between 1 and 20\"\n        )\n    \n    if difficulty_level < 0.0 or difficulty_level > 1.0:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Difficulty level must be between 0.0 and 1.0\"\n        )\n    \n    # Get content for quiz generation\n    text_content = material.extracted_text\n    if content_section:\n        # Extract specific section content if requested\n        from services.pdf_processor import PDFProcessor\n        sections = PDFProcessor.extract_sections(text_content)\n        try:\n            section_num = int(content_section) - 1\n            if 0 <= section_num < len(sections):\n                text_content = sections[section_num]['text']\n            else:\n                raise HTTPException(\n                    status_code=status.HTTP_400_BAD_REQUEST,\n                    detail=\"Invalid section number\"\n                )\n        except ValueError:\n            # If content_section is not a number, use it as a content identifier\n            pass\n    \n    # Generate quiz\n    quiz_result = QuizGenerator.generate_quiz_from_text(\n        text=text_content,\n        num_questions=num_questions,\n        difficulty_level=difficulty_level,\n        content_section=content_section\n    )\n    \n    if not quiz_result['success']:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Quiz generation failed: {quiz_result.get('error', 'Unknown error')}\"\n        )\n    \n    # Create quiz record\n    quiz_title = f\"Quiz for {material.title}\"\n    if content_section:\n        quiz_title += f\" (Section {content_section})\"\n    \n    quiz = Quiz(\n        material_id=material_id,\n        title=quiz_title,\n        questions=quiz_result['questions'],\n        total_questions=quiz_result['total_questions'],\n        difficulty_level=difficulty_level,\n        content_section=content_section\n    )\n    \n    db.add(quiz)\n    db.commit()\n    db.refresh(quiz)\n    \n    return quiz\n\n@router.get(\"/\", response_model=List[QuizSchema])\nasync def get_quizzes(\n    material_id: int = None,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get quizzes for the current user\"\"\"\n    \n    query = db.query(Quiz).join(Material).filter(Material.user_id == current_user.id)\n    \n    if material_id:\n        query = query.filter(Quiz.material_id == material_id)\n    \n    quizzes = query.order_by(Quiz.created_at.desc()).all()\n    return quizzes\n\n@router.get(\"/{quiz_id}\", response_model=QuizSchema)\nasync def get_quiz(\n    quiz_id: int,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get a specific quiz\"\"\"\n    \n    quiz = db.query(Quiz).join(Material).filter(\n        Quiz.id == quiz_id,\n        Material.user_id == current_user.id\n    ).first()\n    \n    if not quiz:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Quiz not found\"\n        )\n    \n    return quiz\n\n@router.get(\"/{quiz_id}/questions\")\nasync def get_quiz_questions(\n    quiz_id: int,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get quiz questions (without correct answers for taking the quiz)\"\"\"\n    \n    quiz = db.query(Quiz).join(Material).filter(\n        Quiz.id == quiz_id,\n        Material.user_id == current_user.id\n    ).first()\n    \n    if not quiz:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Quiz not found\"\n        )\n    \n    # Return questions without correct answers for quiz taking\n    questions = []\n    for i, question in enumerate(quiz.questions):\n        question_data = {\n            'question_number': i + 1,\n            'question': question.get('question', ''),\n            'type': question.get('type', 'multiple_choice'),\n            'options': question.get('options', [])\n        }\n        \n        # For fill-in-the-blank, don't return the answer\n        if question_data['type'] == 'fill_blank':\n            question_data['options'] = []\n        \n        questions.append(question_data)\n    \n    return {\n        'quiz_id': quiz.id,\n        'title': quiz.title,\n        'total_questions': quiz.total_questions,\n        'difficulty_level': quiz.difficulty_level,\n        'questions': questions\n    }\n\n@router.post(\"/{quiz_id}/submit\")\nasync def submit_quiz(\n    quiz_id: int,\n    answers: List[Any],\n    time_taken: float = None,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Submit quiz answers and get results\"\"\"\n    \n    quiz = db.query(Quiz).join(Material).filter(\n        Quiz.id == quiz_id,\n        Material.user_id == current_user.id\n    ).first()\n    \n    if not quiz:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Quiz not found\"\n        )\n    \n    # Validate answers\n    if len(answers) != quiz.total_questions:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=f\"Expected {quiz.total_questions} answers, got {len(answers)}\"\n        )\n    \n    # Validate quiz answers\n    validation_result = QuizGenerator.validate_quiz_answers(quiz.questions, answers)\n    \n    if not validation_result['success']:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=validation_result.get('error', 'Answer validation failed')\n        )\n    \n    # Record performance\n    from services.performance_tracker import PerformanceTracker\n    tracker = PerformanceTracker(db)\n    \n    performance_result = tracker.record_quiz_performance(\n        user_id=current_user.id,\n        quiz_id=quiz_id,\n        score=validation_result['score'],\n        time_taken=time_taken or 0.0,\n        questions_correct=validation_result['correct_count'],\n        questions_total=validation_result['total_questions'],\n        question_responses={\n            'answers': answers,\n            'detailed_results': validation_result['detailed_results']\n        }\n    )\n    \n    if not performance_result['success']:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=\"Failed to record performance\"\n        )\n    \n    return {\n        'score': validation_result['score'],\n        'correct_count': validation_result['correct_count'],\n        'total_questions': validation_result['total_questions'],\n        'percentage': round(validation_result['score'] * 100, 1),\n        'time_taken': time_taken,\n        'detailed_results': validation_result['detailed_results'],\n        'performance_id': performance_result['performance_id'],\n        'analysis': performance_result.get('analysis', {})\n    }\n\n@router.post(\"/{quiz_id}/retry\")\nasync def retry_quiz(\n    quiz_id: int,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Reset and retry a quiz (generates new questions)\"\"\"\n    \n    quiz = db.query(Quiz).join(Material).filter(\n        Quiz.id == quiz_id,\n        Material.user_id == current_user.id\n    ).first()\n    \n    if not quiz:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Quiz not found\"\n        )\n    \n    # Get material content\n    material = quiz.material\n    text_content = material.extracted_text\n    \n    # If quiz was for a specific section, use that section\n    if quiz.content_section:\n        from services.pdf_processor import PDFProcessor\n        sections = PDFProcessor.extract_sections(text_content)\n        try:\n            section_num = int(quiz.content_section) - 1\n            if 0 <= section_num < len(sections):\n                text_content = sections[section_num]['text']\n        except ValueError:\n            pass\n    \n    # Generate new quiz questions\n    quiz_result = QuizGenerator.generate_quiz_from_text(\n        text=text_content,\n        num_questions=quiz.total_questions,\n        difficulty_level=quiz.difficulty_level,\n        content_section=quiz.content_section\n    )\n    \n    if not quiz_result['success']:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=f\"Quiz regeneration failed: {quiz_result.get('error', 'Unknown error')}\"\n        )\n    \n    # Update quiz with new questions\n    quiz.questions = quiz_result['questions']\n    quiz.total_questions = quiz_result['total_questions']\n    \n    db.commit()\n    db.refresh(quiz)\n    \n    return {\n        'message': 'Quiz regenerated with new questions',\n        'quiz': quiz\n    }\n\n@router.delete(\"/{quiz_id}\")\nasync def delete_quiz(\n    quiz_id: int,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Delete a quiz\"\"\"\n    \n    quiz = db.query(Quiz).join(Material).filter(\n        Quiz.id == quiz_id,\n        Material.user_id == current_user.id\n    ).first()\n    \n    if not quiz:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Quiz not found\"\n        )\n    \n    db.delete(quiz)\n    db.commit()\n    \n    return {\"message\": \"Quiz deleted successfully\"}\n\n@router.get(\"/{quiz_id}/answers\")\nasync def get_quiz_answers(\n    quiz_id: int,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get quiz answers (for review after completion)\"\"\"\n    \n    quiz = db.query(Quiz).join(Material).filter(\n        Quiz.id == quiz_id,\n        Material.user_id == current_user.id\n    ).first()\n    \n    if not quiz:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Quiz not found\"\n        )\n    \n    # Check if user has attempted this quiz\n    from models import Performance\n    performance_exists = db.query(Performance).filter(\n        Performance.user_id == current_user.id,\n        Performance.quiz_id == quiz_id\n    ).first()\n    \n    if not performance_exists:\n        raise HTTPException(\n            status_code=status.HTTP_403_FORBIDDEN,\n            detail=\"You must attempt the quiz before viewing answers\"\n        )\n    \n    # Return complete questions with answers\n    return {\n        'quiz_id': quiz.id,\n        'title': quiz.title,\n        'questions_with_answers': quiz.questions\n    }\n","size_bytes":11593},"routers/schedules.py":{"content":"from datetime import datetime, timedelta\nfrom typing import List, Optional\nfrom fastapi import APIRouter, Depends, HTTPException, status\nfrom sqlalchemy.orm import Session\nfrom database import get_db\nfrom models import User, Schedule, Material\nfrom schemas import Schedule as ScheduleSchema, ScheduleCreate, ScheduleUpdate\nfrom auth import get_current_active_user\nfrom services.scheduler import StudyScheduler\n\nrouter = APIRouter()\n\n@router.post(\"/generate\", response_model=List[ScheduleSchema])\nasync def generate_schedule(\n    material_id: int,\n    target_completion_date: datetime,\n    daily_study_time: int = 60,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Generate a study schedule for a material\"\"\"\n    \n    # Verify material belongs to user\n    material = db.query(Material).filter(\n        Material.id == material_id,\n        Material.user_id == current_user.id\n    ).first()\n    \n    if not material:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Material not found\"\n        )\n    \n    # Validate target date\n    if target_completion_date <= datetime.utcnow():\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Target completion date must be in the future\"\n        )\n    \n    # Generate schedule\n    scheduler = StudyScheduler(db)\n    schedule_data = scheduler.generate_initial_schedule(\n        user_id=current_user.id,\n        material_id=material_id,\n        target_completion_date=target_completion_date,\n        daily_study_time=daily_study_time\n    )\n    \n    if not schedule_data:\n        raise HTTPException(\n            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,\n            detail=\"Failed to generate schedule\"\n        )\n    \n    # Save schedules to database\n    schedules = []\n    for schedule_entry in schedule_data:\n        schedule = Schedule(**schedule_entry)\n        db.add(schedule)\n        schedules.append(schedule)\n    \n    db.commit()\n    \n    # Refresh all schedules to get IDs\n    for schedule in schedules:\n        db.refresh(schedule)\n    \n    return schedules\n\n@router.get(\"/\", response_model=List[ScheduleSchema])\nasync def get_schedules(\n    material_id: Optional[int] = None,\n    status_filter: Optional[str] = None,\n    start_date: Optional[datetime] = None,\n    end_date: Optional[datetime] = None,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get schedules for the current user\"\"\"\n    \n    query = db.query(Schedule).filter(Schedule.user_id == current_user.id)\n    \n    if material_id:\n        query = query.filter(Schedule.material_id == material_id)\n    \n    if status_filter:\n        query = query.filter(Schedule.status == status_filter)\n    \n    if start_date:\n        query = query.filter(Schedule.scheduled_date >= start_date)\n    \n    if end_date:\n        query = query.filter(Schedule.scheduled_date <= end_date)\n    \n    schedules = query.order_by(Schedule.scheduled_date).all()\n    return schedules\n\n@router.get(\"/{schedule_id}\", response_model=ScheduleSchema)\nasync def get_schedule(\n    schedule_id: int,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get a specific schedule\"\"\"\n    \n    schedule = db.query(Schedule).filter(\n        Schedule.id == schedule_id,\n        Schedule.user_id == current_user.id\n    ).first()\n    \n    if not schedule:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Schedule not found\"\n        )\n    \n    return schedule\n\n@router.put(\"/{schedule_id}\", response_model=ScheduleSchema)\nasync def update_schedule(\n    schedule_id: int,\n    schedule_update: ScheduleUpdate,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Update a schedule\"\"\"\n    \n    schedule = db.query(Schedule).filter(\n        Schedule.id == schedule_id,\n        Schedule.user_id == current_user.id\n    ).first()\n    \n    if not schedule:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Schedule not found\"\n        )\n    \n    # Update fields\n    update_data = schedule_update.dict(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(schedule, field, value)\n    \n    # Mark as completed if end time is being set\n    if schedule_update.status == \"completed\":\n        schedule.completed_at = datetime.utcnow()\n    \n    db.commit()\n    db.refresh(schedule)\n    \n    return schedule\n\n@router.post(\"/{schedule_id}/complete\")\nasync def complete_schedule(\n    schedule_id: int,\n    completion_data: dict = None,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Mark a schedule as completed\"\"\"\n    \n    schedule = db.query(Schedule).filter(\n        Schedule.id == schedule_id,\n        Schedule.user_id == current_user.id\n    ).first()\n    \n    if not schedule:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Schedule not found\"\n        )\n    \n    if schedule.status == \"completed\":\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Schedule is already completed\"\n        )\n    \n    # Update schedule status\n    schedule.status = \"completed\"\n    schedule.completed_at = datetime.utcnow()\n    \n    # Update completion percentage if provided\n    if completion_data and 'completion_percentage' in completion_data:\n        completion_percentage = completion_data['completion_percentage']\n        if 0 <= completion_percentage <= 100:\n            # Store completion data (could extend Schedule model to include this)\n            pass\n    \n    db.commit()\n    db.refresh(schedule)\n    \n    return {\"message\": \"Schedule marked as completed\", \"schedule\": schedule}\n\n@router.post(\"/adapt\")\nasync def adapt_schedules(\n    material_id: Optional[int] = None,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Adapt schedules based on performance data\"\"\"\n    \n    scheduler = StudyScheduler(db)\n    adaptations = scheduler.adapt_schedule_based_on_performance(\n        user_id=current_user.id,\n        material_id=material_id\n    )\n    \n    if not adaptations:\n        return {\"message\": \"No adaptations needed\", \"adaptations\": []}\n    \n    # Apply adaptations to schedules\n    applied_adaptations = []\n    for adaptation in adaptations:\n        schedule_id = adaptation['schedule_id']\n        schedule = db.query(Schedule).filter(Schedule.id == schedule_id).first()\n        \n        if schedule:\n            # Apply specific adaptations\n            for adapt_action in adaptation['adaptations']:\n                if adapt_action == 'increase_review':\n                    # Add additional review session\n                    review_schedule = Schedule(\n                        user_id=current_user.id,\n                        material_id=schedule.material_id,\n                        scheduled_date=schedule.scheduled_date + timedelta(days=1),\n                        duration_minutes=schedule.duration_minutes // 2,\n                        session_type='review',\n                        priority_score=schedule.priority_score + 0.2,\n                        cognitive_load_score=schedule.cognitive_load_score * 0.8,\n                        repetition_interval=1,\n                        start_position=schedule.start_position,\n                        end_position=schedule.end_position,\n                        status='scheduled'\n                    )\n                    db.add(review_schedule)\n                \n                elif adapt_action.startswith('reduce_interval_to_'):\n                    interval = int(adapt_action.split('_')[-1])\n                    schedule.repetition_interval = interval\n                \n                elif adapt_action.startswith('increase_interval_to_'):\n                    interval = int(adapt_action.split('_')[-1])\n                    schedule.repetition_interval = interval\n                \n                elif adapt_action.startswith('reschedule_to_'):\n                    hour = int(adapt_action.split('_')[-1])\n                    schedule.scheduled_date = schedule.scheduled_date.replace(hour=hour)\n                \n                elif adapt_action == 'reduce_session_duration':\n                    schedule.duration_minutes = int(schedule.duration_minutes * 0.8)\n            \n            applied_adaptations.append(adaptation)\n    \n    db.commit()\n    \n    return {\n        \"message\": f\"Applied {len(applied_adaptations)} schedule adaptations\",\n        \"adaptations\": applied_adaptations\n    }\n\n@router.get(\"/upcoming/week\")\nasync def get_weekly_schedule(\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get upcoming week's schedule\"\"\"\n    \n    start_date = datetime.utcnow().replace(hour=0, minute=0, second=0, microsecond=0)\n    end_date = start_date + timedelta(days=7)\n    \n    schedules = db.query(Schedule).filter(\n        Schedule.user_id == current_user.id,\n        Schedule.scheduled_date >= start_date,\n        Schedule.scheduled_date <= end_date,\n        Schedule.status.in_(['scheduled', 'rescheduled'])\n    ).order_by(Schedule.scheduled_date).all()\n    \n    # Group by date\n    weekly_schedule = {}\n    for schedule in schedules:\n        date_key = schedule.scheduled_date.strftime('%Y-%m-%d')\n        if date_key not in weekly_schedule:\n            weekly_schedule[date_key] = []\n        \n        weekly_schedule[date_key].append({\n            'id': schedule.id,\n            'material_id': schedule.material_id,\n            'time': schedule.scheduled_date.strftime('%H:%M'),\n            'duration_minutes': schedule.duration_minutes,\n            'session_type': schedule.session_type,\n            'priority_score': schedule.priority_score\n        })\n    \n    return {\n        'week_start': start_date.isoformat(),\n        'week_end': end_date.isoformat(),\n        'schedule': weekly_schedule,\n        'total_sessions': len(schedules)\n    }\n\n@router.delete(\"/{schedule_id}\")\nasync def delete_schedule(\n    schedule_id: int,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Delete a schedule\"\"\"\n    \n    schedule = db.query(Schedule).filter(\n        Schedule.id == schedule_id,\n        Schedule.user_id == current_user.id\n    ).first()\n    \n    if not schedule:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Schedule not found\"\n        )\n    \n    db.delete(schedule)\n    db.commit()\n    \n    return {\"message\": \"Schedule deleted successfully\"}\n","size_bytes":10779},"routers/sessions.py":{"content":"from datetime import datetime, timedelta\nfrom typing import List, Optional\nfrom fastapi import APIRouter, Depends, HTTPException, status, Query\nfrom sqlalchemy.orm import Session\nfrom database import get_db\nfrom models import User, StudySession, Schedule, Material\nfrom schemas import StudySession as StudySessionSchema, StudySessionCreate, StudySessionUpdate\nfrom auth import get_current_active_user\nfrom services.performance_tracker import PerformanceTracker\n\nrouter = APIRouter()\n\n@router.post(\"/start\", response_model=StudySessionSchema)\nasync def start_study_session(\n    session_data: StudySessionCreate,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Start a new study session\"\"\"\n    \n    # Verify schedule belongs to user if schedule_id is provided\n    if session_data.schedule_id:\n        schedule = db.query(Schedule).filter(\n            Schedule.id == session_data.schedule_id,\n            Schedule.user_id == current_user.id\n        ).first()\n        \n        if not schedule:\n            raise HTTPException(\n                status_code=status.HTTP_404_NOT_FOUND,\n                detail=\"Schedule not found\"\n            )\n    \n    # Create study session\n    study_session = StudySession(\n        user_id=current_user.id,\n        schedule_id=session_data.schedule_id,\n        start_time=session_data.start_time\n    )\n    \n    db.add(study_session)\n    db.commit()\n    db.refresh(study_session)\n    \n    return study_session\n\n@router.put(\"/{session_id}/update\", response_model=StudySessionSchema)\nasync def update_study_session(\n    session_id: int,\n    session_update: StudySessionUpdate,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Update a study session with progress data\"\"\"\n    \n    study_session = db.query(StudySession).filter(\n        StudySession.id == session_id,\n        StudySession.user_id == current_user.id\n    ).first()\n    \n    if not study_session:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Study session not found\"\n        )\n    \n    # Update fields\n    update_data = session_update.dict(exclude_unset=True)\n    for field, value in update_data.items():\n        setattr(study_session, field, value)\n    \n    # Calculate derived metrics if end_time is set\n    if session_update.end_time and study_session.start_time:\n        duration = (session_update.end_time - study_session.start_time).total_seconds() / 60\n        study_session.duration_minutes = duration\n        \n        # Calculate reading speed if words_read is provided\n        if session_update.words_read and duration > 0:\n            study_session.reading_speed = session_update.words_read / duration\n    \n    db.commit()\n    db.refresh(study_session)\n    \n    return study_session\n\n@router.post(\"/{session_id}/complete\")\nasync def complete_study_session(\n    session_id: int,\n    completion_data: dict = None,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Complete a study session and record performance\"\"\"\n    \n    study_session = db.query(StudySession).filter(\n        StudySession.id == session_id,\n        StudySession.user_id == current_user.id\n    ).first()\n    \n    if not study_session:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Study session not found\"\n        )\n    \n    if study_session.end_time:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Study session is already completed\"\n        )\n    \n    # Set end time and completion data\n    end_time = datetime.utcnow()\n    study_session.end_time = end_time\n    \n    # Calculate duration\n    if study_session.start_time:\n        duration = (end_time - study_session.start_time).total_seconds() / 60\n        study_session.duration_minutes = duration\n        \n        # Calculate reading speed if words were read\n        if study_session.words_read and duration > 0:\n            study_session.reading_speed = study_session.words_read / duration\n    \n    # Update additional completion data if provided\n    if completion_data:\n        for field in ['completion_percentage', 'self_rated_understanding', 'session_notes', 'focus_score']:\n            if field in completion_data:\n                setattr(study_session, field, completion_data[field])\n    \n    db.commit()\n    \n    # Update associated schedule status if exists\n    if study_session.schedule_id:\n        schedule = db.query(Schedule).filter(Schedule.id == study_session.schedule_id).first()\n        if schedule and schedule.status == 'scheduled':\n            schedule.status = 'completed'\n            schedule.completed_at = end_time\n            db.commit()\n    \n    # Record session performance\n    tracker = PerformanceTracker(db)\n    session_performance_data = {\n        'start_time': study_session.start_time,\n        'end_time': study_session.end_time,\n        'duration_minutes': study_session.duration_minutes,\n        'pages_read': study_session.pages_read,\n        'words_read': study_session.words_read,\n        'reading_speed': study_session.reading_speed,\n        'focus_score': study_session.focus_score,\n        'completion_percentage': study_session.completion_percentage,\n        'self_rated_understanding': study_session.self_rated_understanding,\n        'session_notes': study_session.session_notes,\n        'schedule_id': study_session.schedule_id\n    }\n    \n    performance_result = tracker.record_study_session(\n        user_id=current_user.id,\n        session_data=session_performance_data\n    )\n    \n    db.refresh(study_session)\n    \n    return {\n        'message': 'Study session completed successfully',\n        'session': study_session,\n        'performance_recorded': performance_result.get('success', False),\n        'calculated_metrics': {\n            'duration_minutes': study_session.duration_minutes,\n            'reading_speed': study_session.reading_speed\n        }\n    }\n\n@router.get(\"/\", response_model=List[StudySessionSchema])\nasync def get_study_sessions(\n    schedule_id: Optional[int] = Query(None, description=\"Filter by schedule ID\"),\n    material_id: Optional[int] = Query(None, description=\"Filter by material ID\"),\n    start_date: Optional[datetime] = Query(None, description=\"Filter sessions after this date\"),\n    end_date: Optional[datetime] = Query(None, description=\"Filter sessions before this date\"),\n    limit: int = Query(50, description=\"Number of sessions to return\", ge=1, le=200),\n    offset: int = Query(0, description=\"Number of sessions to skip\", ge=0),\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get study sessions for the current user\"\"\"\n    \n    query = db.query(StudySession).filter(StudySession.user_id == current_user.id)\n    \n    if schedule_id:\n        query = query.filter(StudySession.schedule_id == schedule_id)\n    \n    if material_id:\n        query = query.join(Schedule).filter(Schedule.material_id == material_id)\n    \n    if start_date:\n        query = query.filter(StudySession.start_time >= start_date)\n    \n    if end_date:\n        query = query.filter(StudySession.start_time <= end_date)\n    \n    sessions = query.order_by(StudySession.start_time.desc()).offset(offset).limit(limit).all()\n    return sessions\n\n@router.get(\"/{session_id}\", response_model=StudySessionSchema)\nasync def get_study_session(\n    session_id: int,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get a specific study session\"\"\"\n    \n    study_session = db.query(StudySession).filter(\n        StudySession.id == session_id,\n        StudySession.user_id == current_user.id\n    ).first()\n    \n    if not study_session:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Study session not found\"\n        )\n    \n    return study_session\n\n@router.get(\"/active/current\")\nasync def get_active_session(\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get currently active study session (if any)\"\"\"\n    \n    active_session = db.query(StudySession).filter(\n        StudySession.user_id == current_user.id,\n        StudySession.end_time.is_(None)\n    ).order_by(StudySession.start_time.desc()).first()\n    \n    if not active_session:\n        return {\n            'active_session': None,\n            'has_active_session': False\n        }\n    \n    # Check if session is too old (more than 24 hours)\n    if datetime.utcnow() - active_session.start_time > timedelta(hours=24):\n        # Auto-complete old sessions\n        active_session.end_time = active_session.start_time + timedelta(hours=2)  # Assume 2-hour session\n        duration = 120  # 2 hours in minutes\n        active_session.duration_minutes = duration\n        active_session.completion_percentage = 50.0  # Partial completion\n        db.commit()\n        \n        return {\n            'active_session': None,\n            'has_active_session': False,\n            'message': 'Previous session was auto-completed due to timeout'\n        }\n    \n    # Include related information\n    session_info = {\n        'id': active_session.id,\n        'start_time': active_session.start_time,\n        'duration_so_far': (datetime.utcnow() - active_session.start_time).total_seconds() / 60,\n        'pages_read': active_session.pages_read,\n        'words_read': active_session.words_read,\n        'focus_score': active_session.focus_score,\n        'schedule_id': active_session.schedule_id\n    }\n    \n    # Add schedule and material info if available\n    if active_session.schedule_id:\n        schedule = db.query(Schedule).filter(Schedule.id == active_session.schedule_id).first()\n        if schedule:\n            session_info['schedule'] = {\n                'id': schedule.id,\n                'session_type': schedule.session_type,\n                'duration_minutes': schedule.duration_minutes,\n                'material_id': schedule.material_id\n            }\n            \n            if schedule.material:\n                session_info['material'] = {\n                    'id': schedule.material.id,\n                    'title': schedule.material.title,\n                    'subject': schedule.material.subject\n                }\n    \n    return {\n        'active_session': session_info,\n        'has_active_session': True\n    }\n\n@router.post(\"/{session_id}/pause\")\nasync def pause_study_session(\n    session_id: int,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Record a pause in the study session\"\"\"\n    \n    study_session = db.query(StudySession).filter(\n        StudySession.id == session_id,\n        StudySession.user_id == current_user.id\n    ).first()\n    \n    if not study_session:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Study session not found\"\n        )\n    \n    if study_session.end_time:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Cannot pause a completed session\"\n        )\n    \n    # Increment pause count and record pause time\n    study_session.pause_count = (study_session.pause_count or 0) + 1\n    \n    # Note: In a real application, you might want to track pause start/end times\n    # For now, we'll just increment the counter\n    \n    db.commit()\n    \n    return {\n        'message': 'Pause recorded',\n        'total_pauses': study_session.pause_count\n    }\n\n@router.post(\"/{session_id}/resume\")\nasync def resume_study_session(\n    session_id: int,\n    pause_duration_minutes: float = 0,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Resume a paused study session\"\"\"\n    \n    study_session = db.query(StudySession).filter(\n        StudySession.id == session_id,\n        StudySession.user_id == current_user.id\n    ).first()\n    \n    if not study_session:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Study session not found\"\n        )\n    \n    if study_session.end_time:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Cannot resume a completed session\"\n        )\n    \n    # Add pause time to total pause time\n    if pause_duration_minutes > 0:\n        study_session.total_pause_time = (study_session.total_pause_time or 0) + pause_duration_minutes\n        db.commit()\n    \n    return {\n        'message': 'Session resumed',\n        'total_pause_time': study_session.total_pause_time\n    }\n\n@router.get(\"/{session_id}/stats\")\nasync def get_session_stats(\n    session_id: int,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Get detailed statistics for a study session\"\"\"\n    \n    study_session = db.query(StudySession).filter(\n        StudySession.id == session_id,\n        StudySession.user_id == current_user.id\n    ).first()\n    \n    if not study_session:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Study session not found\"\n        )\n    \n    # Calculate effective study time (total time minus pauses)\n    effective_duration = study_session.duration_minutes or 0\n    if study_session.total_pause_time:\n        effective_duration = max(0, effective_duration - study_session.total_pause_time)\n    \n    # Calculate productivity metrics\n    productivity_score = 0\n    if study_session.duration_minutes and study_session.duration_minutes > 0:\n        # Base productivity on focus score and completion percentage\n        focus_component = (study_session.focus_score or 0.5) * 0.4\n        completion_component = (study_session.completion_percentage or 0) / 100 * 0.6\n        productivity_score = focus_component + completion_component\n    \n    # Get material info if available through schedule\n    material_info = None\n    if study_session.schedule and study_session.schedule.material:\n        material = study_session.schedule.material\n        material_info = {\n            'id': material.id,\n            'title': material.title,\n            'subject': material.subject,\n            'difficulty_score': material.difficulty_score\n        }\n    \n    return {\n        'session_id': session_id,\n        'basic_metrics': {\n            'start_time': study_session.start_time,\n            'end_time': study_session.end_time,\n            'duration_minutes': study_session.duration_minutes,\n            'effective_duration_minutes': effective_duration,\n            'pause_count': study_session.pause_count or 0,\n            'total_pause_time': study_session.total_pause_time or 0\n        },\n        'reading_metrics': {\n            'pages_read': study_session.pages_read or 0,\n            'words_read': study_session.words_read or 0,\n            'reading_speed': study_session.reading_speed,\n            'estimated_comprehension': study_session.self_rated_understanding\n        },\n        'engagement_metrics': {\n            'focus_score': study_session.focus_score or 0,\n            'completion_percentage': study_session.completion_percentage or 0,\n            'interaction_count': study_session.interaction_count or 0,\n            'productivity_score': round(productivity_score, 3)\n        },\n        'material': material_info,\n        'notes': study_session.session_notes\n    }\n\n@router.delete(\"/{session_id}\")\nasync def delete_study_session(\n    session_id: int,\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Delete a study session\"\"\"\n    \n    study_session = db.query(StudySession).filter(\n        StudySession.id == session_id,\n        StudySession.user_id == current_user.id\n    ).first()\n    \n    if not study_session:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Study session not found\"\n        )\n    \n    # Check if session is currently active\n    if not study_session.end_time:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Cannot delete an active session. Complete or abandon it first.\"\n        )\n    \n    db.delete(study_session)\n    db.commit()\n    \n    return {\"message\": \"Study session deleted successfully\"}\n\n@router.post(\"/{session_id}/abandon\")\nasync def abandon_study_session(\n    session_id: int,\n    reason: str = \"user_abandoned\",\n    current_user: User = Depends(get_current_active_user),\n    db: Session = Depends(get_db)\n):\n    \"\"\"Abandon an active study session without completion\"\"\"\n    \n    study_session = db.query(StudySession).filter(\n        StudySession.id == session_id,\n        StudySession.user_id == current_user.id\n    ).first()\n    \n    if not study_session:\n        raise HTTPException(\n            status_code=status.HTTP_404_NOT_FOUND,\n            detail=\"Study session not found\"\n        )\n    \n    if study_session.end_time:\n        raise HTTPException(\n            status_code=status.HTTP_400_BAD_REQUEST,\n            detail=\"Session is already completed\"\n        )\n    \n    # Mark session as abandoned\n    study_session.end_time = datetime.utcnow()\n    if study_session.start_time:\n        duration = (study_session.end_time - study_session.start_time).total_seconds() / 60\n        study_session.duration_minutes = duration\n    \n    # Set low completion percentage for abandoned session\n    study_session.completion_percentage = min(study_session.completion_percentage or 0, 25.0)\n    study_session.session_notes = f\"Session abandoned: {reason}\"\n    \n    db.commit()\n    \n    return {\n        'message': 'Study session abandoned',\n        'session_id': session_id,\n        'reason': reason\n    }\n","size_bytes":17837},"services/document_processor.py":{"content":"\"\"\"\nEnhanced Document Processor with ML-driven content analysis\nImplements advanced document processing pipeline from system architecture\n\"\"\"\n\nimport pypdf as PyPDF2\nimport os\nimport re\nimport math\nfrom typing import Dict, Any, Optional, List\nfrom io import BytesIO\nimport numpy as np\nfrom collections import Counter\nfrom sqlalchemy.orm import Session\n\nclass DocumentProcessor:\n    \"\"\"\n    Enhanced document processing service with ML-driven content analysis\n    Supports multiple document types with advanced text analytics\n    \"\"\"\n    \n    def __init__(self):\n        # Initialize TF-IDF and other NLP components\n        self.stop_words = set([\n            'the', 'a', 'an', 'and', 'or', 'but', 'in', 'on', 'at', 'to', 'for', \n            'of', 'with', 'by', 'from', 'up', 'about', 'into', 'through', 'during',\n            'before', 'after', 'above', 'below', 'is', 'are', 'was', 'were', 'be',\n            'been', 'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',\n            'would', 'could', 'should', 'this', 'that', 'these', 'those'\n        ])\n    \n    def process_document(self, file_content: bytes, filename: str) -> Dict[str, Any]:\n        \"\"\"\n        Complete document processing pipeline with ML analysis\n        \n        Args:\n            file_content: Raw file content as bytes\n            filename: Name of the uploaded file\n            \n        Returns:\n            Comprehensive document analysis results\n        \"\"\"\n        try:\n            # Step 1: Text Extraction\n            extraction_result = self._extract_text_content(file_content, filename)\n            if not extraction_result['success']:\n                return extraction_result\n            \n            # Step 2: Content Structure Analysis\n            structure_analysis = self.analyze_content_structure(extraction_result['full_text'])\n            \n            # Step 3: Readability and Difficulty Analysis\n            readability_analysis = self._advanced_readability_analysis(extraction_result['full_text'])\n            \n            # Step 4: Keyword and Topic Extraction\n            keyword_analysis = self._extract_keywords_and_topics(extraction_result['full_text'])\n            \n            # Step 5: Learning Objective Identification\n            learning_objectives = self._identify_learning_objectives(extraction_result['full_text'])\n            \n            # Step 6: Content Segmentation for Optimal Learning\n            content_segments = self._intelligent_content_segmentation(\n                extraction_result['full_text'],\n                readability_analysis['difficulty_score']\n            )\n            \n            return {\n                'success': True,\n                'full_text': extraction_result['full_text'],\n                'metadata': extraction_result['metadata'],\n                'structure_analysis': structure_analysis,\n                'readability_analysis': readability_analysis,\n                'keyword_analysis': keyword_analysis,\n                'learning_objectives': learning_objectives,\n                'content_segments': content_segments,\n                'processing_metadata': {\n                    'processed_at': extraction_result['metadata'].get('processed_at'),\n                    'processor_version': '2.0',\n                    'analysis_methods': ['flesch_reading_ease', 'tf_idf', 'semantic_segmentation']\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Document processing failed: {str(e)}',\n                'stage': 'document_processing'\n            }\n    \n    def analyze_content_structure(self, text: str) -> Dict[str, Any]:\n        \"\"\"\n        Advanced content structure analysis\n        \n        Args:\n            text: Full text content\n            \n        Returns:\n            Detailed structure analysis\n        \"\"\"\n        try:\n            # Basic text statistics\n            words = text.split()\n            sentences = re.split(r'[.!?]+', text)\n            sentences = [s.strip() for s in sentences if s.strip()]\n            paragraphs = text.split('\\n\\n')\n            paragraphs = [p.strip() for p in paragraphs if p.strip()]\n            \n            # Advanced metrics\n            avg_sentence_length = len(words) / len(sentences) if sentences else 0\n            avg_paragraph_length = len(sentences) / len(paragraphs) if paragraphs else 0\n            \n            # Complexity indicators\n            complex_words = [w for w in words if len(w) > 6 and not w.lower() in self.stop_words]\n            technical_terms = self._identify_technical_terms(words)\n            \n            # Estimated difficulty\n            difficulty_score = self._calculate_advanced_difficulty(text, words, sentences)\n            \n            # Reading time estimation with user adaptation\n            base_reading_speed = 200  # words per minute\n            adjusted_speed = base_reading_speed * (1 - (difficulty_score * 0.3))  # Slower for difficult text\n            estimated_reading_time = len(words) / adjusted_speed\n            \n            return {\n                'word_count': len(words),\n                'sentence_count': len(sentences),\n                'paragraph_count': len(paragraphs),\n                'character_count': len(text),\n                'avg_sentence_length': round(avg_sentence_length, 2),\n                'avg_paragraph_length': round(avg_paragraph_length, 2),\n                'complex_word_ratio': len(complex_words) / len(words) if words else 0,\n                'technical_term_count': len(technical_terms),\n                'technical_terms': technical_terms[:10],  # Top 10 technical terms\n                'estimated_difficulty': difficulty_score,\n                'estimated_reading_time': round(estimated_reading_time, 2),\n                'content_density': self._calculate_content_density(text),\n                'structural_complexity': self._analyze_structural_complexity(paragraphs)\n            }\n            \n        except Exception as e:\n            return {\n                'error': str(e),\n                'word_count': 0,\n                'estimated_difficulty': 0.5,\n                'estimated_reading_time': 0\n            }\n    \n    def optimize_content_selection(\n        self,\n        material_id: int,\n        available_time: int,\n        user_reading_speed: float,\n        difficulty_preference: float\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Optimize content selection for study sessions\n        \n        Args:\n            material_id: ID of the material\n            available_time: Available study time in minutes\n            user_reading_speed: User's reading speed (words per minute)\n            difficulty_preference: User's difficulty tolerance (0.0-1.0)\n            \n        Returns:\n            Optimized content selection\n        \"\"\"\n        try:\n            # This would typically retrieve material from database\n            # For now, we'll simulate the optimization logic\n            \n            # Calculate optimal word count for session\n            max_words = int(available_time * user_reading_speed)\n            \n            # Adjust for difficulty preference\n            difficulty_adjustment = 1.0 - (difficulty_preference * 0.3)\n            adjusted_word_count = int(max_words * difficulty_adjustment)\n            \n            # Create recommended sections (simulated)\n            recommended_sections = [\n                {\n                    'section_id': f'section_{i+1}',\n                    'title': f'Section {i+1}',\n                    'word_count': min(500, adjusted_word_count // 3),\n                    'estimated_time': min(15, available_time // 3),\n                    'difficulty_score': min(difficulty_preference + 0.1, 1.0),\n                    'content_type': 'reading',\n                    'learning_objectives': [f'Objective {i+1}.1', f'Objective {i+1}.2']\n                }\n                for i in range(min(3, available_time // 15))  # Max 3 sections, 15 min minimum each\n            ]\n            \n            return {\n                'success': True,\n                'recommended_sections': recommended_sections,\n                'optimization_factors': {\n                    'available_time': available_time,\n                    'user_reading_speed': user_reading_speed,\n                    'difficulty_preference': difficulty_preference,\n                    'total_estimated_time': sum(s['estimated_time'] for s in recommended_sections)\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': str(e),\n                'recommended_sections': []\n            }\n    \n    def _extract_text_content(self, file_content: bytes, filename: str) -> Dict[str, Any]:\n        \"\"\"Enhanced text extraction with multiple format support\"\"\"\n        file_extension = os.path.splitext(filename)[1].lower()\n        \n        if file_extension == '.pdf':\n            return self._extract_pdf_content(file_content, filename)\n        elif file_extension in ['.txt', '.md']:\n            return self._extract_text_content_simple(file_content, filename)\n        else:\n            return {\n                'success': False,\n                'error': f'Unsupported file format: {file_extension}',\n                'supported_formats': ['.pdf', '.txt', '.md']\n            }\n    \n    def _extract_pdf_content(self, file_content: bytes, filename: str) -> Dict[str, Any]:\n        \"\"\"Extract content from PDF with enhanced metadata\"\"\"\n        try:\n            pdf_reader = PyPDF2.PdfReader(BytesIO(file_content))\n            \n            # Enhanced metadata extraction\n            metadata = {\n                'filename': filename,\n                'total_pages': len(pdf_reader.pages),\n                'title': '',\n                'author': '',\n                'subject': '',\n                'creator': '',\n                'producer': '',\n                'creation_date': None,\n                'modification_date': None\n            }\n            \n            # Extract PDF metadata if available\n            if pdf_reader.metadata:\n                metadata.update({\n                    'title': pdf_reader.metadata.get('/Title', ''),\n                    'author': pdf_reader.metadata.get('/Author', ''),\n                    'subject': pdf_reader.metadata.get('/Subject', ''),\n                    'creator': pdf_reader.metadata.get('/Creator', ''),\n                    'producer': pdf_reader.metadata.get('/Producer', ''),\n                    'creation_date': pdf_reader.metadata.get('/CreationDate'),\n                    'modification_date': pdf_reader.metadata.get('/ModDate')\n                })\n            \n            # Extract text with page-level analysis\n            full_text = \"\"\n            page_analyses = []\n            \n            for page_num, page in enumerate(pdf_reader.pages):\n                try:\n                    page_text = page.extract_text()\n                    page_word_count = len(page_text.split()) if page_text else 0\n                    \n                    page_analyses.append({\n                        'page_number': page_num + 1,\n                        'text': page_text,\n                        'word_count': page_word_count,\n                        'character_count': len(page_text) if page_text else 0,\n                        'estimated_reading_time': self._estimate_reading_time(page_word_count)\n                    })\n                    \n                    full_text += page_text + \"\\n\"\n                    \n                except Exception as e:\n                    page_analyses.append({\n                        'page_number': page_num + 1,\n                        'text': '',\n                        'word_count': 0,\n                        'character_count': 0,\n                        'error': str(e)\n                    })\n            \n            return {\n                'success': True,\n                'full_text': full_text,\n                'metadata': metadata,\n                'page_analyses': page_analyses,\n                'extraction_method': 'pypdf'\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': str(e),\n                'full_text': '',\n                'metadata': {'filename': filename}\n            }\n    \n    def _extract_text_content_simple(self, file_content: bytes, filename: str) -> Dict[str, Any]:\n        \"\"\"Extract content from text files\"\"\"\n        try:\n            text = file_content.decode('utf-8')\n            word_count = len(text.split())\n            \n            return {\n                'success': True,\n                'full_text': text,\n                'metadata': {\n                    'filename': filename,\n                    'word_count': word_count,\n                    'character_count': len(text),\n                    'estimated_reading_time': self._estimate_reading_time(word_count)\n                },\n                'extraction_method': 'text_decode'\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': str(e),\n                'full_text': '',\n                'metadata': {'filename': filename}\n            }\n    \n    def _advanced_readability_analysis(self, text: str) -> Dict[str, Any]:\n        \"\"\"Advanced readability analysis using multiple metrics\"\"\"\n        if not text or not text.strip():\n            return {'difficulty_score': 0.5, 'readability_metrics': {}}\n        \n        words = text.split()\n        sentences = re.split(r'[.!?]+', text)\n        sentences = [s.strip() for s in sentences if s.strip()]\n        \n        if not words or not sentences:\n            return {'difficulty_score': 0.5, 'readability_metrics': {}}\n        \n        # Basic metrics\n        avg_sentence_length = len(words) / len(sentences)\n        avg_word_length = sum(len(word) for word in words) / len(words)\n        \n        # Syllable counting for more accurate analysis\n        total_syllables = sum(self._count_syllables(word) for word in words)\n        avg_syllables_per_word = total_syllables / len(words)\n        \n        # Flesch Reading Ease Score\n        flesch_score = 206.835 - (1.015 * avg_sentence_length) - (84.6 * avg_syllables_per_word)\n        \n        # Flesch-Kincaid Grade Level\n        fk_grade = (0.39 * avg_sentence_length) + (11.8 * avg_syllables_per_word) - 15.59\n        \n        # Gunning Fog Index\n        complex_words = [w for w in words if self._count_syllables(w) >= 3]\n        complex_word_ratio = len(complex_words) / len(words)\n        gunning_fog = 0.4 * (avg_sentence_length + (100 * complex_word_ratio))\n        \n        # SMOG Index (simplified)\n        smog_index = 1.043 * math.sqrt(complex_word_ratio * 30) + 3.1291\n        \n        # Convert to normalized difficulty score (0.0 = easy, 1.0 = very difficult)\n        difficulty_indicators = [\n            max(0, min(1, (100 - flesch_score) / 100)),  # Flesch (inverted)\n            max(0, min(1, fk_grade / 20)),  # FK Grade normalized\n            max(0, min(1, gunning_fog / 20)),  # Gunning Fog normalized\n            max(0, min(1, smog_index / 20)),  # SMOG normalized\n            complex_word_ratio  # Complex word ratio\n        ]\n        \n        # Weighted average of difficulty indicators\n        difficulty_score = sum(difficulty_indicators) / len(difficulty_indicators)\n        \n        return {\n            'difficulty_score': round(difficulty_score, 3),\n            'readability_metrics': {\n                'flesch_reading_ease': round(flesch_score, 2),\n                'flesch_kincaid_grade': round(fk_grade, 2),\n                'gunning_fog_index': round(gunning_fog, 2),\n                'smog_index': round(smog_index, 2),\n                'average_sentence_length': round(avg_sentence_length, 2),\n                'average_word_length': round(avg_word_length, 2),\n                'average_syllables_per_word': round(avg_syllables_per_word, 2),\n                'complex_word_percentage': round(complex_word_ratio * 100, 2)\n            },\n            'readability_level': self._get_readability_level(difficulty_score)\n        }\n    \n    def _extract_keywords_and_topics(self, text: str) -> Dict[str, Any]:\n        \"\"\"Extract keywords and topics using TF-IDF analysis\"\"\"\n        words = re.findall(r'\\b[a-zA-Z]{3,}\\b', text.lower())\n        words = [w for w in words if w not in self.stop_words]\n        \n        if not words:\n            return {'keywords': [], 'topics': [], 'word_frequency': {}}\n        \n        # Word frequency analysis\n        word_freq = Counter(words)\n        total_words = len(words)\n        \n        # Calculate TF-IDF scores (simplified)\n        tf_scores = {word: freq / total_words for word, freq in word_freq.items()}\n        \n        # Identify keywords (high frequency, non-common words)\n        keywords = sorted(tf_scores.items(), key=lambda x: x[1], reverse=True)[:20]\n        \n        # Topic identification (simplified clustering of related terms)\n        topics = self._identify_topics(keywords)\n        \n        return {\n            'keywords': [{'word': word, 'score': round(score, 4)} for word, score in keywords],\n            'topics': topics,\n            'word_frequency': dict(word_freq.most_common(50)),\n            'vocabulary_diversity': len(set(words)) / len(words),\n            'total_unique_words': len(set(words))\n        }\n    \n    def _identify_learning_objectives(self, text: str) -> List[Dict[str, Any]]:\n        \"\"\"Identify potential learning objectives from content\"\"\"\n        # Simplified pattern matching for learning objectives\n        objective_patterns = [\n            r'understand\\s+([^.]+)',\n            r'learn\\s+about\\s+([^.]+)',\n            r'explain\\s+([^.]+)',\n            r'describe\\s+([^.]+)',\n            r'analyze\\s+([^.]+)',\n            r'identify\\s+([^.]+)',\n            r'define\\s+([^.]+)'\n        ]\n        \n        objectives = []\n        for pattern in objective_patterns:\n            matches = re.finditer(pattern, text.lower())\n            for match in matches:\n                objective_text = match.group(1).strip()\n                if len(objective_text) > 5 and len(objective_text) < 100:\n                    objectives.append({\n                        'objective': objective_text.capitalize(),\n                        'type': pattern.split('\\\\s+')[0],\n                        'confidence': 0.7  # Simple confidence score\n                    })\n        \n        # Remove duplicates and limit to top objectives\n        unique_objectives = []\n        seen = set()\n        for obj in objectives:\n            if obj['objective'] not in seen:\n                unique_objectives.append(obj)\n                seen.add(obj['objective'])\n                if len(unique_objectives) >= 10:\n                    break\n        \n        return unique_objectives\n    \n    def _intelligent_content_segmentation(self, text: str, difficulty_score: float) -> List[Dict[str, Any]]:\n        \"\"\"Intelligent content segmentation for optimal learning\"\"\"\n        paragraphs = text.split('\\n\\n')\n        paragraphs = [p.strip() for p in paragraphs if p.strip()]\n        \n        # Adaptive section size based on difficulty\n        base_words_per_section = 400\n        difficulty_adjustment = 1.0 - (difficulty_score * 0.4)  # Smaller sections for difficult content\n        target_words_per_section = int(base_words_per_section * difficulty_adjustment)\n        \n        segments = []\n        current_segment = \"\"\n        current_word_count = 0\n        segment_number = 1\n        \n        for para in paragraphs:\n            para_words = len(para.split())\n            \n            if current_word_count + para_words > target_words_per_section and current_segment:\n                # Create segment\n                segment_analysis = self._analyze_segment(current_segment)\n                segments.append({\n                    'segment_number': segment_number,\n                    'content': current_segment.strip(),\n                    'word_count': current_word_count,\n                    'estimated_reading_time': self._estimate_reading_time(current_word_count),\n                    'difficulty_score': segment_analysis['difficulty'],\n                    'key_concepts': segment_analysis['key_concepts'],\n                    'cognitive_load': self._estimate_cognitive_load(current_segment, difficulty_score)\n                })\n                \n                current_segment = para\n                current_word_count = para_words\n                segment_number += 1\n            else:\n                current_segment += \"\\n\\n\" + para if current_segment else para\n                current_word_count += para_words\n        \n        # Add final segment\n        if current_segment.strip():\n            segment_analysis = self._analyze_segment(current_segment)\n            segments.append({\n                'segment_number': segment_number,\n                'content': current_segment.strip(),\n                'word_count': current_word_count,\n                'estimated_reading_time': self._estimate_reading_time(current_word_count),\n                'difficulty_score': segment_analysis['difficulty'],\n                'key_concepts': segment_analysis['key_concepts'],\n                'cognitive_load': self._estimate_cognitive_load(current_segment, difficulty_score)\n            })\n        \n        return segments\n    \n    def _analyze_segment(self, segment_text: str) -> Dict[str, Any]:\n        \"\"\"Analyze individual content segment\"\"\"\n        words = segment_text.split()\n        \n        # Extract key concepts (simplified)\n        important_words = [w for w in words if len(w) > 5 and w.lower() not in self.stop_words]\n        word_freq = Counter(important_words)\n        key_concepts = [word for word, freq in word_freq.most_common(5)]\n        \n        # Calculate segment difficulty\n        difficulty = self._calculate_segment_difficulty(segment_text)\n        \n        return {\n            'key_concepts': key_concepts,\n            'difficulty': difficulty\n        }\n    \n    def _calculate_advanced_difficulty(self, text: str, words: List[str], sentences: List[str]) -> float:\n        \"\"\"Calculate advanced difficulty score\"\"\"\n        if not words or not sentences:\n            return 0.5\n        \n        # Multiple difficulty factors\n        factors = []\n        \n        # 1. Average sentence length\n        avg_sentence_length = len(words) / len(sentences)\n        factors.append(min(1.0, avg_sentence_length / 25.0))  # Normalize to 25 words max\n        \n        # 2. Average word length\n        avg_word_length = sum(len(word) for word in words) / len(words)\n        factors.append(min(1.0, (avg_word_length - 3) / 5.0))  # Normalize to 3-8 chars\n        \n        # 3. Complex word ratio\n        complex_words = [w for w in words if len(w) > 6]\n        factors.append(len(complex_words) / len(words))\n        \n        # 4. Technical term density\n        technical_terms = self._identify_technical_terms(words)\n        factors.append(min(1.0, len(technical_terms) / (len(words) / 100)))  # Per 100 words\n        \n        # 5. Syllable complexity\n        total_syllables = sum(self._count_syllables(word) for word in words)\n        avg_syllables = total_syllables / len(words)\n        factors.append(min(1.0, (avg_syllables - 1) / 2.0))  # Normalize to 1-3 syllables\n        \n        # Weighted average\n        weights = [0.2, 0.15, 0.25, 0.2, 0.2]\n        difficulty = sum(f * w for f, w in zip(factors, weights))\n        \n        return min(1.0, max(0.0, difficulty))\n    \n    def _identify_technical_terms(self, words: List[str]) -> List[str]:\n        \"\"\"Identify technical terms in the text\"\"\"\n        # Simple heuristics for technical terms\n        technical_terms = []\n        \n        for word in words:\n            word_lower = word.lower()\n            # Skip if it's a common word\n            if word_lower in self.stop_words:\n                continue\n            \n            # Heuristics for technical terms\n            if (len(word) > 8 or  # Long words\n                word.isupper() or  # Acronyms\n                '_' in word or  # Underscore terms\n                any(char.isdigit() for char in word) or  # Contains numbers\n                word.endswith(('tion', 'sion', 'ment', 'ness', 'ity', 'ism'))):  # Technical suffixes\n                technical_terms.append(word)\n        \n        return list(set(technical_terms))  # Remove duplicates\n    \n    def _calculate_content_density(self, text: str) -> float:\n        \"\"\"Calculate information density of content\"\"\"\n        words = text.split()\n        if not words:\n            return 0.0\n        \n        # Information markers\n        info_words = ['however', 'therefore', 'because', 'although', 'moreover', 'furthermore']\n        info_count = sum(1 for word in words if word.lower() in info_words)\n        \n        # Question marks (indicate complexity)\n        question_count = text.count('?')\n        \n        # Numbers and data points\n        number_count = sum(1 for word in words if any(char.isdigit() for char in word))\n        \n        # Calculate density score\n        density = (info_count + question_count + number_count) / len(words)\n        return min(1.0, density * 10)  # Scale to 0-1 range\n    \n    def _analyze_structural_complexity(self, paragraphs: List[str]) -> float:\n        \"\"\"Analyze structural complexity of the document\"\"\"\n        if not paragraphs:\n            return 0.0\n        \n        # Variation in paragraph lengths\n        para_lengths = [len(p.split()) for p in paragraphs]\n        if not para_lengths:\n            return 0.0\n        \n        avg_length = sum(para_lengths) / len(para_lengths)\n        variance = sum((l - avg_length) ** 2 for l in para_lengths) / len(para_lengths)\n        \n        # Normalize structural complexity\n        complexity = min(1.0, variance / (avg_length ** 2) if avg_length > 0 else 0)\n        return complexity\n    \n    def _identify_topics(self, keywords: List[tuple]) -> List[Dict[str, Any]]:\n        \"\"\"Identify topics from keywords (simplified clustering)\"\"\"\n        if not keywords:\n            return []\n        \n        # Simple topic identification based on keyword co-occurrence\n        # In a real implementation, this would use more sophisticated NLP\n        topics = []\n        used_words = set()\n        \n        for word, score in keywords[:10]:  # Top 10 keywords\n            if word not in used_words:\n                # Create a topic centered around this keyword\n                topic_words = [word]\n                used_words.add(word)\n                \n                # Find related words (simple similarity based on shared characters)\n                for other_word, other_score in keywords:\n                    if other_word not in used_words and len(set(word) & set(other_word)) >= 3:\n                        topic_words.append(other_word)\n                        used_words.add(other_word)\n                        if len(topic_words) >= 3:\n                            break\n                \n                topics.append({\n                    'topic_name': word.capitalize(),\n                    'keywords': topic_words,\n                    'relevance_score': round(score, 3)\n                })\n                \n                if len(topics) >= 5:  # Limit to 5 topics\n                    break\n        \n        return topics\n    \n    def _calculate_segment_difficulty(self, segment: str) -> float:\n        \"\"\"Calculate difficulty for a text segment\"\"\"\n        words = segment.split()\n        if not words:\n            return 0.5\n        \n        # Simple difficulty calculation for segments\n        complex_words = [w for w in words if len(w) > 6]\n        complexity_ratio = len(complex_words) / len(words)\n        \n        sentences = re.split(r'[.!?]+', segment)\n        sentences = [s.strip() for s in sentences if s.strip()]\n        avg_sentence_length = len(words) / len(sentences) if sentences else 0\n        \n        # Combine factors\n        difficulty = (complexity_ratio * 0.6) + min(1.0, avg_sentence_length / 20.0) * 0.4\n        return min(1.0, max(0.0, difficulty))\n    \n    def _estimate_cognitive_load(self, text: str, base_difficulty: float) -> float:\n        \"\"\"Estimate cognitive load for a text segment\"\"\"\n        words = text.split()\n        \n        # Factors affecting cognitive load\n        word_count_factor = min(1.0, len(words) / 500.0)  # More words = higher load\n        difficulty_factor = base_difficulty\n        \n        # Information density factor\n        info_density = self._calculate_content_density(text)\n        \n        # Combine factors\n        cognitive_load = (word_count_factor * 0.3) + (difficulty_factor * 0.5) + (info_density * 0.2)\n        return min(1.0, cognitive_load)\n    \n    def _count_syllables(self, word: str) -> int:\n        \"\"\"Count syllables in a word (improved algorithm)\"\"\"\n        word = word.lower().strip('.,!?;:\"')\n        if not word:\n            return 0\n        \n        vowels = 'aeiouy'\n        syllable_count = 0\n        previous_was_vowel = False\n        \n        for i, char in enumerate(word):\n            is_vowel = char in vowels\n            if is_vowel and not previous_was_vowel:\n                syllable_count += 1\n            previous_was_vowel = is_vowel\n        \n        # Handle silent 'e'\n        if word.endswith('e') and syllable_count > 1:\n            syllable_count -= 1\n        \n        # Handle 'le' endings\n        if word.endswith('le') and len(word) > 2 and word[-3] not in vowels:\n            syllable_count += 1\n        \n        return max(1, syllable_count)\n    \n    def _estimate_reading_time(self, word_count: int, reading_speed: float = 200.0) -> float:\n        \"\"\"Estimate reading time with improved accuracy\"\"\"\n        if word_count <= 0:\n            return 0.0\n        return round(word_count / reading_speed, 2)\n    \n    def _get_readability_level(self, difficulty_score: float) -> str:\n        \"\"\"Convert difficulty score to readability level\"\"\"\n        if difficulty_score <= 0.2:\n            return \"Very Easy\"\n        elif difficulty_score <= 0.4:\n            return \"Easy\"\n        elif difficulty_score <= 0.6:\n            return \"Moderate\"\n        elif difficulty_score <= 0.8:\n            return \"Difficult\"\n        else:\n            return \"Very Difficult\"","size_bytes":30348},"services/learning_analytics.py":{"content":"\"\"\"\nEnhanced Learning Analytics Service\nImplements comprehensive learning analytics with predictive modeling\n\"\"\"\n\nfrom datetime import datetime, timedelta\nfrom typing import Dict, Any, List, Optional, Tuple\nimport math\nimport numpy as np\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy import func, and_\nfrom collections import defaultdict\nfrom models import User, Performance, StudySession, Quiz, Material, Schedule\n\nclass LearningAnalytics:\n    \"\"\"\n    Advanced learning analytics service with ML-powered insights\n    Provides comprehensive analysis of learning patterns and performance prediction\n    \"\"\"\n    \n    def __init__(self, db: Session):\n        self.db = db\n        # Analytics model parameters\n        self.analytics_params = {\n            'learning_velocity_weights': [0.4, 0.3, 0.2, 0.1],  # Weighted recent performance\n            'retention_prediction_threshold': 0.7,\n            'cognitive_load_optimal_range': (0.4, 0.7),\n            'performance_trend_window': 14,  # Days\n            'confidence_threshold': 0.8\n        }\n    \n    def initialize_material_baseline(\n        self,\n        user_id: int,\n        content_analysis: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Initialize learning analytics baseline for new material\n        \n        Args:\n            user_id: ID of the user\n            content_analysis: Content analysis from document processor\n            \n        Returns:\n            Baseline metrics for learning analytics\n        \"\"\"\n        try:\n            # Get user's historical learning profile\n            user_profile = self._get_comprehensive_user_profile(user_id)\n            \n            # Predict initial learning metrics based on content and user profile\n            predicted_metrics = self._predict_initial_learning_metrics(\n                content_analysis, user_profile\n            )\n            \n            # Calculate expected learning trajectory\n            learning_trajectory = self._calculate_expected_trajectory(\n                content_analysis, user_profile, predicted_metrics\n            )\n            \n            # Set up performance monitoring baselines\n            monitoring_baselines = self._setup_monitoring_baselines(\n                user_profile, content_analysis\n            )\n            \n            return {\n                'success': True,\n                'baseline_metrics': {\n                    'predicted_completion_time': predicted_metrics['completion_time'],\n                    'expected_retention_rate': predicted_metrics['retention_rate'],\n                    'estimated_sessions_needed': predicted_metrics['sessions_needed'],\n                    'predicted_difficulty_adaptation': predicted_metrics['difficulty_adaptation']\n                },\n                'learning_trajectory': learning_trajectory,\n                'monitoring_baselines': monitoring_baselines,\n                'initialization_metadata': {\n                    'initialized_at': datetime.utcnow().isoformat(),\n                    'content_difficulty': content_analysis.get('estimated_difficulty', 0.5),\n                    'user_experience_level': user_profile['experience_level']\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Baseline initialization failed: {str(e)}'\n            }\n    \n    def analyze_learning_patterns(\n        self,\n        user_id: int,\n        material_id: int,\n        analysis_window_days: int = 30\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Comprehensive analysis of user learning patterns\n        \n        Args:\n            user_id: ID of the user\n            material_id: ID of the material\n            analysis_window_days: Analysis window in days\n            \n        Returns:\n            Detailed learning pattern analysis\n        \"\"\"\n        try:\n            # Get comprehensive learning data\n            learning_data = self._get_comprehensive_learning_data(\n                user_id, material_id, analysis_window_days\n            )\n            \n            # Analyze performance patterns\n            performance_patterns = self._analyze_performance_patterns(learning_data['performances'])\n            \n            # Analyze study behavior patterns\n            behavior_patterns = self._analyze_study_behavior_patterns(learning_data['study_sessions'])\n            \n            # Analyze temporal patterns\n            temporal_patterns = self._analyze_temporal_learning_patterns(learning_data)\n            \n            # Calculate learning efficiency metrics\n            efficiency_metrics = self._calculate_learning_efficiency(learning_data)\n            \n            # Identify learning strengths and weaknesses\n            strengths_weaknesses = self._identify_strengths_weaknesses(\n                performance_patterns, behavior_patterns\n            )\n            \n            # Predict difficulty progression\n            difficulty_progression = self._predict_difficulty_progression(\n                performance_patterns, material_id\n            )\n            \n            # Calculate overall learning health score\n            learning_health_score = self._calculate_learning_health_score(\n                performance_patterns, behavior_patterns, efficiency_metrics\n            )\n            \n            return {\n                'success': True,\n                'performance_patterns': performance_patterns,\n                'behavior_patterns': behavior_patterns,\n                'temporal_patterns': temporal_patterns,\n                'efficiency_metrics': efficiency_metrics,\n                'strengths_weaknesses': strengths_weaknesses,\n                'difficulty_progression': difficulty_progression,\n                'learning_health_score': learning_health_score,\n                'analysis_metadata': {\n                    'analysis_date': datetime.utcnow().isoformat(),\n                    'data_points_analyzed': len(learning_data['performances']) + len(learning_data['study_sessions']),\n                    'analysis_confidence': self._calculate_analysis_confidence(learning_data)\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Learning pattern analysis failed: {str(e)}'\n            }\n    \n    def calculate_cognitive_load_optimization(\n        self,\n        user_id: int,\n        current_performance: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Calculate cognitive load optimization recommendations\n        \n        Args:\n            user_id: ID of the user\n            current_performance: Current performance analysis\n            \n        Returns:\n            Cognitive load optimization recommendations\n        \"\"\"\n        try:\n            # Get user's cognitive profile\n            cognitive_profile = self._get_cognitive_profile(user_id)\n            \n            # Analyze current cognitive load\n            current_load_analysis = self._analyze_current_cognitive_load(\n                current_performance, cognitive_profile\n            )\n            \n            # Calculate optimal cognitive load distribution\n            optimal_distribution = self._calculate_optimal_cognitive_distribution(\n                cognitive_profile, current_load_analysis\n            )\n            \n            # Generate load balancing recommendations\n            load_recommendations = self._generate_cognitive_load_recommendations(\n                current_load_analysis, optimal_distribution\n            )\n            \n            # Calculate session timing optimizations\n            timing_optimizations = self._optimize_session_timing(\n                cognitive_profile, current_load_analysis\n            )\n            \n            return {\n                'success': True,\n                'current_load_analysis': current_load_analysis,\n                'optimal_distribution': optimal_distribution,\n                'recommendations': load_recommendations,\n                'timing_optimizations': timing_optimizations,\n                'optimization_metadata': {\n                    'optimization_date': datetime.utcnow().isoformat(),\n                    'cognitive_capacity': cognitive_profile['capacity'],\n                    'optimization_confidence': current_load_analysis['confidence']\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Cognitive load optimization failed: {str(e)}'\n            }\n    \n    def predict_learning_velocity(\n        self,\n        user_id: int,\n        current_performance: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Predict learning velocity and completion timeline\n        \n        Args:\n            user_id: ID of the user\n            current_performance: Current performance data\n            \n        Returns:\n            Learning velocity predictions\n        \"\"\"\n        try:\n            # Get historical velocity data\n            velocity_history = self._get_learning_velocity_history(user_id)\n            \n            # Calculate current velocity trend\n            current_velocity = self._calculate_current_velocity(\n                velocity_history, current_performance\n            )\n            \n            # Predict future velocity based on patterns\n            velocity_prediction = self._predict_future_velocity(\n                velocity_history, current_velocity, current_performance\n            )\n            \n            # Calculate completion timeline predictions\n            completion_predictions = self._predict_completion_timeline(\n                velocity_prediction, current_performance\n            )\n            \n            # Identify velocity optimization opportunities\n            optimization_opportunities = self._identify_velocity_optimizations(\n                velocity_history, current_velocity\n            )\n            \n            return {\n                'success': True,\n                'current_velocity': current_velocity,\n                'velocity_prediction': velocity_prediction,\n                'completion_predictions': completion_predictions,\n                'optimization_opportunities': optimization_opportunities,\n                'velocity_metadata': {\n                    'prediction_date': datetime.utcnow().isoformat(),\n                    'historical_data_points': len(velocity_history),\n                    'prediction_confidence': velocity_prediction['confidence']\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Learning velocity prediction failed: {str(e)}'\n            }\n    \n    def get_comprehensive_learning_history(\n        self,\n        user_id: int,\n        material_id: int\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Get comprehensive learning history for a user and material\n        \n        Args:\n            user_id: ID of the user\n            material_id: ID of the material\n            \n        Returns:\n            Comprehensive learning history\n        \"\"\"\n        try:\n            # Get all performance data\n            performances = self._get_detailed_performance_history(user_id, material_id)\n            \n            # Get all study sessions\n            study_sessions = self._get_detailed_study_sessions(user_id, material_id)\n            \n            # Calculate learning milestones\n            milestones = self._identify_learning_milestones(performances, study_sessions)\n            \n            # Analyze learning progression\n            progression_analysis = self._analyze_learning_progression(\n                performances, study_sessions, milestones\n            )\n            \n            # Calculate comprehensive metrics\n            comprehensive_metrics = self._calculate_comprehensive_metrics(\n                performances, study_sessions\n            )\n            \n            return {\n                'success': True,\n                'performances': performances,\n                'study_sessions': study_sessions,\n                'milestones': milestones,\n                'progression_analysis': progression_analysis,\n                'comprehensive_metrics': comprehensive_metrics,\n                'history_metadata': {\n                    'data_span_days': self._calculate_data_span(performances, study_sessions),\n                    'total_learning_time': comprehensive_metrics['total_study_time'],\n                    'data_quality_score': self._assess_data_quality(performances, study_sessions)\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Learning history retrieval failed: {str(e)}'\n            }\n    \n    def get_user_learning_profile(self, user_id: int) -> Dict[str, Any]:\n        \"\"\"\n        Get comprehensive user learning profile\n        \n        Args:\n            user_id: ID of the user\n            \n        Returns:\n            Comprehensive user learning profile\n        \"\"\"\n        try:\n            # Get basic user data\n            user = self.db.query(User).filter(User.id == user_id).first()\n            if not user:\n                return self._get_default_learning_profile()\n            \n            # Calculate learning characteristics\n            learning_characteristics = self._calculate_learning_characteristics(user_id)\n            \n            # Analyze preferred learning patterns\n            learning_preferences = self._analyze_learning_preferences(user_id)\n            \n            # Calculate performance consistency\n            performance_consistency = self._calculate_performance_consistency(user_id)\n            \n            # Determine optimal difficulty level\n            optimal_difficulty = self._determine_optimal_difficulty(user_id)\n            \n            return {\n                'user_id': user_id,\n                'reading_speed': getattr(user, 'average_reading_speed', 200),\n                'current_level': learning_characteristics['current_level'],\n                'learning_characteristics': learning_characteristics,\n                'learning_preferences': learning_preferences,\n                'performance_consistency': performance_consistency,\n                'optimal_difficulty': optimal_difficulty,\n                'cognitive_profile': {\n                    'capacity': getattr(user, 'cognitive_load_limit', 0.8),\n                    'attention_span': learning_characteristics['attention_span'],\n                    'processing_speed': learning_characteristics['processing_speed']\n                },\n                'difficulty_tolerance': optimal_difficulty\n            }\n            \n        except Exception as e:\n            return self._get_default_learning_profile()\n    \n    def optimize_session_cognitive_load(\n        self,\n        user_id: int,\n        content_sections: List[Dict[str, Any]],\n        available_time: int,\n        current_state: Optional[Dict[str, Any]] = None\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Optimize cognitive load for a specific study session\n        \n        Args:\n            user_id: ID of the user\n            content_sections: Content sections for the session\n            available_time: Available time in minutes\n            current_state: Current cognitive state\n            \n        Returns:\n            Cognitive load optimization plan\n        \"\"\"\n        try:\n            # Get user's cognitive profile\n            cognitive_profile = self._get_cognitive_profile(user_id)\n            \n            # Calculate load for each content section\n            section_loads = self._calculate_section_cognitive_loads(\n                content_sections, cognitive_profile\n            )\n            \n            # Optimize section sequencing\n            optimized_sequence = self._optimize_section_sequence(\n                section_loads, available_time, cognitive_profile\n            )\n            \n            # Calculate optimal break intervals\n            break_intervals = self._calculate_optimal_breaks(\n                optimized_sequence, cognitive_profile, available_time\n            )\n            \n            # Generate load management strategies\n            load_strategies = self._generate_load_management_strategies(\n                optimized_sequence, cognitive_profile, current_state\n            )\n            \n            return {\n                'success': True,\n                'section_loads': section_loads,\n                'optimized_sequence': optimized_sequence,\n                'break_intervals': break_intervals,\n                'load_strategies': load_strategies,\n                'total_estimated_load': sum(s['cognitive_load'] for s in optimized_sequence),\n                'optimization_metadata': {\n                    'optimization_method': 'cognitive_load_balancing',\n                    'user_capacity': cognitive_profile['capacity'],\n                    'session_duration': available_time\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Session cognitive load optimization failed: {str(e)}'\n            }\n    \n    # Helper methods for learning analytics\n    \n    def _get_comprehensive_user_profile(self, user_id: int) -> Dict[str, Any]:\n        \"\"\"Get comprehensive user profile for analytics\"\"\"\n        user = self.db.query(User).filter(User.id == user_id).first()\n        \n        # Get performance statistics\n        avg_performance = self.db.query(func.avg(Performance.score)).filter(\n            Performance.user_id == user_id\n        ).scalar() or 0.7\n        \n        # Get study session statistics\n        total_sessions = self.db.query(StudySession).filter(\n            StudySession.user_id == user_id\n        ).count()\n        \n        # Calculate experience level\n        experience_level = min(1.0, total_sessions / 50.0)  # 50 sessions = experienced\n        \n        return {\n            'user_id': user_id,\n            'average_performance': avg_performance,\n            'total_sessions': total_sessions,\n            'experience_level': experience_level,\n            'reading_speed': getattr(user, 'average_reading_speed', 200) if user else 200,\n            'retention_rate': getattr(user, 'retention_rate', 0.7) if user else 0.7,\n            'cognitive_capacity': getattr(user, 'cognitive_load_limit', 0.8) if user else 0.8\n        }\n    \n    def _predict_initial_learning_metrics(\n        self,\n        content_analysis: Dict[str, Any],\n        user_profile: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"Predict initial learning metrics for new material\"\"\"\n        difficulty = content_analysis.get('estimated_difficulty', 0.5)\n        word_count = content_analysis.get('word_count', 1000)\n        \n        # Predict completion time\n        base_time = word_count / user_profile['reading_speed']\n        difficulty_multiplier = 1 + (difficulty * 0.5)\n        experience_adjustment = 1 - (user_profile['experience_level'] * 0.2)\n        completion_time = base_time * difficulty_multiplier * experience_adjustment\n        \n        # Predict retention rate\n        base_retention = user_profile['retention_rate']\n        difficulty_penalty = difficulty * 0.15\n        retention_rate = max(0.5, base_retention - difficulty_penalty)\n        \n        # Predict sessions needed\n        base_sessions = max(3, int(completion_time / 60))  # 1 hour per session\n        sessions_needed = int(base_sessions * (1 + difficulty * 0.3))\n        \n        # Predict difficulty adaptation\n        adaptation_rate = user_profile['experience_level'] * 0.3 + 0.7\n        \n        return {\n            'completion_time': round(completion_time, 1),\n            'retention_rate': round(retention_rate, 3),\n            'sessions_needed': sessions_needed,\n            'difficulty_adaptation': round(adaptation_rate, 3)\n        }\n    \n    def _calculate_expected_trajectory(\n        self,\n        content_analysis: Dict[str, Any],\n        user_profile: Dict[str, Any],\n        predicted_metrics: Dict[str, Any]\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Calculate expected learning trajectory\"\"\"\n        trajectory = []\n        sessions = predicted_metrics['sessions_needed']\n        \n        for session in range(1, sessions + 1):\n            # Predict performance for each session\n            progress_factor = session / sessions\n            initial_performance = 0.3 + (user_profile['experience_level'] * 0.2)\n            \n            # Learning curve (exponential improvement with plateau)\n            performance = initial_performance + (0.6 * (1 - math.exp(-progress_factor * 3)))\n            \n            # Adjust for difficulty\n            difficulty = content_analysis.get('estimated_difficulty', 0.5)\n            adjusted_performance = performance * (1 - difficulty * 0.2)\n            \n            trajectory.append({\n                'session_number': session,\n                'expected_performance': round(min(0.9, adjusted_performance), 3),\n                'expected_retention': round(predicted_metrics['retention_rate'] * \n                                          (0.8 + progress_factor * 0.2), 3),\n                'confidence': round(0.9 - (session * 0.02), 2)  # Decreasing confidence for future\n            })\n        \n        return trajectory\n    \n    def _setup_monitoring_baselines(\n        self,\n        user_profile: Dict[str, Any],\n        content_analysis: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"Setup monitoring baselines for performance tracking\"\"\"\n        return {\n            'performance_threshold': max(0.6, user_profile['average_performance'] - 0.1),\n            'retention_threshold': max(0.5, user_profile['retention_rate'] - 0.1),\n            'cognitive_load_threshold': user_profile['cognitive_capacity'] * 0.8,\n            'session_duration_optimal': 45,  # minutes\n            'break_frequency_optimal': 25,  # minutes between breaks\n            'alert_triggers': {\n                'performance_decline': 0.15,  # 15% decline triggers alert\n                'retention_decline': 0.1,    # 10% decline triggers alert\n                'cognitive_overload': 0.9    # 90% of capacity triggers alert\n            }\n        }\n    \n    def _get_comprehensive_learning_data(\n        self,\n        user_id: int,\n        material_id: int,\n        days: int\n    ) -> Dict[str, Any]:\n        \"\"\"Get comprehensive learning data for analysis\"\"\"\n        cutoff_date = datetime.utcnow() - timedelta(days=days)\n        \n        # Get performance data\n        performances = self.db.query(Performance).join(Quiz).filter(\n            Performance.user_id == user_id,\n            Quiz.material_id == material_id,\n            Performance.created_at >= cutoff_date\n        ).order_by(Performance.created_at).all()\n        \n        # Get study sessions\n        study_sessions = self.db.query(StudySession).join(Schedule).filter(\n            StudySession.user_id == user_id,\n            Schedule.material_id == material_id,\n            StudySession.start_time >= cutoff_date\n        ).order_by(StudySession.start_time).all()\n        \n        return {\n            'performances': performances,\n            'study_sessions': study_sessions,\n            'analysis_period': days\n        }\n    \n    def _analyze_performance_patterns(self, performances: List[Performance]) -> Dict[str, Any]:\n        \"\"\"Analyze performance patterns from quiz data\"\"\"\n        if not performances:\n            return self._get_default_performance_patterns()\n        \n        scores = [p.score for p in performances]\n        times = [p.time_taken for p in performances if p.time_taken]\n        \n        # Calculate basic statistics\n        avg_score = sum(scores) / len(scores)\n        score_trend = self._calculate_trend(scores)\n        consistency = 1 - (np.std(scores) if len(scores) > 1 else 0)\n        \n        # Analyze improvement rate\n        if len(scores) >= 4:\n            first_half = scores[:len(scores)//2]\n            second_half = scores[len(scores)//2:]\n            improvement_rate = (sum(second_half)/len(second_half)) - (sum(first_half)/len(first_half))\n        else:\n            improvement_rate = 0\n        \n        # Analyze time efficiency\n        time_efficiency = self._analyze_time_efficiency(times, scores)\n        \n        return {\n            'average_score': round(avg_score, 3),\n            'score_trend': score_trend,\n            'consistency_score': round(consistency, 3),\n            'improvement_rate': round(improvement_rate, 3),\n            'time_efficiency': time_efficiency,\n            'total_assessments': len(performances),\n            'performance_volatility': round(np.std(scores) if len(scores) > 1 else 0, 3)\n        }\n    \n    def _analyze_study_behavior_patterns(self, study_sessions: List[StudySession]) -> Dict[str, Any]:\n        \"\"\"Analyze study behavior patterns\"\"\"\n        if not study_sessions:\n            return self._get_default_behavior_patterns()\n        \n        # Calculate session statistics\n        durations = [s.duration_minutes for s in study_sessions if s.duration_minutes]\n        focus_scores = [s.focus_score for s in study_sessions if s.focus_score is not None]\n        \n        # Analyze study timing patterns\n        study_times = [s.start_time.hour for s in study_sessions]\n        preferred_time = max(set(study_times), key=study_times.count) if study_times else 9\n        \n        # Calculate engagement metrics\n        avg_duration = sum(durations) / len(durations) if durations else 0\n        avg_focus = sum(focus_scores) / len(focus_scores) if focus_scores else 0.5\n        \n        # Analyze consistency\n        session_consistency = self._analyze_session_consistency(study_sessions)\n        \n        return {\n            'average_session_duration': round(avg_duration, 1),\n            'average_focus_score': round(avg_focus, 3),\n            'preferred_study_time': preferred_time,\n            'session_consistency': session_consistency,\n            'total_study_time': sum(durations),\n            'total_sessions': len(study_sessions),\n            'engagement_level': self._calculate_engagement_level(focus_scores, durations)\n        }\n    \n    def _analyze_temporal_learning_patterns(self, learning_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Analyze temporal patterns in learning\"\"\"\n        performances = learning_data['performances']\n        study_sessions = learning_data['study_sessions']\n        \n        # Analyze learning by day of week\n        weekday_performance = defaultdict(list)\n        for p in performances:\n            weekday = p.created_at.weekday()\n            weekday_performance[weekday].append(p.score)\n        \n        # Analyze learning by time of day\n        hour_performance = defaultdict(list)\n        for p in performances:\n            hour = p.created_at.hour\n            hour_performance[hour].append(p.score)\n        \n        # Find optimal learning times\n        best_weekday = max(weekday_performance.items(), \n                          key=lambda x: sum(x[1])/len(x[1]) if x[1] else 0)[0] if weekday_performance else 1\n        best_hour = max(hour_performance.items(),\n                       key=lambda x: sum(x[1])/len(x[1]) if x[1] else 0)[0] if hour_performance else 9\n        \n        return {\n            'best_weekday': best_weekday,\n            'best_hour': best_hour,\n            'weekday_patterns': dict(weekday_performance),\n            'hourly_patterns': dict(hour_performance),\n            'learning_rhythm': self._identify_learning_rhythm(performances, study_sessions)\n        }\n    \n    def _calculate_learning_efficiency(self, learning_data: Dict[str, Any]) -> Dict[str, Any]:\n        \"\"\"Calculate learning efficiency metrics\"\"\"\n        performances = learning_data['performances']\n        study_sessions = learning_data['study_sessions']\n        \n        if not performances or not study_sessions:\n            return {'efficiency_score': 0.5, 'time_to_competency': 0}\n        \n        # Calculate score per unit time\n        total_study_time = sum(s.duration_minutes for s in study_sessions if s.duration_minutes)\n        avg_score = sum(p.score for p in performances) / len(performances)\n        \n        if total_study_time > 0:\n            efficiency_score = avg_score / (total_study_time / 60)  # Score per hour\n        else:\n            efficiency_score = 0\n        \n        # Calculate time to competency (score > 0.7)\n        competent_performances = [p for p in performances if p.score >= 0.7]\n        time_to_competency = 0\n        if competent_performances:\n            first_competent = min(competent_performances, key=lambda x: x.created_at)\n            first_session = min(study_sessions, key=lambda x: x.start_time)\n            time_to_competency = (first_competent.created_at - first_session.start_time).days\n        \n        return {\n            'efficiency_score': round(min(efficiency_score, 2.0), 3),  # Cap at 2.0\n            'time_to_competency': time_to_competency,\n            'total_study_time_hours': round(total_study_time / 60, 1),\n            'average_performance': round(avg_score, 3),\n            'learning_rate': self._calculate_learning_rate(performances)\n        }\n    \n    def _identify_strengths_weaknesses(\n        self,\n        performance_patterns: Dict[str, Any],\n        behavior_patterns: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"Identify learning strengths and weaknesses\"\"\"\n        strengths = []\n        weaknesses = []\n        \n        # Analyze performance strengths/weaknesses\n        if performance_patterns['average_score'] >= 0.8:\n            strengths.append('High performance consistency')\n        elif performance_patterns['average_score'] < 0.6:\n            weaknesses.append('Below average performance')\n        \n        if performance_patterns['improvement_rate'] > 0.1:\n            strengths.append('Strong learning progression')\n        elif performance_patterns['improvement_rate'] < -0.05:\n            weaknesses.append('Declining performance trend')\n        \n        if performance_patterns['consistency_score'] > 0.8:\n            strengths.append('Consistent performance')\n        elif performance_patterns['consistency_score'] < 0.6:\n            weaknesses.append('Inconsistent performance')\n        \n        # Analyze behavior strengths/weaknesses\n        if behavior_patterns['average_focus_score'] > 0.7:\n            strengths.append('High focus and attention')\n        elif behavior_patterns['average_focus_score'] < 0.5:\n            weaknesses.append('Attention and focus challenges')\n        \n        if behavior_patterns['session_consistency']['consistency_score'] > 0.7:\n            strengths.append('Regular study habits')\n        elif behavior_patterns['session_consistency']['consistency_score'] < 0.5:\n            weaknesses.append('Irregular study schedule')\n        \n        return {\n            'strengths': strengths,\n            'weaknesses': weaknesses,\n            'improvement_priorities': self._prioritize_improvements(weaknesses),\n            'strength_leverage_opportunities': self._identify_leverage_opportunities(strengths)\n        }\n    \n    def _predict_difficulty_progression(\n        self,\n        performance_patterns: Dict[str, Any],\n        material_id: int\n    ) -> Dict[str, Any]:\n        \"\"\"Predict optimal difficulty progression\"\"\"\n        current_performance = performance_patterns['average_score']\n        improvement_rate = performance_patterns['improvement_rate']\n        consistency = performance_patterns['consistency_score']\n        \n        # Calculate optimal difficulty\n        if current_performance >= 0.8 and consistency > 0.7:\n            recommended_difficulty = 'increase'\n            target_difficulty = min(1.0, 0.7 + current_performance * 0.3)\n        elif current_performance < 0.6 or consistency < 0.5:\n            recommended_difficulty = 'decrease'\n            target_difficulty = max(0.3, current_performance * 0.8)\n        else:\n            recommended_difficulty = 'maintain'\n            target_difficulty = 0.5 + current_performance * 0.2\n        \n        return {\n            'current_optimal_difficulty': round(target_difficulty, 2),\n            'recommendation': recommended_difficulty,\n            'progression_rate': 'gradual' if consistency > 0.7 else 'careful',\n            'confidence': round(consistency * 0.8 + (1 - abs(improvement_rate)) * 0.2, 2)\n        }\n    \n    def _calculate_learning_health_score(\n        self,\n        performance_patterns: Dict[str, Any],\n        behavior_patterns: Dict[str, Any],\n        efficiency_metrics: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"Calculate overall learning health score\"\"\"\n        # Weight different components\n        performance_weight = 0.4\n        behavior_weight = 0.3\n        efficiency_weight = 0.3\n        \n        # Normalize scores to 0-1 range\n        performance_score = performance_patterns['average_score']\n        behavior_score = (behavior_patterns['average_focus_score'] + \n                         behavior_patterns['session_consistency']['consistency_score']) / 2\n        efficiency_score = min(1.0, efficiency_metrics['efficiency_score'] / 2.0)\n        \n        # Calculate weighted health score\n        health_score = (performance_score * performance_weight + \n                       behavior_score * behavior_weight + \n                       efficiency_score * efficiency_weight)\n        \n        # Determine health category\n        if health_score >= 0.8:\n            health_category = 'excellent'\n        elif health_score >= 0.7:\n            health_category = 'good'\n        elif health_score >= 0.6:\n            health_category = 'fair'\n        else:\n            health_category = 'needs_improvement'\n        \n        return {\n            'overall_score': round(health_score, 3),\n            'category': health_category,\n            'component_scores': {\n                'performance': round(performance_score, 3),\n                'behavior': round(behavior_score, 3),\n                'efficiency': round(efficiency_score, 3)\n            },\n            'improvement_potential': round((1 - health_score) * 100, 1)  # Percentage improvement possible\n        }\n    \n    # Additional helper methods would continue here...\n    # This represents the core structure of the LearningAnalytics service\n    \n    def _get_default_learning_profile(self) -> Dict[str, Any]:\n        \"\"\"Return default learning profile for new users\"\"\"\n        return {\n            'reading_speed': 200,\n            'current_level': 0.5,\n            'difficulty_tolerance': 0.5,\n            'cognitive_profile': {\n                'capacity': 0.8,\n                'attention_span': 45,\n                'processing_speed': 0.7\n            }\n        }\n    \n    def _calculate_analysis_confidence(self, learning_data: Dict[str, Any]) -> float:\n        \"\"\"Calculate confidence in analysis based on data quality\"\"\"\n        performances = learning_data['performances']\n        study_sessions = learning_data['study_sessions']\n        \n        data_points = len(performances) + len(study_sessions)\n        if data_points >= 10:\n            return 0.9\n        elif data_points >= 5:\n            return 0.7\n        elif data_points >= 2:\n            return 0.5\n        else:\n            return 0.3\n    \n    def _get_default_performance_patterns(self) -> Dict[str, Any]:\n        \"\"\"Return default performance patterns\"\"\"\n        return {\n            'average_score': 0.5,\n            'score_trend': 'stable',\n            'consistency_score': 0.5,\n            'improvement_rate': 0.0,\n            'time_efficiency': {'efficiency_score': 0.5},\n            'total_assessments': 0,\n            'performance_volatility': 0.0\n        }\n    \n    def _get_default_behavior_patterns(self) -> Dict[str, Any]:\n        \"\"\"Return default behavior patterns\"\"\"\n        return {\n            'average_session_duration': 30,\n            'average_focus_score': 0.5,\n            'preferred_study_time': 9,\n            'session_consistency': {'consistency_score': 0.5},\n            'total_study_time': 0,\n            'total_sessions': 0,\n            'engagement_level': 0.5\n        }\n    \n    def _calculate_trend(self, values: List[float]) -> str:\n        \"\"\"Calculate trend direction from a list of values\"\"\"\n        if len(values) < 3:\n            return 'stable'\n        \n        # Simple linear trend calculation\n        x = list(range(len(values)))\n        n = len(values)\n        \n        sum_x = sum(x)\n        sum_y = sum(values)\n        sum_xy = sum(x[i] * values[i] for i in range(n))\n        sum_x2 = sum(x[i] ** 2 for i in range(n))\n        \n        slope = (n * sum_xy - sum_x * sum_y) / (n * sum_x2 - sum_x ** 2)\n        \n        if slope > 0.05:\n            return 'improving'\n        elif slope < -0.05:\n            return 'declining'\n        else:\n            return 'stable'","size_bytes":36960},"services/ml_service.py":{"content":"\"\"\"\nMain ML Service for orchestrating all machine learning operations\nImplements the ML pipeline described in the system architecture\n\"\"\"\n\nfrom datetime import datetime, timedelta\nfrom typing import Dict, Any, List, Optional\nimport math\nimport numpy as np\nfrom sqlalchemy.orm import Session\nfrom .document_processor import DocumentProcessor\nfrom .quiz_generator import QuizGenerator  \nfrom .spaced_repetition_scheduler import SpacedRepetitionScheduler\nfrom .learning_analytics import LearningAnalytics\n\nclass MLService:\n    \"\"\"\n    Main orchestration service for all ML operations\n    Coordinates document processing, quiz generation, scheduling, and analytics\n    \"\"\"\n    \n    def __init__(self, db: Session):\n        self.db = db\n        self.document_processor = DocumentProcessor()\n        self.quiz_generator = QuizGenerator(db)\n        self.scheduler = SpacedRepetitionScheduler(db)\n        self.analytics = LearningAnalytics(db)\n    \n    def process_learning_material(\n        self,\n        user_id: int,\n        file_content: bytes,\n        filename: str,\n        target_completion_date: Optional[datetime] = None\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Complete ML pipeline for processing new learning material\n        \n        Args:\n            user_id: ID of the user\n            file_content: Raw file content\n            filename: Name of the uploaded file\n            target_completion_date: Optional target completion date\n            \n        Returns:\n            Complete processing results with schedule and initial quiz\n        \"\"\"\n        try:\n            # Step 1: Document Processing Pipeline\n            doc_result = self.document_processor.process_document(file_content, filename)\n            if not doc_result['success']:\n                return doc_result\n            \n            # Step 2: Content Analysis and Segmentation\n            content_analysis = self.document_processor.analyze_content_structure(\n                doc_result['full_text']\n            )\n            \n            # Step 3: Generate Initial Assessment Quiz\n            initial_quiz = self.quiz_generator.generate_adaptive_quiz(\n                text=doc_result['full_text'],\n                difficulty_level=content_analysis['estimated_difficulty'],\n                num_questions=5,\n                quiz_type='assessment'\n            )\n            \n            # Step 4: Create Personalized Study Schedule using HLR\n            if not target_completion_date:\n                target_completion_date = datetime.utcnow() + timedelta(days=14)\n                \n            schedule = self.scheduler.generate_hlr_schedule(\n                user_id=user_id,\n                content_analysis=content_analysis,\n                target_date=target_completion_date,\n                initial_difficulty=content_analysis['estimated_difficulty']\n            )\n            \n            # Step 5: Initialize Learning Analytics Baseline\n            baseline_metrics = self.analytics.initialize_material_baseline(\n                user_id=user_id,\n                content_analysis=content_analysis\n            )\n            \n            return {\n                'success': True,\n                'document_analysis': content_analysis,\n                'initial_quiz': initial_quiz,\n                'study_schedule': schedule,\n                'baseline_metrics': baseline_metrics,\n                'processing_metadata': {\n                    'processed_at': datetime.utcnow().isoformat(),\n                    'ml_version': '1.0',\n                    'pipeline_stages': ['document_processing', 'content_analysis', 'quiz_generation', 'hlr_scheduling', 'analytics_init']\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'ML pipeline failed: {str(e)}',\n                'stage': 'ml_orchestration'\n            }\n    \n    def adapt_learning_path(\n        self,\n        user_id: int,\n        material_id: int,\n        performance_data: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Adaptive learning path adjustment based on performance\n        Implements continuous optimization of the learning experience\n        \n        Args:\n            user_id: ID of the user\n            material_id: ID of the material\n            performance_data: Latest performance metrics\n            \n        Returns:\n            Updated learning path with adaptations\n        \"\"\"\n        try:\n            # Step 1: Analyze Current Performance Patterns\n            performance_analysis = self.analytics.analyze_learning_patterns(\n                user_id=user_id,\n                material_id=material_id\n            )\n            \n            # Step 2: Update Half-Life Regression Model\n            hlr_update = self.scheduler.update_hlr_model(\n                user_id=user_id,\n                material_id=material_id,\n                performance_data=performance_data\n            )\n            \n            # Step 3: Adaptive Schedule Optimization\n            schedule_adaptations = self.scheduler.optimize_schedule_intervals(\n                user_id=user_id,\n                material_id=material_id,\n                performance_analysis=performance_analysis\n            )\n            \n            # Step 4: Generate Adaptive Quizzes\n            adaptive_quizzes = self.quiz_generator.generate_adaptive_quiz_sequence(\n                user_id=user_id,\n                material_id=material_id,\n                difficulty_progression=performance_analysis['difficulty_progression']\n            )\n            \n            # Step 5: Cognitive Load Management\n            cognitive_load_adjustment = self.analytics.calculate_cognitive_load_optimization(\n                user_id=user_id,\n                current_performance=performance_analysis\n            )\n            \n            return {\n                'success': True,\n                'adaptations': {\n                    'performance_analysis': performance_analysis,\n                    'hlr_model_update': hlr_update,\n                    'schedule_changes': schedule_adaptations,\n                    'adaptive_quizzes': adaptive_quizzes,\n                    'cognitive_load_adjustments': cognitive_load_adjustment\n                },\n                'adaptation_metadata': {\n                    'adapted_at': datetime.utcnow().isoformat(),\n                    'adaptation_trigger': 'performance_feedback',\n                    'confidence_score': performance_analysis.get('confidence_score', 0.7)\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Adaptation pipeline failed: {str(e)}',\n                'stage': 'learning_adaptation'\n            }\n    \n    def predict_learning_outcomes(\n        self,\n        user_id: int,\n        material_id: int,\n        time_horizon_days: int = 30\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Predictive modeling for learning outcomes\n        Uses ML models to forecast user progress and retention\n        \n        Args:\n            user_id: ID of the user\n            material_id: ID of the material\n            time_horizon_days: Prediction horizon in days\n            \n        Returns:\n            Predicted learning outcomes and recommendations\n        \"\"\"\n        try:\n            # Get user's learning history\n            learning_history = self.analytics.get_comprehensive_learning_history(\n                user_id=user_id,\n                material_id=material_id\n            )\n            \n            # Predict retention rates using HLR\n            retention_predictions = self.scheduler.predict_retention_curve(\n                user_id=user_id,\n                material_id=material_id,\n                time_horizon=time_horizon_days\n            )\n            \n            # Predict optimal study intervals\n            interval_predictions = self.scheduler.predict_optimal_intervals(\n                user_id=user_id,\n                learning_history=learning_history\n            )\n            \n            # Predict learning velocity\n            velocity_prediction = self.analytics.predict_learning_velocity(\n                user_id=user_id,\n                current_performance=learning_history\n            )\n            \n            # Generate personalized recommendations\n            recommendations = self._generate_personalized_recommendations(\n                learning_history=learning_history,\n                retention_predictions=retention_predictions,\n                velocity_prediction=velocity_prediction\n            )\n            \n            return {\n                'success': True,\n                'predictions': {\n                    'retention_curve': retention_predictions,\n                    'optimal_intervals': interval_predictions,\n                    'learning_velocity': velocity_prediction,\n                    'completion_probability': self._calculate_completion_probability(\n                        velocity_prediction, time_horizon_days\n                    )\n                },\n                'recommendations': recommendations,\n                'prediction_metadata': {\n                    'model_version': '1.0',\n                    'prediction_date': datetime.utcnow().isoformat(),\n                    'confidence_interval': '95%',\n                    'time_horizon_days': time_horizon_days\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Prediction pipeline failed: {str(e)}',\n                'stage': 'learning_prediction'\n            }\n    \n    def optimize_study_session(\n        self,\n        user_id: int,\n        material_id: int,\n        available_time_minutes: int,\n        current_cognitive_state: Optional[Dict[str, Any]] = None\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Real-time study session optimization\n        Optimizes content selection and pacing for maximum learning efficiency\n        \n        Args:\n            user_id: ID of the user\n            material_id: ID of the material\n            available_time_minutes: Available study time\n            current_cognitive_state: Optional current cognitive state data\n            \n        Returns:\n            Optimized study session plan\n        \"\"\"\n        try:\n            # Get current user state and preferences\n            user_profile = self.analytics.get_user_learning_profile(user_id)\n            \n            # Analyze optimal content sections for this session\n            content_optimization = self.document_processor.optimize_content_selection(\n                material_id=material_id,\n                available_time=available_time_minutes,\n                user_reading_speed=user_profile['reading_speed'],\n                difficulty_preference=user_profile['difficulty_tolerance']\n            )\n            \n            # Optimize cognitive load for session\n            cognitive_optimization = self.analytics.optimize_session_cognitive_load(\n                user_id=user_id,\n                content_sections=content_optimization['recommended_sections'],\n                available_time=available_time_minutes,\n                current_state=current_cognitive_state\n            )\n            \n            # Generate session-specific quizzes\n            session_quizzes = self.quiz_generator.generate_session_quizzes(\n                content_sections=content_optimization['recommended_sections'],\n                user_performance_level=user_profile['current_level']\n            )\n            \n            # Create adaptive session timeline\n            session_timeline = self._create_adaptive_session_timeline(\n                content_sections=content_optimization['recommended_sections'],\n                quizzes=session_quizzes,\n                available_time=available_time_minutes,\n                cognitive_optimization=cognitive_optimization\n            )\n            \n            return {\n                'success': True,\n                'session_plan': {\n                    'recommended_sections': content_optimization['recommended_sections'],\n                    'quiz_checkpoints': session_quizzes,\n                    'session_timeline': session_timeline,\n                    'cognitive_load_plan': cognitive_optimization,\n                    'break_recommendations': self._calculate_optimal_breaks(available_time_minutes)\n                },\n                'optimization_metadata': {\n                    'optimized_at': datetime.utcnow().isoformat(),\n                    'optimization_factors': ['content_difficulty', 'cognitive_load', 'time_constraints', 'user_preferences']\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Session optimization failed: {str(e)}',\n                'stage': 'session_optimization'\n            }\n    \n    def _generate_personalized_recommendations(\n        self,\n        learning_history: Dict[str, Any],\n        retention_predictions: Dict[str, Any],\n        velocity_prediction: Dict[str, Any]\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Generate personalized study recommendations\"\"\"\n        recommendations = []\n        \n        # Retention-based recommendations\n        if retention_predictions.get('declining_sections'):\n            recommendations.append({\n                'type': 'retention_alert',\n                'priority': 'high',\n                'message': 'Some material sections may need review to prevent forgetting',\n                'action': 'schedule_review',\n                'sections': retention_predictions['declining_sections']\n            })\n        \n        # Velocity-based recommendations\n        if velocity_prediction.get('below_target'):\n            recommendations.append({\n                'type': 'pace_adjustment',\n                'priority': 'medium', \n                'message': 'Consider adjusting study pace or session duration',\n                'action': 'modify_schedule',\n                'suggested_changes': velocity_prediction['suggested_adjustments']\n            })\n        \n        # Cognitive load recommendations\n        if learning_history.get('high_cognitive_load_sessions', 0) > 3:\n            recommendations.append({\n                'type': 'cognitive_load',\n                'priority': 'medium',\n                'message': 'Recent sessions may have been too challenging',\n                'action': 'reduce_difficulty',\n                'suggestion': 'Break complex material into smaller sections'\n            })\n        \n        return recommendations\n    \n    def _calculate_completion_probability(\n        self,\n        velocity_prediction: Dict[str, Any],\n        time_horizon_days: int\n    ) -> float:\n        \"\"\"Calculate probability of material completion within time horizon\"\"\"\n        expected_velocity = velocity_prediction.get('expected_daily_progress', 0.05)\n        current_progress = velocity_prediction.get('current_completion_rate', 0.0)\n        \n        projected_completion = current_progress + (expected_velocity * time_horizon_days)\n        \n        # Add uncertainty factor\n        uncertainty_factor = 0.1  # 10% uncertainty\n        return max(0.0, min(1.0, projected_completion - uncertainty_factor))\n    \n    def _create_adaptive_session_timeline(\n        self,\n        content_sections: List[Dict[str, Any]],\n        quizzes: List[Dict[str, Any]],\n        available_time: int,\n        cognitive_optimization: Dict[str, Any]\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Create an adaptive timeline for the study session\"\"\"\n        timeline = []\n        current_time = 0\n        \n        for i, section in enumerate(content_sections):\n            # Add content study block\n            study_duration = min(section['estimated_time'], \n                               cognitive_optimization['max_focus_duration'])\n            \n            timeline.append({\n                'type': 'study',\n                'start_time': current_time,\n                'duration': study_duration,\n                'content': section,\n                'cognitive_load': section.get('difficulty_score', 0.5)\n            })\n            current_time += study_duration\n            \n            # Add quiz if available\n            if i < len(quizzes):\n                timeline.append({\n                    'type': 'assessment',\n                    'start_time': current_time,\n                    'duration': 5,  # 5 minutes for quiz\n                    'quiz': quizzes[i]\n                })\n                current_time += 5\n            \n            # Add break if needed\n            if current_time < available_time - 10 and i < len(content_sections) - 1:\n                break_duration = cognitive_optimization.get('recommended_break_duration', 5)\n                timeline.append({\n                    'type': 'break',\n                    'start_time': current_time,\n                    'duration': break_duration\n                })\n                current_time += break_duration\n        \n        return timeline\n    \n    def _calculate_optimal_breaks(self, available_time: int) -> List[Dict[str, Any]]:\n        \"\"\"Calculate optimal break intervals for the session\"\"\"\n        breaks = []\n        \n        # Use research-based break intervals (Pomodoro technique with adaptations)\n        if available_time >= 60:  # For sessions 1 hour or longer\n            break_intervals = [25, 50, 75]  # Every 25 minutes\n            for interval in break_intervals:\n                if interval < available_time - 10:\n                    breaks.append({\n                        'time': interval,\n                        'duration': 5 if interval != 50 else 10,  # Longer break at halfway point\n                        'type': 'cognitive_refresh'\n                    })\n        \n        return breaks","size_bytes":17875},"services/pdf_processor.py":{"content":"import pypdf as PyPDF2\nimport os\nimport re\nfrom typing import Dict, Any, Optional, List\nfrom io import BytesIO\n\nclass PDFProcessor:\n    \"\"\"Service for processing PDF files and extracting text content\"\"\"\n    \n    @staticmethod\n    def extract_text_from_pdf(file_path: str) -> Dict[str, Any]:\n        \"\"\"\n        Extract text content from PDF file\n        \n        Args:\n            file_path: Path to the PDF file\n            \n        Returns:\n            Dictionary containing extracted text and metadata\n        \"\"\"\n        try:\n            with open(file_path, 'rb') as file:\n                pdf_reader = PyPDF2.PdfReader(file)\n                \n                # Extract metadata\n                metadata = {\n                    'total_pages': len(pdf_reader.pages),\n                    'title': '',\n                    'author': '',\n                    'subject': ''\n                }\n                \n                # Get document info if available\n                if pdf_reader.metadata:\n                    metadata.update({\n                        'title': pdf_reader.metadata.get('/Title', ''),\n                        'author': pdf_reader.metadata.get('/Author', ''),\n                        'subject': pdf_reader.metadata.get('/Subject', '')\n                    })\n                \n                # Extract text from all pages\n                full_text = \"\"\n                page_texts = []\n                \n                for page_num, page in enumerate(pdf_reader.pages):\n                    try:\n                        page_text = page.extract_text()\n                        page_texts.append({\n                            'page_number': page_num + 1,\n                            'text': page_text,\n                            'word_count': len(page_text.split()) if page_text else 0\n                        })\n                        full_text += page_text + \"\\n\"\n                    except Exception as e:\n                        print(f\"Error extracting text from page {page_num + 1}: {e}\")\n                        page_texts.append({\n                            'page_number': page_num + 1,\n                            'text': '',\n                            'word_count': 0,\n                            'error': str(e)\n                        })\n                \n                # Calculate statistics\n                word_count = len(full_text.split()) if full_text else 0\n                char_count = len(full_text)\n                \n                return {\n                    'success': True,\n                    'full_text': full_text,\n                    'page_texts': page_texts,\n                    'metadata': metadata,\n                    'statistics': {\n                        'word_count': word_count,\n                        'char_count': char_count,\n                        'estimated_reading_time': PDFProcessor.estimate_reading_time(word_count),\n                        'difficulty_score': PDFProcessor.estimate_difficulty(full_text)\n                    }\n                }\n                \n        except Exception as e:\n            return {\n                'success': False,\n                'error': str(e),\n                'full_text': '',\n                'statistics': {\n                    'word_count': 0,\n                    'char_count': 0,\n                    'estimated_reading_time': 0,\n                    'difficulty_score': 0.5\n                }\n            }\n    \n    @staticmethod\n    def extract_text_from_bytes(file_bytes: bytes, filename: str) -> Dict[str, Any]:\n        \"\"\"\n        Extract text content from PDF bytes\n        \n        Args:\n            file_bytes: PDF file as bytes\n            filename: Name of the file\n            \n        Returns:\n            Dictionary containing extracted text and metadata\n        \"\"\"\n        try:\n            pdf_reader = PyPDF2.PdfReader(BytesIO(file_bytes))\n            \n            # Extract metadata\n            metadata = {\n                'total_pages': len(pdf_reader.pages),\n                'filename': filename,\n                'title': '',\n                'author': '',\n                'subject': ''\n            }\n            \n            # Get document info if available\n            if pdf_reader.metadata:\n                metadata.update({\n                    'title': pdf_reader.metadata.get('/Title', ''),\n                    'author': pdf_reader.metadata.get('/Author', ''),\n                    'subject': pdf_reader.metadata.get('/Subject', '')\n                })\n            \n            # Extract text from all pages\n            full_text = \"\"\n            page_texts = []\n            \n            for page_num, page in enumerate(pdf_reader.pages):\n                try:\n                    page_text = page.extract_text()\n                    page_texts.append({\n                        'page_number': page_num + 1,\n                        'text': page_text,\n                        'word_count': len(page_text.split()) if page_text else 0\n                    })\n                    full_text += page_text + \"\\n\"\n                except Exception as e:\n                    print(f\"Error extracting text from page {page_num + 1}: {e}\")\n                    page_texts.append({\n                        'page_number': page_num + 1,\n                        'text': '',\n                        'word_count': 0,\n                        'error': str(e)\n                    })\n            \n            # Calculate statistics\n            word_count = len(full_text.split()) if full_text else 0\n            char_count = len(full_text)\n            \n            return {\n                'success': True,\n                'full_text': full_text,\n                'page_texts': page_texts,\n                'metadata': metadata,\n                'statistics': {\n                    'word_count': word_count,\n                    'char_count': char_count,\n                    'estimated_reading_time': PDFProcessor.estimate_reading_time(word_count),\n                    'difficulty_score': PDFProcessor.estimate_difficulty(full_text)\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': str(e),\n                'full_text': '',\n                'statistics': {\n                    'word_count': 0,\n                    'char_count': 0,\n                    'estimated_reading_time': 0,\n                    'difficulty_score': 0.5\n                }\n            }\n    \n    @staticmethod\n    def estimate_reading_time(word_count: int, reading_speed: float = 200.0) -> float:\n        \"\"\"\n        Estimate reading time in minutes based on word count\n        \n        Args:\n            word_count: Number of words in the text\n            reading_speed: Reading speed in words per minute (default: 200 WPM)\n            \n        Returns:\n            Estimated reading time in minutes\n        \"\"\"\n        if word_count <= 0:\n            return 0.0\n        return round(word_count / reading_speed, 2)\n    \n    @staticmethod\n    def estimate_difficulty(text: str) -> float:\n        \"\"\"\n        Estimate text difficulty based on various metrics\n        \n        Args:\n            text: Text content to analyze\n            \n        Returns:\n            Difficulty score between 0.0 and 1.0\n        \"\"\"\n        if not text or len(text.strip()) == 0:\n            return 0.5\n        \n        try:\n            # Basic text analysis metrics\n            sentences = re.split(r'[.!?]+', text)\n            sentences = [s.strip() for s in sentences if s.strip()]\n            words = text.split()\n            \n            if len(sentences) == 0 or len(words) == 0:\n                return 0.5\n            \n            # Average sentence length\n            avg_sentence_length = len(words) / len(sentences)\n            \n            # Average word length\n            avg_word_length = sum(len(word) for word in words) / len(words)\n            \n            # Count of complex words (more than 6 characters)\n            complex_words = [word for word in words if len(word) > 6]\n            complex_word_ratio = len(complex_words) / len(words)\n            \n            # Flesch Reading Ease approximation\n            # Higher values = easier text\n            flesch_score = 206.835 - (1.015 * avg_sentence_length) - (84.6 * (sum(PDFProcessor._count_syllables(word) for word in words) / len(words)))\n            \n            # Convert to difficulty score (0.0 = easy, 1.0 = very difficult)\n            if flesch_score >= 90:\n                difficulty = 0.1  # Very easy\n            elif flesch_score >= 80:\n                difficulty = 0.2  # Easy\n            elif flesch_score >= 70:\n                difficulty = 0.3  # Fairly easy\n            elif flesch_score >= 60:\n                difficulty = 0.4  # Standard\n            elif flesch_score >= 50:\n                difficulty = 0.5  # Fairly difficult\n            elif flesch_score >= 30:\n                difficulty = 0.7  # Difficult\n            else:\n                difficulty = 0.9  # Very difficult\n            \n            # Adjust based on other factors\n            if complex_word_ratio > 0.3:\n                difficulty += 0.1\n            if avg_word_length > 7:\n                difficulty += 0.1\n            \n            # Ensure score is between 0.0 and 1.0\n            return min(max(difficulty, 0.0), 1.0)\n            \n        except Exception as e:\n            print(f\"Error calculating difficulty: {e}\")\n            return 0.5\n    \n    @staticmethod\n    def _count_syllables(word: str) -> int:\n        \"\"\"\n        Estimate syllable count in a word\n        \n        Args:\n            word: Word to count syllables for\n            \n        Returns:\n            Estimated number of syllables\n        \"\"\"\n        word = word.lower()\n        vowels = \"aeiouy\"\n        syllable_count = 0\n        previous_was_vowel = False\n        \n        for char in word:\n            is_vowel = char in vowels\n            if is_vowel and not previous_was_vowel:\n                syllable_count += 1\n            previous_was_vowel = is_vowel\n        \n        # Handle silent 'e'\n        if word.endswith('e'):\n            syllable_count -= 1\n        \n        # Every word has at least one syllable\n        return max(syllable_count, 1)\n    \n    @staticmethod\n    def extract_sections(text: str, max_section_words: int = 500) -> List[Dict[str, Any]]:\n        \"\"\"\n        Split text into manageable sections for study scheduling\n        \n        Args:\n            text: Full text content\n            max_section_words: Maximum words per section\n            \n        Returns:\n            List of text sections with metadata\n        \"\"\"\n        if not text or len(text.strip()) == 0:\n            return []\n        \n        try:\n            # Split by paragraphs first\n            paragraphs = text.split('\\n\\n')\n            sections = []\n            current_section = \"\"\n            current_word_count = 0\n            section_number = 1\n            \n            for paragraph in paragraphs:\n                paragraph = paragraph.strip()\n                if not paragraph:\n                    continue\n                \n                para_words = len(paragraph.split())\n                \n                # If adding this paragraph would exceed the limit, start new section\n                if current_word_count + para_words > max_section_words and current_section:\n                    sections.append({\n                        'section_number': section_number,\n                        'text': current_section.strip(),\n                        'word_count': current_word_count,\n                        'estimated_reading_time': PDFProcessor.estimate_reading_time(current_word_count)\n                    })\n                    current_section = paragraph\n                    current_word_count = para_words\n                    section_number += 1\n                else:\n                    current_section += \"\\n\\n\" + paragraph if current_section else paragraph\n                    current_word_count += para_words\n            \n            # Add the last section if it has content\n            if current_section.strip():\n                sections.append({\n                    'section_number': section_number,\n                    'text': current_section.strip(),\n                    'word_count': current_word_count,\n                    'estimated_reading_time': PDFProcessor.estimate_reading_time(current_word_count)\n                })\n            \n            return sections\n            \n        except Exception as e:\n            print(f\"Error extracting sections: {e}\")\n            return [{\n                'section_number': 1,\n                'text': text,\n                'word_count': len(text.split()),\n                'estimated_reading_time': PDFProcessor.estimate_reading_time(len(text.split()))\n            }]\n","size_bytes":12824},"services/performance_tracker.py":{"content":"from datetime import datetime, timedelta\nfrom typing import Dict, Any, List, Optional\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy import func\nfrom models import User, Performance, StudySession, Quiz, Material\n\nclass PerformanceTracker:\n    \"\"\"Service for tracking and analyzing user performance\"\"\"\n    \n    def __init__(self, db: Session):\n        self.db = db\n    \n    def record_quiz_performance(\n        self,\n        user_id: int,\n        quiz_id: int,\n        score: float,\n        time_taken: float,\n        questions_correct: int,\n        questions_total: int,\n        question_responses: Dict[str, Any] = None\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Record quiz performance metrics\n        \n        Args:\n            user_id: ID of the user\n            quiz_id: ID of the quiz taken\n            score: Score from 0.0 to 1.0\n            time_taken: Time taken in minutes\n            questions_correct: Number of correct answers\n            questions_total: Total number of questions\n            question_responses: Detailed responses to questions\n            \n        Returns:\n            Dictionary with recorded performance data\n        \"\"\"\n        try:\n            # Get quiz and material info for context\n            quiz = self.db.query(Quiz).filter(Quiz.id == quiz_id).first()\n            if not quiz:\n                return {'success': False, 'error': 'Quiz not found'}\n            \n            # Calculate additional metrics\n            comprehension_speed = questions_total / time_taken if time_taken > 0 else 0\n            difficulty_handled = quiz.difficulty_level\n            \n            # Create performance record\n            performance = Performance(\n                user_id=user_id,\n                quiz_id=quiz_id,\n                score=score,\n                time_taken=time_taken,\n                questions_correct=questions_correct,\n                questions_total=questions_total,\n                comprehension_speed=comprehension_speed,\n                difficulty_handled=difficulty_handled,\n                question_responses=question_responses or {}\n            )\n            \n            self.db.add(performance)\n            self.db.commit()\n            \n            # Update user's learning metrics\n            self._update_user_metrics(user_id)\n            \n            # Analyze performance patterns\n            analysis = self._analyze_recent_performance(user_id, quiz.material_id)\n            \n            return {\n                'success': True,\n                'performance_id': performance.id,\n                'analysis': analysis\n            }\n            \n        except Exception as e:\n            self.db.rollback()\n            return {'success': False, 'error': str(e)}\n    \n    def record_study_session(\n        self,\n        user_id: int,\n        session_data: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Record study session performance\n        \n        Args:\n            user_id: ID of the user\n            session_data: Dictionary containing session metrics\n            \n        Returns:\n            Dictionary with recorded session data\n        \"\"\"\n        try:\n            # Calculate derived metrics\n            duration = None\n            reading_speed = None\n            \n            if 'end_time' in session_data and 'start_time' in session_data:\n                duration = (session_data['end_time'] - session_data['start_time']).total_seconds() / 60\n                \n                if 'words_read' in session_data and duration > 0:\n                    reading_speed = session_data['words_read'] / duration\n            \n            # Create study session record\n            session = StudySession(\n                user_id=user_id,\n                schedule_id=session_data.get('schedule_id'),\n                start_time=session_data['start_time'],\n                end_time=session_data.get('end_time'),\n                duration_minutes=duration,\n                pages_read=session_data.get('pages_read', 0),\n                words_read=session_data.get('words_read', 0),\n                reading_speed=reading_speed,\n                focus_score=session_data.get('focus_score', 0.5),\n                interaction_count=session_data.get('interaction_count', 0),\n                pause_count=session_data.get('pause_count', 0),\n                total_pause_time=session_data.get('total_pause_time', 0.0),\n                completion_percentage=session_data.get('completion_percentage', 0.0),\n                self_rated_understanding=session_data.get('self_rated_understanding'),\n                session_notes=session_data.get('session_notes')\n            )\n            \n            self.db.add(session)\n            self.db.commit()\n            \n            # Update user's reading metrics\n            self._update_reading_metrics(user_id)\n            \n            return {\n                'success': True,\n                'session_id': session.id,\n                'calculated_duration': duration,\n                'calculated_reading_speed': reading_speed\n            }\n            \n        except Exception as e:\n            self.db.rollback()\n            return {'success': False, 'error': str(e)}\n    \n    def get_performance_analytics(\n        self,\n        user_id: int,\n        material_id: Optional[int] = None,\n        days_back: int = 30\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Get comprehensive performance analytics for a user\n        \n        Args:\n            user_id: ID of the user\n            material_id: Optional material ID to filter by\n            days_back: Number of days to look back\n            \n        Returns:\n            Dictionary with performance analytics\n        \"\"\"\n        try:\n            cutoff_date = datetime.utcnow() - timedelta(days=days_back)\n            \n            # Get quiz performances\n            quiz_query = self.db.query(Performance).filter(\n                Performance.user_id == user_id,\n                Performance.created_at >= cutoff_date\n            )\n            \n            if material_id:\n                quiz_query = quiz_query.join(Quiz).filter(Quiz.material_id == material_id)\n            \n            quiz_performances = quiz_query.all()\n            \n            # Get study sessions\n            session_query = self.db.query(StudySession).filter(\n                StudySession.user_id == user_id,\n                StudySession.start_time >= cutoff_date\n            )\n            \n            study_sessions = session_query.all()\n            \n            # Calculate quiz metrics\n            quiz_metrics = self._calculate_quiz_metrics(quiz_performances)\n            \n            # Calculate study session metrics\n            session_metrics = self._calculate_session_metrics(study_sessions)\n            \n            # Calculate learning trends\n            trends = self._calculate_learning_trends(quiz_performances, study_sessions)\n            \n            # Get user's current metrics\n            user = self.db.query(User).filter(User.id == user_id).first()\n            \n            return {\n                'success': True,\n                'period': f'{days_back} days',\n                'quiz_metrics': quiz_metrics,\n                'session_metrics': session_metrics,\n                'learning_trends': trends,\n                'user_profile': {\n                    'average_reading_speed': user.average_reading_speed if user else 200,\n                    'retention_rate': user.retention_rate if user else 0.7,\n                    'cognitive_load_limit': user.cognitive_load_limit if user else 1.0\n                }\n            }\n            \n        except Exception as e:\n            return {'success': False, 'error': str(e)}\n    \n    def get_learning_curve_data(self, user_id: int, material_id: int) -> Dict[str, Any]:\n        \"\"\"\n        Get learning curve data for a specific material\n        \n        Args:\n            user_id: ID of the user\n            material_id: ID of the material\n            \n        Returns:\n            Dictionary with learning curve data points\n        \"\"\"\n        try:\n            # Get all performances for this material\n            performances = self.db.query(Performance).join(Quiz).filter(\n                Performance.user_id == user_id,\n                Quiz.material_id == material_id\n            ).order_by(Performance.created_at).all()\n            \n            if not performances:\n                return {\n                    'success': True,\n                    'data_points': [],\n                    'trend': 'no_data'\n                }\n            \n            # Create data points for learning curve\n            data_points = []\n            for i, perf in enumerate(performances):\n                data_points.append({\n                    'session_number': i + 1,\n                    'score': perf.score,\n                    'time_taken': perf.time_taken,\n                    'comprehension_speed': perf.comprehension_speed,\n                    'date': perf.created_at.isoformat(),\n                    'difficulty': perf.difficulty_handled\n                })\n            \n            # Calculate trend\n            if len(performances) >= 3:\n                recent_scores = [p.score for p in performances[-3:]]\n                early_scores = [p.score for p in performances[:3]]\n                \n                recent_avg = sum(recent_scores) / len(recent_scores)\n                early_avg = sum(early_scores) / len(early_scores)\n                \n                if recent_avg > early_avg + 0.1:\n                    trend = 'improving'\n                elif recent_avg < early_avg - 0.1:\n                    trend = 'declining'\n                else:\n                    trend = 'stable'\n            else:\n                trend = 'insufficient_data'\n            \n            return {\n                'success': True,\n                'data_points': data_points,\n                'trend': trend,\n                'total_sessions': len(performances)\n            }\n            \n        except Exception as e:\n            return {'success': False, 'error': str(e)}\n    \n    def _update_user_metrics(self, user_id: int):\n        \"\"\"Update user's learning metrics based on recent performance\"\"\"\n        try:\n            user = self.db.query(User).filter(User.id == user_id).first()\n            if not user:\n                return\n            \n            # Get recent performances\n            recent_performances = self.db.query(Performance).filter(\n                Performance.user_id == user_id,\n                Performance.created_at >= datetime.utcnow() - timedelta(days=30)\n            ).limit(20).all()\n            \n            if recent_performances:\n                # Update retention rate\n                avg_score = sum(p.score for p in recent_performances) / len(recent_performances)\n                user.retention_rate = (user.retention_rate * 0.7) + (avg_score * 0.3)\n                \n                # Update cognitive load limit based on performance under different loads\n                high_load_performances = [p for p in recent_performances if hasattr(p, 'cognitive_load') and p.cognitive_load > 0.7]\n                if high_load_performances:\n                    high_load_avg = sum(p.score for p in high_load_performances) / len(high_load_performances)\n                    if high_load_avg > 0.7:\n                        user.cognitive_load_limit = min(1.5, user.cognitive_load_limit * 1.1)\n                    elif high_load_avg < 0.5:\n                        user.cognitive_load_limit = max(0.5, user.cognitive_load_limit * 0.9)\n                \n                self.db.commit()\n                \n        except Exception as e:\n            print(f\"Error updating user metrics: {e}\")\n            self.db.rollback()\n    \n    def _update_reading_metrics(self, user_id: int):\n        \"\"\"Update user's reading speed based on recent sessions\"\"\"\n        try:\n            user = self.db.query(User).filter(User.id == user_id).first()\n            if not user:\n                return\n            \n            # Get recent study sessions with reading speed data\n            recent_sessions = self.db.query(StudySession).filter(\n                StudySession.user_id == user_id,\n                StudySession.reading_speed.isnot(None),\n                StudySession.start_time >= datetime.utcnow() - timedelta(days=30)\n            ).limit(10).all()\n            \n            if recent_sessions:\n                speeds = [s.reading_speed for s in recent_sessions if s.reading_speed > 0]\n                if speeds:\n                    avg_speed = sum(speeds) / len(speeds)\n                    # Weighted average with existing speed\n                    user.average_reading_speed = (user.average_reading_speed * 0.7) + (avg_speed * 0.3)\n                    self.db.commit()\n                    \n        except Exception as e:\n            print(f\"Error updating reading metrics: {e}\")\n            self.db.rollback()\n    \n    def _calculate_quiz_metrics(self, performances: List[Performance]) -> Dict[str, Any]:\n        \"\"\"Calculate quiz performance metrics\"\"\"\n        if not performances:\n            return {\n                'total_quizzes': 0,\n                'average_score': 0,\n                'average_time': 0,\n                'improvement_rate': 0\n            }\n        \n        scores = [p.score for p in performances]\n        times = [p.time_taken for p in performances if p.time_taken]\n        \n        # Calculate improvement rate\n        improvement_rate = 0\n        if len(scores) >= 2:\n            first_half = scores[:len(scores)//2]\n            second_half = scores[len(scores)//2:]\n            improvement_rate = (sum(second_half)/len(second_half)) - (sum(first_half)/len(first_half))\n        \n        return {\n            'total_quizzes': len(performances),\n            'average_score': sum(scores) / len(scores),\n            'average_time': sum(times) / len(times) if times else 0,\n            'improvement_rate': improvement_rate,\n            'score_range': {'min': min(scores), 'max': max(scores)},\n            'consistency': 1 - (max(scores) - min(scores))  # Higher is more consistent\n        }\n    \n    def _calculate_session_metrics(self, sessions: List[StudySession]) -> Dict[str, Any]:\n        \"\"\"Calculate study session metrics\"\"\"\n        if not sessions:\n            return {\n                'total_sessions': 0,\n                'total_study_time': 0,\n                'average_session_duration': 0,\n                'average_focus_score': 0\n            }\n        \n        durations = [s.duration_minutes for s in sessions if s.duration_minutes]\n        focus_scores = [s.focus_score for s in sessions]\n        reading_speeds = [s.reading_speed for s in sessions if s.reading_speed]\n        \n        return {\n            'total_sessions': len(sessions),\n            'total_study_time': sum(durations),\n            'average_session_duration': sum(durations) / len(durations) if durations else 0,\n            'average_focus_score': sum(focus_scores) / len(focus_scores),\n            'average_reading_speed': sum(reading_speeds) / len(reading_speeds) if reading_speeds else 0,\n            'completion_rate': sum(s.completion_percentage for s in sessions) / len(sessions) / 100\n        }\n    \n    def _calculate_learning_trends(\n        self,\n        performances: List[Performance],\n        sessions: List[StudySession]\n    ) -> Dict[str, Any]:\n        \"\"\"Calculate learning trends over time\"\"\"\n        trends = {\n            'score_trend': 'stable',\n            'speed_trend': 'stable',\n            'engagement_trend': 'stable'\n        }\n        \n        # Score trend\n        if len(performances) >= 4:\n            recent_scores = [p.score for p in performances[-len(performances)//2:]]\n            early_scores = [p.score for p in performances[:len(performances)//2]]\n            \n            recent_avg = sum(recent_scores) / len(recent_scores)\n            early_avg = sum(early_scores) / len(early_scores)\n            \n            if recent_avg > early_avg + 0.05:\n                trends['score_trend'] = 'improving'\n            elif recent_avg < early_avg - 0.05:\n                trends['score_trend'] = 'declining'\n        \n        # Reading speed trend\n        session_speeds = [s.reading_speed for s in sessions if s.reading_speed and s.reading_speed > 0]\n        if len(session_speeds) >= 4:\n            recent_speeds = session_speeds[-len(session_speeds)//2:]\n            early_speeds = session_speeds[:len(session_speeds)//2]\n            \n            recent_avg = sum(recent_speeds) / len(recent_speeds)\n            early_avg = sum(early_speeds) / len(early_speeds)\n            \n            if recent_avg > early_avg * 1.1:\n                trends['speed_trend'] = 'improving'\n            elif recent_avg < early_avg * 0.9:\n                trends['speed_trend'] = 'declining'\n        \n        # Engagement trend (based on focus scores)\n        focus_scores = [s.focus_score for s in sessions]\n        if len(focus_scores) >= 4:\n            recent_focus = focus_scores[-len(focus_scores)//2:]\n            early_focus = focus_scores[:len(focus_scores)//2]\n            \n            recent_avg = sum(recent_focus) / len(recent_focus)\n            early_avg = sum(early_focus) / len(early_focus)\n            \n            if recent_avg > early_avg + 0.05:\n                trends['engagement_trend'] = 'improving'\n            elif recent_avg < early_avg - 0.05:\n                trends['engagement_trend'] = 'declining'\n        \n        return trends\n    \n    def _analyze_recent_performance(self, user_id: int, material_id: int) -> Dict[str, Any]:\n        \"\"\"Analyze recent performance for a specific material\"\"\"\n        try:\n            # Get last 5 performances for this material\n            recent_performances = self.db.query(Performance).join(Quiz).filter(\n                Performance.user_id == user_id,\n                Quiz.material_id == material_id\n            ).order_by(Performance.created_at.desc()).limit(5).all()\n            \n            if not recent_performances:\n                return {'status': 'no_data'}\n            \n            avg_score = sum(p.score for p in recent_performances) / len(recent_performances)\n            avg_speed = sum(p.comprehension_speed for p in recent_performances if p.comprehension_speed) / len(recent_performances)\n            \n            # Determine learning status\n            if avg_score >= 0.8:\n                status = 'mastery'\n                recommendation = 'Ready for advanced material or spaced review'\n            elif avg_score >= 0.6:\n                status = 'progressing'\n                recommendation = 'Continue with current pace'\n            else:\n                status = 'struggling'\n                recommendation = 'Consider reviewing fundamentals or reducing difficulty'\n            \n            return {\n                'status': status,\n                'average_score': avg_score,\n                'average_speed': avg_speed,\n                'recommendation': recommendation,\n                'total_attempts': len(recent_performances)\n            }\n            \n        except Exception as e:\n            return {'status': 'error', 'message': str(e)}\n","size_bytes":19141},"services/quiz_generator.py":{"content":"import random\nimport re\nfrom typing import List, Dict, Any, Optional\nfrom config import settings\n\nclass QuizGenerator:\n    \"\"\"Service for generating quizzes from text content\"\"\"\n    \n    @staticmethod\n    def generate_quiz_from_text(\n        text: str, \n        num_questions: int = None,\n        difficulty_level: float = 0.5,\n        content_section: str = None\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Generate a quiz from text content\n        \n        Args:\n            text: Text content to generate quiz from\n            num_questions: Number of questions to generate\n            difficulty_level: Difficulty level (0.0 to 1.0)\n            content_section: Section identifier for the content\n            \n        Returns:\n            Dictionary containing quiz data\n        \"\"\"\n        if num_questions is None:\n            num_questions = settings.QUIZ_QUESTIONS_PER_SECTION\n        \n        try:\n            # Extract potential quiz content\n            sentences = QuizGenerator._extract_sentences(text)\n            facts = QuizGenerator._extract_facts(text)\n            definitions = QuizGenerator._extract_definitions(text)\n            \n            if not sentences and not facts:\n                return {\n                    'success': False,\n                    'error': 'Insufficient content for quiz generation',\n                    'questions': []\n                }\n            \n            questions = []\n            \n            # Generate different types of questions\n            question_types = [\n                ('multiple_choice', 0.6),\n                ('true_false', 0.3),\n                ('fill_blank', 0.1)\n            ]\n            \n            # Adjust question types based on difficulty\n            if difficulty_level < 0.3:\n                # Easier questions - more true/false\n                question_types = [('true_false', 0.5), ('multiple_choice', 0.5)]\n            elif difficulty_level > 0.7:\n                # Harder questions - more fill in the blank and complex multiple choice\n                question_types = [('multiple_choice', 0.5), ('fill_blank', 0.3), ('true_false', 0.2)]\n            \n            # Generate questions\n            for i in range(min(num_questions, len(sentences))):\n                question_type = QuizGenerator._select_question_type(question_types)\n                \n                if question_type == 'multiple_choice':\n                    question = QuizGenerator._generate_multiple_choice(sentences, facts, i)\n                elif question_type == 'true_false':\n                    question = QuizGenerator._generate_true_false(sentences, i)\n                elif question_type == 'fill_blank':\n                    question = QuizGenerator._generate_fill_blank(sentences, i)\n                else:\n                    question = QuizGenerator._generate_multiple_choice(sentences, facts, i)\n                \n                if question:\n                    questions.append(question)\n            \n            return {\n                'success': True,\n                'questions': questions,\n                'total_questions': len(questions),\n                'difficulty_level': difficulty_level,\n                'content_section': content_section\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Quiz generation failed: {str(e)}',\n                'questions': []\n            }\n    \n    @staticmethod\n    def _extract_sentences(text: str) -> List[str]:\n        \"\"\"Extract meaningful sentences from text\"\"\"\n        # Split by sentence-ending punctuation\n        sentences = re.split(r'[.!?]+', text)\n        \n        # Filter and clean sentences\n        meaningful_sentences = []\n        for sentence in sentences:\n            sentence = sentence.strip()\n            # Keep sentences that are not too short or too long\n            if 10 <= len(sentence.split()) <= 50:\n                meaningful_sentences.append(sentence)\n        \n        return meaningful_sentences\n    \n    @staticmethod\n    def _extract_facts(text: str) -> List[str]:\n        \"\"\"Extract factual statements from text\"\"\"\n        facts = []\n        sentences = QuizGenerator._extract_sentences(text)\n        \n        # Look for sentences that contain factual patterns\n        fact_patterns = [\n            r'\\b\\d+\\b',  # Contains numbers\n            r'\\b(is|are|was|were|has|have|had)\\b',  # Contains state verbs\n            r'\\b(according to|research shows|studies indicate)\\b',  # Research references\n            r'\\b(defined as|refers to|means)\\b'  # Definitions\n        ]\n        \n        for sentence in sentences:\n            for pattern in fact_patterns:\n                if re.search(pattern, sentence, re.IGNORECASE):\n                    facts.append(sentence)\n                    break\n        \n        return facts\n    \n    @staticmethod\n    def _extract_definitions(text: str) -> List[Dict[str, str]]:\n        \"\"\"Extract term definitions from text\"\"\"\n        definitions = []\n        \n        # Look for definition patterns\n        definition_patterns = [\n            r'(\\b[A-Z][a-z]+\\b)\\s+(?:is|are|refers to|means|defined as)\\s+([^.!?]+)',\n            r'(\\b[A-Z][a-z]+\\b):\\s*([^.!?]+)',\n        ]\n        \n        for pattern in definition_patterns:\n            matches = re.finditer(pattern, text)\n            for match in matches:\n                term = match.group(1)\n                definition = match.group(2).strip()\n                if len(definition.split()) >= 3:  # Ensure definition is meaningful\n                    definitions.append({'term': term, 'definition': definition})\n        \n        return definitions\n    \n    @staticmethod\n    def _select_question_type(question_types: List[tuple]) -> str:\n        \"\"\"Select question type based on weights\"\"\"\n        total_weight = sum(weight for _, weight in question_types)\n        r = random.random() * total_weight\n        \n        cumulative_weight = 0\n        for q_type, weight in question_types:\n            cumulative_weight += weight\n            if r <= cumulative_weight:\n                return q_type\n        \n        return question_types[0][0]  # Fallback\n    \n    @staticmethod\n    def _generate_multiple_choice(sentences: List[str], facts: List[str], index: int) -> Optional[Dict[str, Any]]:\n        \"\"\"Generate a multiple choice question\"\"\"\n        try:\n            if index >= len(sentences):\n                return None\n            \n            base_sentence = sentences[index]\n            \n            # Extract key information from sentence\n            words = base_sentence.split()\n            if len(words) < 5:\n                return None\n            \n            # Find a good word to ask about (noun or important term)\n            important_words = [word for word in words if len(word) > 4 and word.isalpha()]\n            if not important_words:\n                return None\n            \n            target_word = random.choice(important_words)\n            \n            # Create question by replacing the target word\n            question_text = base_sentence.replace(target_word, \"______\")\n            \n            # Generate answer options\n            options = [target_word]  # Correct answer\n            \n            # Generate distractors\n            all_words = []\n            for sentence in sentences[:20]:  # Use first 20 sentences for distractors\n                all_words.extend([word for word in sentence.split() if len(word) > 4 and word.isalpha()])\n            \n            distractors = list(set(all_words) - {target_word})\n            random.shuffle(distractors)\n            \n            # Add 3 distractors\n            options.extend(distractors[:3])\n            \n            # Shuffle options\n            correct_index = 0\n            random.shuffle(options)\n            correct_index = options.index(target_word)\n            \n            return {\n                'type': 'multiple_choice',\n                'question': f'Fill in the blank: {question_text}',\n                'options': options,\n                'correct_answer': correct_index,\n                'explanation': f'The correct answer is \"{target_word}\" based on the context provided.'\n            }\n            \n        except Exception as e:\n            print(f\"Error generating multiple choice question: {e}\")\n            return None\n    \n    @staticmethod\n    def _generate_true_false(sentences: List[str], index: int) -> Optional[Dict[str, Any]]:\n        \"\"\"Generate a true/false question\"\"\"\n        try:\n            if index >= len(sentences):\n                return None\n            \n            base_sentence = sentences[index]\n            \n            # Randomly decide if this should be true or false\n            is_true = random.choice([True, False])\n            \n            if is_true:\n                # Use the sentence as-is\n                question_text = base_sentence\n                correct_answer = 0  # True\n                explanation = \"This statement is true based on the provided content.\"\n            else:\n                # Modify the sentence to make it false\n                words = base_sentence.split()\n                if len(words) < 5:\n                    return None\n                \n                # Simple modifications to make false\n                modifications = [\n                    lambda s: s.replace(' is ', ' is not '),\n                    lambda s: s.replace(' are ', ' are not '),\n                    lambda s: s.replace(' can ', ' cannot '),\n                    lambda s: s.replace(' will ', ' will not ')\n                ]\n                \n                modification = random.choice(modifications)\n                question_text = modification(base_sentence)\n                \n                # If no modification was made, try word replacement\n                if question_text == base_sentence and len(words) > 3:\n                    # Replace a key word with an antonym or different word\n                    replacements = {\n                        'increase': 'decrease',\n                        'large': 'small',\n                        'high': 'low',\n                        'important': 'unimportant',\n                        'effective': 'ineffective',\n                        'positive': 'negative',\n                        'good': 'bad',\n                        'always': 'never',\n                        'all': 'none'\n                    }\n                    \n                    for word in words:\n                        if word.lower() in replacements:\n                            question_text = base_sentence.replace(word, replacements[word.lower()])\n                            break\n                \n                correct_answer = 1  # False\n                explanation = \"This statement is false. The original content states something different.\"\n            \n            return {\n                'type': 'true_false',\n                'question': question_text,\n                'options': ['True', 'False'],\n                'correct_answer': correct_answer,\n                'explanation': explanation\n            }\n            \n        except Exception as e:\n            print(f\"Error generating true/false question: {e}\")\n            return None\n    \n    @staticmethod\n    def _generate_fill_blank(sentences: List[str], index: int) -> Optional[Dict[str, Any]]:\n        \"\"\"Generate a fill-in-the-blank question\"\"\"\n        try:\n            if index >= len(sentences):\n                return None\n            \n            base_sentence = sentences[index]\n            words = base_sentence.split()\n            \n            if len(words) < 6:\n                return None\n            \n            # Find important words to blank out\n            important_words = []\n            for i, word in enumerate(words):\n                if (len(word) > 4 and \n                    word.isalpha() and \n                    word.lower() not in ['the', 'and', 'or', 'but', 'with', 'from', 'they', 'this', 'that']):\n                    important_words.append((i, word))\n            \n            if not important_words:\n                return None\n            \n            # Select word to blank out\n            word_index, target_word = random.choice(important_words)\n            \n            # Create question with blank\n            question_words = words.copy()\n            question_words[word_index] = \"______\"\n            question_text = \" \".join(question_words)\n            \n            return {\n                'type': 'fill_blank',\n                'question': f'Fill in the blank: {question_text}',\n                'options': [target_word],  # For fill-in-blank, we store the answer in options[0]\n                'correct_answer': 0,\n                'explanation': f'The correct answer is \"{target_word}\".'\n            }\n            \n        except Exception as e:\n            print(f\"Error generating fill blank question: {e}\")\n            return None\n    \n    @staticmethod\n    def validate_quiz_answers(quiz_questions: List[Dict[str, Any]], user_answers: List[Any]) -> Dict[str, Any]:\n        \"\"\"\n        Validate user answers against quiz questions\n        \n        Args:\n            quiz_questions: List of quiz question dictionaries\n            user_answers: List of user answers (indices or strings)\n            \n        Returns:\n            Dictionary with validation results\n        \"\"\"\n        if len(quiz_questions) != len(user_answers):\n            return {\n                'success': False,\n                'error': 'Mismatch between questions and answers count'\n            }\n        \n        correct_count = 0\n        total_questions = len(quiz_questions)\n        detailed_results = []\n        \n        for i, (question, user_answer) in enumerate(zip(quiz_questions, user_answers)):\n            correct_answer = question.get('correct_answer', 0)\n            is_correct = False\n            \n            # Handle different answer formats\n            if question.get('type') == 'fill_blank':\n                # For fill-in-the-blank, check if answer matches (case-insensitive)\n                expected = question['options'][0].lower().strip()\n                given = str(user_answer).lower().strip()\n                is_correct = expected == given\n            else:\n                # For multiple choice and true/false, check index\n                try:\n                    is_correct = int(user_answer) == correct_answer\n                except (ValueError, TypeError):\n                    is_correct = False\n            \n            if is_correct:\n                correct_count += 1\n            \n            detailed_results.append({\n                'question_index': i,\n                'user_answer': user_answer,\n                'correct_answer': correct_answer,\n                'is_correct': is_correct,\n                'explanation': question.get('explanation', '')\n            })\n        \n        score = correct_count / total_questions if total_questions > 0 else 0\n        \n        return {\n            'success': True,\n            'score': score,\n            'correct_count': correct_count,\n            'total_questions': total_questions,\n            'detailed_results': detailed_results\n        }\n","size_bytes":15170},"services/scheduler.py":{"content":"from datetime import datetime, timedelta\nfrom typing import List, Dict, Any, Optional\nfrom sqlalchemy.orm import Session\nfrom models import User, Material, Schedule, Performance, StudySession, Quiz\nimport math\n\nclass StudyScheduler:\n    \"\"\"Service for generating and adapting study schedules\"\"\"\n    \n    def __init__(self, db: Session):\n        self.db = db\n    \n    def generate_initial_schedule(\n        self,\n        user_id: int,\n        material_id: int,\n        target_completion_date: datetime,\n        daily_study_time: int = 60  # minutes per day\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Generate initial study schedule for a material\n        \n        Args:\n            user_id: ID of the user\n            material_id: ID of the material to schedule\n            target_completion_date: When to complete the material\n            daily_study_time: Available study time per day in minutes\n            \n        Returns:\n            List of schedule entries\n        \"\"\"\n        try:\n            # Get user and material data\n            user = self.db.query(User).filter(User.id == user_id).first()\n            material = self.db.query(Material).filter(Material.id == material_id).first()\n            \n            if not user or not material:\n                return []\n            \n            # Calculate total study sessions needed\n            estimated_total_time = material.estimated_reading_time or 60  # fallback to 1 hour\n            sessions_needed = math.ceil(estimated_total_time / daily_study_time)\n            \n            # Calculate days available\n            days_available = (target_completion_date - datetime.utcnow()).days\n            if days_available <= 0:\n                days_available = 7  # Default to 1 week\n            \n            # Adjust session frequency\n            if sessions_needed > days_available:\n                # Need multiple sessions per day\n                sessions_per_day = math.ceil(sessions_needed / days_available)\n                session_duration = daily_study_time // sessions_per_day\n            else:\n                # One session per scheduled day\n                sessions_per_day = 1\n                session_duration = daily_study_time\n                # Spread sessions across available days\n                days_between_sessions = days_available // sessions_needed\n            \n            schedules = []\n            current_date = datetime.utcnow().replace(hour=9, minute=0, second=0, microsecond=0)  # Start at 9 AM\n            \n            # Get user's preferred study times\n            preferred_times = user.preferred_study_times or {'morning': 0.7, 'afternoon': 0.5, 'evening': 0.3}\n            \n            for session_num in range(sessions_needed):\n                # Determine optimal time based on user preferences\n                study_hour = self._get_optimal_study_time(preferred_times, session_num)\n                \n                # Calculate schedule date\n                if sessions_per_day == 1:\n                    schedule_date = current_date + timedelta(days=session_num * days_between_sessions)\n                else:\n                    day_offset = session_num // sessions_per_day\n                    session_of_day = session_num % sessions_per_day\n                    schedule_date = current_date + timedelta(days=day_offset)\n                    # Spread sessions throughout the day\n                    schedule_date = schedule_date.replace(hour=study_hour + (session_of_day * 2))\n                \n                # Ensure we don't schedule past the target date\n                if schedule_date > target_completion_date:\n                    schedule_date = target_completion_date - timedelta(hours=(sessions_needed - session_num))\n                \n                # Calculate content section for this session\n                total_words = material.word_count or 1000\n                words_per_session = total_words // sessions_needed\n                start_position = session_num * words_per_session\n                end_position = min((session_num + 1) * words_per_session, total_words)\n                \n                # Determine session type (alternating study and review)\n                session_type = \"study\" if session_num % 3 != 2 else \"review\"\n                \n                # Calculate cognitive load and priority\n                cognitive_load = self._calculate_cognitive_load(\n                    session_duration, \n                    material.difficulty_score or 0.5, \n                    user.cognitive_load_limit\n                )\n                \n                priority_score = self._calculate_priority_score(\n                    session_num, sessions_needed, material.difficulty_score or 0.5\n                )\n                \n                schedule_entry = {\n                    'user_id': user_id,\n                    'material_id': material_id,\n                    'scheduled_date': schedule_date,\n                    'duration_minutes': session_duration,\n                    'session_type': session_type,\n                    'priority_score': priority_score,\n                    'cognitive_load_score': cognitive_load,\n                    'repetition_interval': 1,  # Initial interval\n                    'start_position': start_position,\n                    'end_position': end_position,\n                    'status': 'scheduled'\n                }\n                \n                schedules.append(schedule_entry)\n            \n            return schedules\n            \n        except Exception as e:\n            print(f\"Error generating schedule: {e}\")\n            return []\n    \n    def adapt_schedule_based_on_performance(\n        self,\n        user_id: int,\n        material_id: int = None\n    ) -> List[Dict[str, Any]]:\n        \"\"\"\n        Adapt existing schedules based on user performance\n        \n        Args:\n            user_id: ID of the user\n            material_id: Optional specific material ID to adapt\n            \n        Returns:\n            List of updated schedule entries\n        \"\"\"\n        try:\n            # Get user's performance data\n            user = self.db.query(User).filter(User.id == user_id).first()\n            if not user:\n                return []\n            \n            # Get recent performance records\n            performance_query = self.db.query(Performance).filter(Performance.user_id == user_id)\n            if material_id:\n                performance_query = performance_query.join(Quiz).filter(Quiz.material_id == material_id)\n            \n            recent_performances = performance_query.order_by(Performance.created_at.desc()).limit(10).all()\n            \n            # Get current schedules\n            schedule_query = self.db.query(Schedule).filter(\n                Schedule.user_id == user_id,\n                Schedule.status == 'scheduled',\n                Schedule.scheduled_date > datetime.utcnow()\n            )\n            if material_id:\n                schedule_query = schedule_query.filter(Schedule.material_id == material_id)\n            \n            current_schedules = schedule_query.all()\n            \n            adaptations = []\n            \n            # Analyze performance patterns\n            performance_analysis = self._analyze_performance(recent_performances)\n            \n            for schedule in current_schedules:\n                adaptations_needed = []\n                \n                # Check if material needs more review based on performance\n                material_performance = [p for p in recent_performances if p.quiz and p.quiz.material_id == schedule.material_id]\n                \n                if material_performance:\n                    avg_score = sum(p.score for p in material_performance) / len(material_performance)\n                    \n                    # If performance is poor, increase review frequency\n                    if avg_score < 0.6:\n                        adaptations_needed.append('increase_review')\n                        # Decrease interval for spaced repetition\n                        new_interval = max(1, schedule.repetition_interval // 2)\n                        adaptations_needed.append(f'reduce_interval_to_{new_interval}')\n                    \n                    # If performance is excellent, we can space out reviews more\n                    elif avg_score > 0.9:\n                        new_interval = min(14, schedule.repetition_interval * 2)\n                        adaptations_needed.append(f'increase_interval_to_{new_interval}')\n                \n                # Adjust based on user's learning patterns\n                if performance_analysis['struggles_with_difficulty']:\n                    if schedule.material.difficulty_score > 0.7:\n                        # Break difficult material into smaller chunks\n                        adaptations_needed.append('reduce_session_duration')\n                \n                if performance_analysis['peak_performance_time']:\n                    # Reschedule to optimal time\n                    optimal_time = performance_analysis['peak_performance_time']\n                    new_time = schedule.scheduled_date.replace(hour=optimal_time)\n                    adaptations_needed.append(f'reschedule_to_{optimal_time}')\n                \n                # Apply adaptations\n                if adaptations_needed:\n                    adaptation_entry = {\n                        'schedule_id': schedule.id,\n                        'original_date': schedule.scheduled_date,\n                        'adaptations': adaptations_needed,\n                        'reason': 'performance_based_adaptation'\n                    }\n                    adaptations.append(adaptation_entry)\n            \n            return adaptations\n            \n        except Exception as e:\n            print(f\"Error adapting schedule: {e}\")\n            return []\n    \n    def calculate_spaced_repetition_interval(\n        self,\n        current_interval: int,\n        performance_score: float,\n        retention_rate: float = 0.7\n    ) -> int:\n        \"\"\"\n        Calculate next repetition interval using spaced repetition algorithm\n        \n        Args:\n            current_interval: Current interval in days\n            performance_score: Score from 0.0 to 1.0\n            retention_rate: Target retention rate\n            \n        Returns:\n            Next interval in days\n        \"\"\"\n        # Base multiplier based on performance\n        if performance_score >= 0.9:\n            multiplier = 2.5\n        elif performance_score >= 0.8:\n            multiplier = 2.0\n        elif performance_score >= 0.7:\n            multiplier = 1.5\n        elif performance_score >= 0.6:\n            multiplier = 1.2\n        else:\n            # Poor performance - reduce interval\n            multiplier = 0.8\n        \n        # Adjust based on retention rate\n        retention_adjustment = retention_rate / 0.7  # Normalized to default 0.7\n        multiplier *= retention_adjustment\n        \n        # Calculate new interval\n        new_interval = int(current_interval * multiplier)\n        \n        # Ensure reasonable bounds\n        new_interval = max(1, min(new_interval, 30))  # Between 1 and 30 days\n        \n        return new_interval\n    \n    def _get_optimal_study_time(self, preferred_times: Dict[str, float], session_num: int) -> int:\n        \"\"\"Get optimal study hour based on preferences\"\"\"\n        # Convert preferences to hours\n        time_scores = {\n            9: preferred_times.get('morning', 0.7),   # 9 AM\n            14: preferred_times.get('afternoon', 0.5), # 2 PM\n            19: preferred_times.get('evening', 0.3)    # 7 PM\n        }\n        \n        # Add some variation to avoid scheduling everything at the same time\n        variation = (session_num % 3) - 1  # -1, 0, or 1\n        \n        # Find the best time\n        best_hour = max(time_scores.keys(), key=lambda h: time_scores[h])\n        \n        return max(8, min(21, best_hour + variation))  # Keep within 8 AM to 9 PM\n    \n    def _calculate_cognitive_load(\n        self, \n        duration_minutes: int, \n        difficulty_score: float, \n        user_limit: float\n    ) -> float:\n        \"\"\"Calculate cognitive load for a study session\"\"\"\n        # Base load from duration\n        duration_load = duration_minutes / 120.0  # Normalize to 2-hour max\n        \n        # Difficulty contributes to cognitive load\n        difficulty_load = difficulty_score\n        \n        # Combine factors\n        total_load = (duration_load * 0.6) + (difficulty_load * 0.4)\n        \n        # Scale to user's limit\n        return min(total_load / user_limit, 1.0)\n    \n    def _calculate_priority_score(\n        self,\n        session_num: int,\n        total_sessions: int,\n        difficulty_score: float\n    ) -> float:\n        \"\"\"Calculate priority score for a session\"\"\"\n        # Earlier sessions have higher priority\n        position_priority = (total_sessions - session_num) / total_sessions\n        \n        # More difficult content gets higher priority\n        difficulty_priority = difficulty_score\n        \n        # Combine factors\n        return (position_priority * 0.7) + (difficulty_priority * 0.3)\n    \n    def _analyze_performance(self, performances: List[Performance]) -> Dict[str, Any]:\n        \"\"\"Analyze user performance patterns\"\"\"\n        if not performances:\n            return {\n                'struggles_with_difficulty': False,\n                'peak_performance_time': 9,  # Default to 9 AM\n                'average_score': 0.5\n            }\n        \n        # Calculate average score\n        avg_score = sum(p.score for p in performances) / len(performances)\n        \n        # Check if user struggles with difficult content\n        difficult_performances = [p for p in performances if p.difficulty_handled and p.difficulty_handled > 0.7]\n        struggles_with_difficulty = False\n        if difficult_performances:\n            difficult_avg = sum(p.score for p in difficult_performances) / len(difficult_performances)\n            struggles_with_difficulty = difficult_avg < avg_score * 0.8\n        \n        # Find peak performance time (simplified - would need more session data)\n        peak_time = 9  # Default morning time\n        \n        return {\n            'struggles_with_difficulty': struggles_with_difficulty,\n            'peak_performance_time': peak_time,\n            'average_score': avg_score,\n            'total_performances': len(performances)\n        }\n","size_bytes":14437},"services/spaced_repetition_scheduler.py":{"content":"\"\"\"\nAdvanced Spaced Repetition Scheduler with Half-Life Regression (HLR)\nImplements Duolingo-inspired adaptive scheduling algorithm\n\"\"\"\n\nfrom datetime import datetime, timedelta\nfrom typing import Dict, Any, List, Optional, Tuple\nimport math\nimport numpy as np\nfrom sqlalchemy.orm import Session\nfrom sqlalchemy import func, and_\nfrom models import User, Material, Schedule, Performance, StudySession, Quiz\n\nclass SpacedRepetitionScheduler:\n    \"\"\"\n    Advanced spaced repetition scheduler using Half-Life Regression\n    Implements adaptive scheduling based on individual learning patterns\n    \"\"\"\n    \n    def __init__(self, db: Session):\n        self.db = db\n        \n        # HLR model parameters (based on Duolingo research)\n        self.hlr_params = {\n            'initial_stability': 2.5,  # Initial memory stability in days\n            'difficulty_weight': -0.05,  # Weight for item difficulty\n            'previous_successes_weight': 0.15,  # Weight for previous successes\n            'previous_failures_weight': -0.077,  # Weight for previous failures\n            'elapsed_time_weight': 0.05,  # Weight for elapsed time since last review\n            'lag_time_weight': 0.112,  # Weight for lag time (delay in review)\n            'decay_factor': -0.105,  # Exponential decay factor\n            'threshold_recall_probability': 0.85  # Target recall probability\n        }\n        \n        # Cognitive load management parameters\n        self.cognitive_params = {\n            'max_daily_cognitive_load': 1.0,\n            'optimal_session_load': 0.6,\n            'load_recovery_rate': 0.2,  # Per hour\n            'difficulty_cognitive_multiplier': 1.5\n        }\n    \n    def generate_hlr_schedule(\n        self,\n        user_id: int,\n        content_analysis: Dict[str, Any],\n        target_date: datetime,\n        initial_difficulty: float\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Generate initial schedule using Half-Life Regression\n        \n        Args:\n            user_id: ID of the user\n            content_analysis: Content analysis from document processor\n            target_date: Target completion date\n            initial_difficulty: Initial difficulty assessment\n            \n        Returns:\n            HLR-based schedule with adaptive intervals\n        \"\"\"\n        try:\n            # Get user's learning profile\n            user_profile = self._get_user_hlr_profile(user_id)\n            \n            # Calculate content segments for scheduling\n            content_segments = self._prepare_content_segments(content_analysis)\n            \n            # Initialize HLR model for each segment\n            hlr_models = self._initialize_hlr_models(content_segments, initial_difficulty)\n            \n            # Generate adaptive schedule\n            schedule_entries = self._generate_adaptive_schedule(\n                user_id, user_profile, hlr_models, target_date\n            )\n            \n            # Optimize schedule for cognitive load\n            optimized_schedule = self._optimize_cognitive_load_distribution(\n                schedule_entries, user_profile\n            )\n            \n            # Calculate schedule metadata\n            schedule_metadata = self._calculate_schedule_metadata(optimized_schedule)\n            \n            return {\n                'success': True,\n                'schedule_entries': optimized_schedule,\n                'hlr_models': hlr_models,\n                'schedule_metadata': schedule_metadata,\n                'optimization_info': {\n                    'algorithm': 'half_life_regression',\n                    'target_recall_probability': self.hlr_params['threshold_recall_probability'],\n                    'cognitive_load_optimized': True,\n                    'generated_at': datetime.utcnow().isoformat()\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'HLR schedule generation failed: {str(e)}'\n            }\n    \n    def update_hlr_model(\n        self,\n        user_id: int,\n        material_id: int,\n        performance_data: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Update HLR model based on new performance data\n        \n        Args:\n            user_id: ID of the user\n            material_id: ID of the material\n            performance_data: Latest performance metrics\n            \n        Returns:\n            Updated HLR model parameters\n        \"\"\"\n        try:\n            # Get current HLR state\n            current_hlr_state = self._get_current_hlr_state(user_id, material_id)\n            \n            # Calculate new memory stability based on performance\n            new_stability = self._calculate_memory_stability(\n                current_hlr_state, performance_data\n            )\n            \n            # Update difficulty estimate\n            updated_difficulty = self._update_difficulty_estimate(\n                current_hlr_state, performance_data\n            )\n            \n            # Calculate next optimal interval\n            next_interval = self._calculate_optimal_interval(\n                new_stability, self.hlr_params['threshold_recall_probability']\n            )\n            \n            # Update HLR parameters based on learning\n            updated_params = self._update_hlr_parameters(\n                current_hlr_state, performance_data, new_stability\n            )\n            \n            return {\n                'success': True,\n                'updated_stability': new_stability,\n                'updated_difficulty': updated_difficulty,\n                'next_optimal_interval': next_interval,\n                'updated_parameters': updated_params,\n                'model_confidence': self._calculate_model_confidence(current_hlr_state),\n                'update_metadata': {\n                    'updated_at': datetime.utcnow().isoformat(),\n                    'performance_score': performance_data.get('score', 0),\n                    'model_version': '2.0'\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'HLR model update failed: {str(e)}'\n            }\n    \n    def optimize_schedule_intervals(\n        self,\n        user_id: int,\n        material_id: int,\n        performance_analysis: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Optimize schedule intervals based on performance analysis\n        \n        Args:\n            user_id: ID of the user\n            material_id: ID of the material\n            performance_analysis: Performance analysis data\n            \n        Returns:\n            Optimized schedule intervals\n        \"\"\"\n        try:\n            # Get current scheduled items\n            current_schedules = self._get_current_schedules(user_id, material_id)\n            \n            # Calculate interval optimizations for each scheduled item\n            interval_optimizations = []\n            \n            for schedule in current_schedules:\n                # Get HLR state for this item\n                hlr_state = self._get_schedule_hlr_state(schedule)\n                \n                # Calculate optimal interval based on current performance\n                optimal_interval = self._calculate_performance_based_interval(\n                    hlr_state, performance_analysis\n                )\n                \n                # Calculate cognitive load adjustment\n                cognitive_adjustment = self._calculate_cognitive_load_adjustment(\n                    schedule, performance_analysis, user_id\n                )\n                \n                # Combine optimizations\n                final_interval = self._combine_interval_optimizations(\n                    optimal_interval, cognitive_adjustment\n                )\n                \n                # Check if optimization is significant enough\n                if self._is_optimization_significant(schedule, final_interval):\n                    interval_optimizations.append({\n                        'schedule_id': schedule.id,\n                        'current_interval': schedule.repetition_interval,\n                        'optimized_interval': final_interval,\n                        'optimization_reason': self._get_optimization_reason(\n                            schedule, final_interval, performance_analysis\n                        ),\n                        'expected_improvement': self._calculate_expected_improvement(\n                            schedule, final_interval\n                        )\n                    })\n            \n            # Optimize overall schedule balance\n            balanced_optimizations = self._balance_schedule_optimizations(\n                interval_optimizations, user_id\n            )\n            \n            return {\n                'success': True,\n                'interval_optimizations': balanced_optimizations,\n                'optimization_summary': {\n                    'total_items_optimized': len(balanced_optimizations),\n                    'average_interval_change': self._calculate_average_change(balanced_optimizations),\n                    'expected_performance_improvement': self._calculate_overall_improvement(balanced_optimizations)\n                },\n                'optimization_metadata': {\n                    'optimized_at': datetime.utcnow().isoformat(),\n                    'optimization_algorithm': 'hlr_performance_based',\n                    'user_performance_level': performance_analysis.get('performance_patterns', {}).get('average_score', 0.5)\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Schedule optimization failed: {str(e)}'\n            }\n    \n    def predict_retention_curve(\n        self,\n        user_id: int,\n        material_id: int,\n        time_horizon: int\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Predict retention curve using HLR model\n        \n        Args:\n            user_id: ID of the user\n            material_id: ID of the material\n            time_horizon: Prediction horizon in days\n            \n        Returns:\n            Predicted retention curve data\n        \"\"\"\n        try:\n            # Get current HLR states for all material segments\n            hlr_states = self._get_material_hlr_states(user_id, material_id)\n            \n            # Generate retention predictions for each segment\n            retention_predictions = []\n            \n            for segment_id, hlr_state in hlr_states.items():\n                segment_curve = self._predict_segment_retention(\n                    hlr_state, time_horizon\n                )\n                retention_predictions.append({\n                    'segment_id': segment_id,\n                    'retention_curve': segment_curve,\n                    'half_life': hlr_state['memory_stability'],\n                    'current_strength': hlr_state['memory_strength']\n                })\n            \n            # Calculate overall material retention curve\n            overall_retention = self._calculate_overall_retention_curve(\n                retention_predictions, time_horizon\n            )\n            \n            # Identify critical review points\n            critical_points = self._identify_critical_review_points(\n                overall_retention, self.hlr_params['threshold_recall_probability']\n            )\n            \n            # Calculate forgetting curve parameters\n            forgetting_curve_params = self._calculate_forgetting_curve_parameters(\n                hlr_states, retention_predictions\n            )\n            \n            return {\n                'success': True,\n                'overall_retention_curve': overall_retention,\n                'segment_predictions': retention_predictions,\n                'critical_review_points': critical_points,\n                'forgetting_curve_parameters': forgetting_curve_params,\n                'prediction_metadata': {\n                    'prediction_date': datetime.utcnow().isoformat(),\n                    'time_horizon_days': time_horizon,\n                    'model_confidence': self._calculate_prediction_confidence(hlr_states),\n                    'segments_analyzed': len(hlr_states)\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Retention curve prediction failed: {str(e)}'\n            }\n    \n    def predict_optimal_intervals(\n        self,\n        user_id: int,\n        learning_history: Dict[str, Any]\n    ) -> Dict[str, Any]:\n        \"\"\"\n        Predict optimal intervals for future learning\n        \n        Args:\n            user_id: ID of the user\n            learning_history: Comprehensive learning history\n            \n        Returns:\n            Predicted optimal intervals\n        \"\"\"\n        try:\n            # Analyze historical interval effectiveness\n            interval_effectiveness = self._analyze_interval_effectiveness(learning_history)\n            \n            # Calculate user-specific HLR parameters\n            personalized_params = self._calculate_personalized_hlr_params(\n                user_id, learning_history\n            )\n            \n            # Predict optimal intervals for different difficulty levels\n            interval_predictions = {}\n            difficulty_levels = [0.3, 0.5, 0.7, 0.9]\n            \n            for difficulty in difficulty_levels:\n                optimal_sequence = self._predict_optimal_sequence(\n                    personalized_params, difficulty, interval_effectiveness\n                )\n                interval_predictions[f'difficulty_{difficulty}'] = optimal_sequence\n            \n            # Calculate adaptive interval recommendations\n            adaptive_recommendations = self._generate_adaptive_interval_recommendations(\n                interval_predictions, learning_history\n            )\n            \n            return {\n                'success': True,\n                'interval_predictions': interval_predictions,\n                'adaptive_recommendations': adaptive_recommendations,\n                'personalized_parameters': personalized_params,\n                'interval_effectiveness_analysis': interval_effectiveness,\n                'prediction_metadata': {\n                    'prediction_date': datetime.utcnow().isoformat(),\n                    'personalization_confidence': self._calculate_personalization_confidence(learning_history),\n                    'recommendations_based_on': 'hlr_historical_analysis'\n                }\n            }\n            \n        except Exception as e:\n            return {\n                'success': False,\n                'error': f'Optimal interval prediction failed: {str(e)}'\n            }\n    \n    # Core HLR algorithm implementation\n    \n    def _calculate_memory_stability(\n        self,\n        hlr_state: Dict[str, Any],\n        performance_data: Dict[str, Any]\n    ) -> float:\n        \"\"\"Calculate memory stability using HLR algorithm\"\"\"\n        \n        # Get performance metrics\n        success = 1 if performance_data.get('score', 0) >= 0.7 else 0\n        response_time = performance_data.get('time_taken', 10)  # Default 10 seconds\n        difficulty = hlr_state.get('difficulty', 0.5)\n        \n        # Get previous performance history\n        previous_successes = hlr_state.get('success_count', 0)\n        previous_failures = hlr_state.get('failure_count', 0)\n        \n        # Calculate elapsed time since last review\n        last_review = hlr_state.get('last_review_date')\n        if last_review:\n            elapsed_days = (datetime.utcnow() - last_review).days\n        else:\n            elapsed_days = 0\n        \n        # Calculate lag time (delay from scheduled review)\n        scheduled_date = hlr_state.get('scheduled_date')\n        if scheduled_date and datetime.utcnow() > scheduled_date:\n            lag_days = (datetime.utcnow() - scheduled_date).days\n        else:\n            lag_days = 0\n        \n        # HLR stability calculation\n        log_stability = (\n            math.log(max(self.hlr_params['initial_stability'], 0.1)) +\n            self.hlr_params['difficulty_weight'] * difficulty +\n            self.hlr_params['previous_successes_weight'] * previous_successes +\n            self.hlr_params['previous_failures_weight'] * previous_failures +\n            self.hlr_params['elapsed_time_weight'] * elapsed_days +\n            self.hlr_params['lag_time_weight'] * lag_days\n        )\n        \n        # Convert back to days and apply success/failure modifier\n        stability = math.exp(log_stability)\n        \n        # Update based on current performance\n        if success:\n            stability *= (1.3 + (response_time / 100))  # Faster response = better memory\n        else:\n            stability *= 0.6  # Failure decreases stability\n        \n        # Ensure reasonable bounds\n        return max(0.5, min(30.0, stability))\n    \n    def _calculate_recall_probability(\n        self,\n        stability: float,\n        elapsed_time: float\n    ) -> float:\n        \"\"\"Calculate recall probability using exponential decay\"\"\"\n        if stability <= 0:\n            return 0.0\n        \n        # Exponential decay function: P(recall) = 2^(-elapsed_time/stability)\n        recall_probability = math.pow(2, -elapsed_time / stability)\n        return max(0.0, min(1.0, recall_probability))\n    \n    def _calculate_optimal_interval(\n        self,\n        stability: float,\n        target_recall_probability: float\n    ) -> int:\n        \"\"\"Calculate optimal interval for target recall probability\"\"\"\n        if stability <= 0 or target_recall_probability <= 0:\n            return 1\n        \n        # Solve for time: target_recall = 2^(-time/stability)\n        # time = -stability * log2(target_recall)\n        optimal_time = -stability * math.log2(target_recall_probability)\n        \n        # Convert to days and ensure reasonable bounds\n        optimal_days = max(1, min(30, int(round(optimal_time))))\n        return optimal_days\n    \n    def _update_difficulty_estimate(\n        self,\n        hlr_state: Dict[str, Any],\n        performance_data: Dict[str, Any]\n    ) -> float:\n        \"\"\"Update difficulty estimate based on performance\"\"\"\n        current_difficulty = hlr_state.get('difficulty', 0.5)\n        score = performance_data.get('score', 0)\n        time_taken = performance_data.get('time_taken', 10)\n        \n        # Calculate difficulty indicators\n        score_indicator = 1 - score  # Lower score = higher difficulty\n        time_indicator = min(1.0, time_taken / 60)  # Longer time = higher difficulty\n        \n        # Weighted update\n        difficulty_update = (score_indicator * 0.7) + (time_indicator * 0.3)\n        \n        # Smooth update using exponential moving average\n        alpha = 0.3  # Learning rate\n        new_difficulty = (1 - alpha) * current_difficulty + alpha * difficulty_update\n        \n        return max(0.0, min(1.0, new_difficulty))\n    \n    def _get_user_hlr_profile(self, user_id: int) -> Dict[str, Any]:\n        \"\"\"Get user's HLR learning profile\"\"\"\n        user = self.db.query(User).filter(User.id == user_id).first()\n        \n        # Get historical performance for personalization\n        recent_performances = self.db.query(Performance).filter(\n            Performance.user_id == user_id\n        ).order_by(Performance.created_at.desc()).limit(20).all()\n        \n        # Calculate personalized HLR parameters\n        if recent_performances:\n            avg_score = sum(p.score for p in recent_performances) / len(recent_performances)\n            avg_time = sum(p.time_taken for p in recent_performances if p.time_taken) / len(recent_performances)\n        else:\n            avg_score = 0.7\n            avg_time = 15\n        \n        # Adjust HLR parameters based on user performance\n        personalized_params = self.hlr_params.copy()\n        \n        # Better performers can handle longer intervals\n        if avg_score > 0.8:\n            personalized_params['threshold_recall_probability'] = 0.8\n        elif avg_score < 0.6:\n            personalized_params['threshold_recall_probability'] = 0.9\n        \n        return {\n            'user_id': user_id,\n            'average_performance': avg_score,\n            'average_response_time': avg_time,\n            'cognitive_capacity': getattr(user, 'cognitive_load_limit', 0.8) if user else 0.8,\n            'learning_rate': min(1.0, avg_score + 0.2),\n            'hlr_parameters': personalized_params\n        }\n    \n    def _prepare_content_segments(self, content_analysis: Dict[str, Any]) -> List[Dict[str, Any]]:\n        \"\"\"Prepare content segments for HLR scheduling\"\"\"\n        segments = content_analysis.get('content_segments', [])\n        \n        prepared_segments = []\n        for i, segment in enumerate(segments):\n            prepared_segments.append({\n                'segment_id': f'segment_{i+1}',\n                'content': segment.get('content', ''),\n                'word_count': segment.get('word_count', 0),\n                'difficulty': segment.get('difficulty_score', 0.5),\n                'estimated_study_time': segment.get('estimated_reading_time', 15),\n                'cognitive_load': segment.get('cognitive_load', 0.5),\n                'key_concepts': segment.get('key_concepts', [])\n            })\n        \n        return prepared_segments\n    \n    def _initialize_hlr_models(\n        self,\n        content_segments: List[Dict[str, Any]],\n        initial_difficulty: float\n    ) -> Dict[str, Dict[str, Any]]:\n        \"\"\"Initialize HLR models for content segments\"\"\"\n        hlr_models = {}\n        \n        for segment in content_segments:\n            segment_id = segment['segment_id']\n            \n            hlr_models[segment_id] = {\n                'segment_id': segment_id,\n                'difficulty': segment['difficulty'],\n                'memory_stability': self.hlr_params['initial_stability'],\n                'memory_strength': 1.0,\n                'success_count': 0,\n                'failure_count': 0,\n                'last_review_date': None,\n                'scheduled_date': None,\n                'repetition_number': 0,\n                'cognitive_load': segment['cognitive_load'],\n                'initial_interval': self._calculate_initial_interval(segment['difficulty'])\n            }\n        \n        return hlr_models\n    \n    def _calculate_initial_interval(self, difficulty: float) -> int:\n        \"\"\"Calculate initial review interval based on difficulty\"\"\"\n        base_interval = 2  # 2 days base\n        difficulty_adjustment = 1 - (difficulty * 0.5)  # Easier content = longer interval\n        return max(1, int(base_interval * difficulty_adjustment))\n    \n    def _generate_adaptive_schedule(\n        self,\n        user_id: int,\n        user_profile: Dict[str, Any],\n        hlr_models: Dict[str, Dict[str, Any]],\n        target_date: datetime\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Generate adaptive schedule using HLR models\"\"\"\n        schedule_entries = []\n        current_date = datetime.utcnow().replace(hour=9, minute=0, second=0, microsecond=0)\n        \n        # Calculate total available days\n        available_days = max(7, (target_date - current_date).days)\n        \n        for segment_id, hlr_model in hlr_models.items():\n            # Generate review schedule for this segment\n            segment_schedule = self._generate_segment_schedule(\n                user_id, segment_id, hlr_model, current_date, available_days, user_profile\n            )\n            schedule_entries.extend(segment_schedule)\n        \n        # Sort by scheduled date\n        schedule_entries.sort(key=lambda x: x['scheduled_date'])\n        \n        return schedule_entries\n    \n    def _generate_segment_schedule(\n        self,\n        user_id: int,\n        segment_id: str,\n        hlr_model: Dict[str, Any],\n        start_date: datetime,\n        available_days: int,\n        user_profile: Dict[str, Any]\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Generate schedule for a single content segment\"\"\"\n        schedule = []\n        current_date = start_date\n        repetition_number = 0\n        current_interval = hlr_model['initial_interval']\n        \n        # Generate review sessions until target mastery or end date\n        while current_date <= start_date + timedelta(days=available_days) and repetition_number < 8:\n            # Create schedule entry\n            schedule_entry = {\n                'user_id': user_id,\n                'segment_id': segment_id,\n                'scheduled_date': current_date,\n                'repetition_number': repetition_number,\n                'repetition_interval': current_interval,\n                'estimated_duration': self._calculate_session_duration(hlr_model, repetition_number),\n                'session_type': self._determine_session_type(repetition_number),\n                'difficulty_level': hlr_model['difficulty'],\n                'cognitive_load': self._calculate_session_cognitive_load(hlr_model, repetition_number),\n                'expected_recall_probability': self._calculate_recall_probability(\n                    hlr_model['memory_stability'], current_interval\n                ),\n                'priority_score': self._calculate_priority_score(hlr_model, repetition_number),\n                'status': 'scheduled'\n            }\n            \n            schedule.append(schedule_entry)\n            \n            # Calculate next interval using HLR\n            next_interval = self._predict_next_interval(hlr_model, repetition_number)\n            current_date += timedelta(days=next_interval)\n            repetition_number += 1\n            current_interval = next_interval\n        \n        return schedule\n    \n    def _predict_next_interval(self, hlr_model: Dict[str, Any], repetition_number: int) -> int:\n        \"\"\"Predict next optimal interval\"\"\"\n        # Simulate performance for interval calculation\n        # In real implementation, this would be updated after actual performance\n        simulated_success_rate = max(0.5, 1.0 - hlr_model['difficulty'] * 0.4)\n        \n        if simulated_success_rate > 0.8:\n            # Good performance, increase interval\n            multiplier = 2.0 + (repetition_number * 0.2)\n        elif simulated_success_rate > 0.6:\n            # Average performance, moderate increase\n            multiplier = 1.5 + (repetition_number * 0.1)\n        else:\n            # Poor performance, conservative increase\n            multiplier = 1.2\n        \n        base_interval = hlr_model.get('initial_interval', 2)\n        next_interval = int(base_interval * multiplier)\n        \n        return max(1, min(14, next_interval))  # Bounds: 1-14 days\n    \n    def _calculate_session_duration(self, hlr_model: Dict[str, Any], repetition_number: int) -> int:\n        \"\"\"Calculate session duration based on repetition number and difficulty\"\"\"\n        base_duration = 20  # 20 minutes base\n        difficulty_multiplier = 1 + (hlr_model['difficulty'] * 0.3)\n        repetition_adjustment = max(0.7, 1 - (repetition_number * 0.1))  # Shorter for later repetitions\n        \n        duration = int(base_duration * difficulty_multiplier * repetition_adjustment)\n        return max(10, min(60, duration))  # Bounds: 10-60 minutes\n    \n    def _determine_session_type(self, repetition_number: int) -> str:\n        \"\"\"Determine session type based on repetition number\"\"\"\n        if repetition_number == 0:\n            return 'initial_learning'\n        elif repetition_number <= 2:\n            return 'active_recall'\n        elif repetition_number <= 4:\n            return 'spaced_review'\n        else:\n            return 'maintenance_review'\n    \n    def _calculate_session_cognitive_load(self, hlr_model: Dict[str, Any], repetition_number: int) -> float:\n        \"\"\"Calculate cognitive load for session\"\"\"\n        base_load = hlr_model['cognitive_load']\n        repetition_reduction = repetition_number * 0.1  # Load decreases with repetition\n        \n        adjusted_load = max(0.2, base_load - repetition_reduction)\n        return round(adjusted_load, 2)\n    \n    def _calculate_priority_score(self, hlr_model: Dict[str, Any], repetition_number: int) -> float:\n        \"\"\"Calculate priority score for scheduling\"\"\"\n        difficulty_priority = hlr_model['difficulty']  # Higher difficulty = higher priority\n        urgency_priority = 1.0 / (repetition_number + 1)  # First reviews have higher priority\n        \n        priority = (difficulty_priority * 0.6) + (urgency_priority * 0.4)\n        return round(priority, 3)\n    \n    def _optimize_cognitive_load_distribution(\n        self,\n        schedule_entries: List[Dict[str, Any]],\n        user_profile: Dict[str, Any]\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Optimize cognitive load distribution across schedule\"\"\"\n        # Group by date\n        daily_schedules = {}\n        for entry in schedule_entries:\n            date_key = entry['scheduled_date'].date()\n            if date_key not in daily_schedules:\n                daily_schedules[date_key] = []\n            daily_schedules[date_key].append(entry)\n        \n        # Optimize each day's cognitive load\n        optimized_entries = []\n        user_capacity = user_profile.get('cognitive_capacity', 0.8)\n        \n        for date, daily_entries in daily_schedules.items():\n            # Calculate total cognitive load for the day\n            total_load = sum(entry['cognitive_load'] for entry in daily_entries)\n            \n            if total_load > user_capacity:\n                # Redistribute or reschedule some items\n                optimized_daily = self._redistribute_daily_cognitive_load(\n                    daily_entries, user_capacity\n                )\n            else:\n                optimized_daily = daily_entries\n            \n            optimized_entries.extend(optimized_daily)\n        \n        return sorted(optimized_entries, key=lambda x: x['scheduled_date'])\n    \n    def _redistribute_daily_cognitive_load(\n        self,\n        daily_entries: List[Dict[str, Any]],\n        capacity: float\n    ) -> List[Dict[str, Any]]:\n        \"\"\"Redistribute cognitive load for a single day\"\"\"\n        # Sort by priority (high priority items stay on original day)\n        daily_entries.sort(key=lambda x: x['priority_score'], reverse=True)\n        \n        redistributed = []\n        current_load = 0\n        \n        for entry in daily_entries:\n            if current_load + entry['cognitive_load'] <= capacity:\n                # Keep on original day\n                redistributed.append(entry)\n                current_load += entry['cognitive_load']\n            else:\n                # Move to next available day\n                entry['scheduled_date'] += timedelta(days=1)\n                entry['rescheduled'] = True\n                redistributed.append(entry)\n        \n        return redistributed\n    \n    def _calculate_schedule_metadata(self, schedule_entries: List[Dict[str, Any]]) -> Dict[str, Any]:\n        \"\"\"Calculate metadata for the generated schedule\"\"\"\n        if not schedule_entries:\n            return {'total_sessions': 0}\n        \n        total_sessions = len(schedule_entries)\n        total_duration = sum(entry['estimated_duration'] for entry in schedule_entries)\n        avg_cognitive_load = sum(entry['cognitive_load'] for entry in schedule_entries) / total_sessions\n        \n        # Calculate schedule span\n        start_date = min(entry['scheduled_date'] for entry in schedule_entries)\n        end_date = max(entry['scheduled_date'] for entry in schedule_entries)\n        schedule_span = (end_date - start_date).days\n        \n        # Calculate session types distribution\n        session_types = {}\n        for entry in schedule_entries:\n            session_type = entry['session_type']\n            session_types[session_type] = session_types.get(session_type, 0) + 1\n        \n        return {\n            'total_sessions': total_sessions,\n            'total_estimated_duration': total_duration,\n            'average_cognitive_load': round(avg_cognitive_load, 3),\n            'schedule_span_days': schedule_span,\n            'session_types_distribution': session_types,\n            'average_repetition_interval': round(\n                sum(entry['repetition_interval'] for entry in schedule_entries) / total_sessions, 1\n            ),\n            'cognitive_load_optimized': any(entry.get('rescheduled', False) for entry in schedule_entries)\n        }\n    \n    # Additional helper methods would continue here...\n    # This represents the core HLR implementation structure","size_bytes":32638}},"version":1}